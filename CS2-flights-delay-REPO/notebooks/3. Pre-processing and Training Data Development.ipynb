{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual Arrival Delay Prediction\n",
    "\n",
    "## Pre-processing and Trainging Data Development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this project is to build a model that predicts the likelihood and duration of flight delays with a specified level of accuracy, helping travelers meet specific arrival time requirements.\n",
    "\n",
    "The source data comes from the US Domestic Flights Delay (2013–2018) dataset, which includes scheduled and actual departure and arrival times. Collected by the U.S. Office of Airline Information, Bureau of Transportation Statistics (BTS), the dataset covers flights between 2014 and 2018 and provides details such as date, time, origin, destination, airline, distance, and delay status. (Source: [Kaggle](https://www.kaggle.com/datasets/gabrielluizone/us-domestic-flights-delay-prediction-2013-2018))\n",
    "\n",
    "During the Data Wrangling stage of the project, the raw data was collected, evaluated, and cleaned. The resulting dataset was stored in the pickle data format.\n",
    "\n",
    "In the Exploratory Data Analysis (EDA) stage, the following factors were explored and tested:\n",
    "*\tAirports of departure and arrival\n",
    "*\tAirlines operating the flight\n",
    "*\tMonth of the flight\n",
    "*\tDay of the week of the flight\n",
    "*\tTime of day (categorized into time blocks) for departure and arrival\n",
    "\n",
    "All these variables are categorical by nature (even though the month and day of the week are stored as integers) and need to be encoded for modeling purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Loading packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "input_file_name = '../data/processed/processed_2014_2018_final.pickle'\n",
    "with open(input_file_name, 'rb') as in_file:\n",
    "    flights = pickle.load(in_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating dummy features for categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Origin    368\n",
       "Dest      368\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights[['Origin', 'Dest']].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there are 368 airports for both Origin and Destination. Converting them into dummy features would result in more than 730 features, which is excessive for the model, especially since some of these airports are used infrequently. It would be reasonable to apply a threshold to distinguish major airports from minor ones. I propose using the cumulative share of total flights departing from or arriving at each airport for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tolal number of airports cumulatively fullfilled 95% of domestic flights is 129 airports\n"
     ]
    }
   ],
   "source": [
    "# Calculation of cumulative share of the domestic flights\n",
    "number_of_flights = flights.groupby('Origin', observed=False)[['CRSDepDT']].count().sort_values(by='CRSDepDT', ascending=False)\n",
    "number_of_flights['Share'] = number_of_flights['CRSDepDT'] / np.sum(number_of_flights['CRSDepDT'])\n",
    "number_of_flights['Cum_share'] = number_of_flights['Share'].cumsum()\n",
    "\n",
    "# Applying the THRESHOLD to identify the major airports responsible for the specified share of domestic flights\n",
    "THRESHOLD = 0.95\n",
    "main_airports = list(number_of_flights[number_of_flights['Cum_share'] <= THRESHOLD].index)\n",
    "print('The tolal number of airports cumulatively fullfilled {:.0%} of domestic flights is {:,d} airports'.format(THRESHOLD, len(main_airports)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Marking minor airports — those accounting for less than 5% of total domestic flights — as ‘OTHER’ will significantly reduce the number of dummy variables, decreasing from 728 to 258. These dummy variables represent only the airports of Origin and Destination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the categories of minor Origin and Destination airports to the 'OTHER' category\n",
    "flights['Origin_'] = pd.Categorical(np.where(~flights['Origin'].isin(main_airports), 'OTHER', flights['Origin']))\n",
    "flights['Dest_'] = pd.Categorical(np.where(~flights['Dest'].isin(main_airports), 'OTHER', flights['Dest']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dest_      130\n",
      "Origin_    130\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(flights[['Dest_', 'Origin_']].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the result contains 130 Origin and 130 Destination airports, which will be converted into 258 dummy variables in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of predictive categorical factors\n",
    "factors = ['Month', 'Weekday', 'Reporting_Airline', 'Origin_', 'Dest_', 'DepTimeBlk', 'ArrTimeBlk']\n",
    "\n",
    "# Creating two predicted variables: Cancelled flights and Actual Arrival Delay\n",
    "notReachedDest = flights.loc[flights['ReachedDest'] == False, 'ReachedDest']\n",
    "ActArrDelay = flights.loc[flights['ReachedDest'] == True, 'ActArrDelay'].astype('float16')\n",
    "\n",
    "# Converting 'Month' and 'Weekday' to 'category' data type for memory efficiency\n",
    "flights[['Month', 'Weekday']] = flights[['Month', 'Weekday']].astype('category')\n",
    "\n",
    "# Splitting and truncating the dataset to reduce memory usage\n",
    "flights_notReachedDest = flights.loc[flights['ReachedDest'] == False, factors]\n",
    "flights = flights.loc[flights['ReachedDest'] == True, factors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting all categorical data to dummy variables and dropping the first category to avoid multicollinearity.\n",
    "arr_model_data = pd.DataFrame()\n",
    "notReachedDest_model_data = pd.DataFrame()\n",
    "for factor in factors:\n",
    "    arr_model_data = pd.concat([arr_model_data, pd.get_dummies(flights[factor], drop_first=True, prefix=factor)], axis=1)\n",
    "    notReachedDest_model_data = pd.concat([notReachedDest_model_data, pd.get_dummies(flights_notReachedDest[factor], drop_first=True, prefix=factor)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Training and Testing Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I plan to create two prediction models — one to predict the likelihood of flight cancellation and another to estimate the arrival delay, using features such as flight date, time, airline, and airport. To accomplish this, the features dataset, along with the two target variables (flight cancellation and actual arrival delay), will be split into training and testing sets in a 70/30% ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_arr_train, X_arr_test, y_arr_train, y_arr_test= train_test_split(arr_model_data, ActArrDelay, test_size = 0.3, random_state = 1812)\n",
    "X_notReachedDest_train, X_notReachedDest_test, y_notReachedDest_train, y_notReachedDest_test = train_test_split(\n",
    "    notReachedDest_model_data, notReachedDest, test_size = 0.3, random_state = 1812)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traing features (actual arrival delay) shape: (20564378, 330)\n",
      "Test features (actual arrival delay) shape: (8813306, 330)\n",
      "Target variable (actual arrival delay) training shape: (20564378,)\n",
      "Target variable (actual arrival delay) test shape:  (8813306,)\n",
      "\n",
      "Traing features (not reached destination) shape: (345659, 330)\n",
      "Test features (not reached destination) shape: (148140, 330)\n",
      "Target variable (not reached destination) training shape:  (345659,)\n",
      "Target variable (not reached destination) test shape: (148140,)\n"
     ]
    }
   ],
   "source": [
    "print('Traing features (actual arrival delay) shape: {}'.format(X_arr_train.shape))\n",
    "print('Test features (actual arrival delay) shape: {}'.format(X_arr_test.shape))\n",
    "print('Target variable (actual arrival delay) training shape: {}'.format(y_arr_train.shape))\n",
    "print('Target variable (actual arrival delay) test shape:  {}'.format(y_arr_test.shape))\n",
    "print()\n",
    "print('Traing features (not reached destination) shape: {}'.format(X_notReachedDest_train.shape))\n",
    "print('Test features (not reached destination) shape: {}'.format(X_notReachedDest_test.shape))\n",
    "print('Target variable (not reached destination) training shape:  {}'.format(y_notReachedDest_train.shape))\n",
    "print('Target variable (not reached destination) test shape: {}'.format(y_notReachedDest_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standartization of numeric features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only numeric feature in this model is the Actual Arrival Delay, which is the target variable. In this case, standardization does not make sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusuions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\t__Data Preprocessing and Feature Engineering:__  \n",
    "*\tBy applying a cumulative share threshold, minor airports were grouped under the ‘OTHER’ category, significantly reducing the number of dummy variables from 728 to 258, which makes the model more efficient.\n",
    "*\tThe categorical features (such as month, weekday, airport origin and destination, airline, and time blocks) were successfully encoded into dummy variables. This step ensures the model can handle these features properly without introducing multicollinearity.\n",
    "*   Two target variables were identified: flight cancellation (binary) and actual arrival delay (numeric). These two different target types will require different approaches for modeling but were both addressed within the same framework.\n",
    "*   Standardization is typically used when the predictive features have different scales. Since the only numeric feature is the actual arrival delay (target variable), standardization was deemed unnecessary. \n",
    "\n",
    "2.\t__Training and Testing Split:__ \n",
    "*\tThe dataset was split into training and testing sets with a 70/30 ratio, which is a common practice for training models while ensuring enough data for validation. This split will allow for assessing the model’s performance on unseen data.\n",
    "\n",
    "3.\t__Modeling Potential:__  \n",
    "*\tThe framework set up allows for the development of predictive models that will estimate flight delays and cancellation likelihood based on various features, including the airline, airport, time of day, and day of the week and month.\n",
    "*\tFuture steps would involve training the model, testing it, and evaluating its accuracy, considering the use of machine learning techniques like classification for cancellations and regression for delay prediction.\n",
    "\n",
    "4.\t__Next Steps:__  \n",
    "*\tThe next steps in this project include applying machine learning algorithms to train the model, evaluating its performance with appropriate metrics (e.g., accuracy, precision, recall for classification; RMSE for regression), and refining the model based on the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20564378, 330) X_arr_train\n",
      "(8813306, 330) X_arr_test\n",
      "(20564378,) y_arr_train\n",
      "(8813306,) y_arr_test\n",
      "(345659, 330) X_notReachedDest_train\n",
      "(148140, 330) X_notReachedDest_test\n",
      "(345659,) y_notReachedDest_train\n",
      "(148140,) y_notReachedDest_test\n"
     ]
    }
   ],
   "source": [
    "datasets = [X_arr_train, X_arr_test, y_arr_train, y_arr_test, X_notReachedDest_train, X_notReachedDest_test, y_notReachedDest_train, \n",
    "            y_notReachedDest_test]\n",
    "datasets_names = ['X_arr_train', 'X_arr_test', 'y_arr_train', 'y_arr_test', 'X_notReachedDest_train', 'X_notReachedDest_test', \n",
    "                  'y_notReachedDest_train', 'y_notReachedDest_test']\n",
    "\n",
    "for df, df_name in zip(datasets, datasets_names):\n",
    "    print(df.shape, df_name)\n",
    "    output_file_name = '../data/processed/'+ df_name+ '.pickle'\n",
    "    with open(output_file_name, 'wb') as out_file:\n",
    "        pickle.dump(df, out_file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "springboard",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
