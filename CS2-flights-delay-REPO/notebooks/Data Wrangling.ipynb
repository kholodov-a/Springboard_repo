{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection\n",
    "\n",
    "The original dataset, US Domestic Flights Delay Prediction (2013 - 2018) (Source: [Kaggle](https://www.kaggle.com/datasets/gabrielluizone/us-domestic-flights-delay-prediction-2013-2018)), is provided as a zip archive of 1.54 GB. When decompressed, the archive contains 60 files with a total size of 13.6 GB. Each file corresponds to one month of data, starting from January 2014 and ending in December 2018.\n",
    "\n",
    "Steps for collecting and cleaning the data:\n",
    "\n",
    "*\tLoading the first file\n",
    "*\tEvaluating the data’s size and quality\n",
    "*\tDefining the specific data needed for the project\n",
    "*\tDeveloping a process for data organization and cleaning\n",
    "*\tTesting the code on one month’s data file\n",
    "*\tApplying the code to all files\n",
    "*\tAccumulating the complete dataset\n",
    "\n",
    "\n",
    "The archive file (csv_flight.zip) was downloaded and saved locally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the first file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required modules\n",
    "import zipfile\n",
    "import os\n",
    "import pandas as pd\n",
    "os.chdir('/Users/a.kholodov/Documents/02. Personal/20. Education/50. Universities/Springboard/Springboard_git/Springboard _repo/CS2-flights-delay-REPO')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "source_zip_file = 'data/interim/csv_flight.zip'\n",
    "data_file = 'csv_flight/report_2014_1.csv'\n",
    "\n",
    "# reading the first file to evaluate the data\n",
    "with zipfile.ZipFile(source_zip_file) as zip_source:\n",
    "    with zip_source.open(data_file) as data_file:\n",
    "        flights_2014_1 = pd.read_csv(data_file, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# reading the first file to evaluate the data\n",
    "with zipfile.ZipFile(source_zip_file) as zip_source:\n",
    "    with zip_source.open(data_file) as data_file:\n",
    "        flights_2014_1 = pd.read_csv(data_file, low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(flights_2014_1.shape)\n",
    "print(flights_2014_1.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data for one month contains 471,949 rows and 110 columns, with a total memory size of 396 MB. The estimated size of the entire dataset, without reorganization or cleaning, may exceed 23 GB, which could be challenging to process locally. Therefore, one of the goals of data preparation will be to reduce the dataset size without compromising quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data structure and check\n",
    "### Date of the flight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_2014_1.iloc[:,:6].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. **Year**\n",
    "    * **Description:** Year\n",
    "    * **Data type:** int16\n",
    "    * **Keep**\n",
    "    * **Comment:** Despite there is a field FlightData, I decided to keep separat fileds because they can correlate with flights delay\n",
    "\n",
    "1. **Quarter**  \n",
    "    * **Description:** Quarter (1-4)  \n",
    "    * **Data type:** int8\n",
    "    * **Keep**\n",
    "\n",
    "2. **Month**  \n",
    "    * **Description:** Month (1-12)  \n",
    "    * **Data type:** int8\n",
    "    * **Keep**\n",
    "\n",
    "3. **DayofMonth**  \n",
    "    * **Description:** Day of month  \n",
    "    * **Data type:** int8\n",
    "    * **Keep**\n",
    "\n",
    "4. **DayOfWeek**  \n",
    "    * **Description:** Day of week  \n",
    "    * **Data type:** int8\n",
    "    * **Keep**  \n",
    "\n",
    "5. **FlightDate**  \n",
    "    * **Description:** Flight Date (yyyymmdd)\n",
    "    * **Data type:** datetime\n",
    "    * **Keep**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Values check for fields of Date of the flight: the data accurate, there is no outliers or NA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_2014_1.loc[:5, ['Year', 'Quarter', 'Month', 'DayofMonth', 'DayOfWeek', 'FlightDate']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_2014_1.iloc[:,5].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we need to change the data type during the data transformation from current type to the types in the table above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_2014_1.iloc[:,:6].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_2014_1.iloc[:,:6].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Airline's and flight's details "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_2014_1.iloc[:, 6:10].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "6. **Reporting_Airline**\n",
    "    * **Description:**  Unique Carrier Code. When the same code has been used by multiple carriers, a numeric suffix is used for earlier users, for example, PA, PA(1), PA(2). Use this field for analysis across a range of years. \n",
    "    * **Data type:** category \n",
    "    * **Keep**\n",
    "    * **Comment:** I decided to keep this field and drop DOT_ID_Reporting_Airline and IATA_CODE_Reporting_Airline because it is declared as unique and recomended by data provider as such | \n",
    "\n",
    "7. **DOT_ID_Reporting_Airline**\n",
    "    * **Description** An identification number assigned by US DOT to identify a unique airline (carrier). A unique airline (carrier) is defined as one holding and reporting under the same DOT certificate regardless of its Code, Name, or holding company/corporation.\n",
    "    * **Drop**\n",
    "    * **Comment:** Not unique\n",
    "    \n",
    "8. **IATA_CODE_Reporting_Airline**\n",
    "    * **Description:** Code assigned by IATA and commonly used to identify a carrier. As the same code may have been assigned to different carriers over time, the code is not always unique. For analysis, use the Unique Carrier Code.\n",
    "    * **Drop**\n",
    "    * **Comment:** Not unique\n",
    "\n",
    "9. **Tail_Number**\n",
    "    * **Description:** Tail Number\n",
    "    * **Drop**\n",
    "    * **Comment:** Irrelevant to the purposes of the project\n",
    "\n",
    "10. **Flight_Number_Reporting_Airline**\n",
    "    * **Description:** Flight Number\n",
    "    * **Data type:** int16\n",
    "    * **Keep**\n",
    "    * **Comment:** Unique number of the flight at a specific day/time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_2014_1.iloc[:, 6].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_2014_1['Flight_Number_Reporting_Airline'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_2014_1[['Reporting_Airline', 'Flight_Number_Reporting_Airline']].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_2014_1[['Reporting_Airline', 'Flight_Number_Reporting_Airline']].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data in the fields Reporting_Airline and Flight_Number_Reporting_Airline is accurate, there is no outliers or NA, But I need to change the data type during the data transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Origin and Destination detailes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DestFields = ['DestAirportID', \n",
    "                'DestAirportSeqID', \n",
    "                'DestCityMarketID',\n",
    "                'Dest',\n",
    "                'DestCityName',\n",
    "                'DestState',\n",
    "                'DestStateFips',\n",
    "                'DestStateName',\n",
    "                'DestWac']\n",
    "flights_2014_1.loc[:5, DestFields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OriginFields = ['OriginAirportID', \n",
    "                'OriginAirportSeqID', \n",
    "                'OriginCityMarketID',\n",
    "                'Origin',\n",
    "                'OriginCityName',\n",
    "                'OriginState',\n",
    "                'OriginStateFips',\n",
    "                'OriginStateName',\n",
    "                'OriginWac']\n",
    "flights_2014_1.loc[:5, OriginFields]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Origin and Destination data has the same structure so I will treat it the same way.\n",
    "\n",
    "11.\t**OriginAirportID / 20. DestAirportID**  \n",
    "    * **Description:** Origin/Destination Airport, Airport ID. An identification number assigned by US DOT to identify a unique airport. Use this field for airport analysis across a range of years because an airport can change its airport code and airport codes can be reused.  \n",
    "    * **Data type:** category  \n",
    "    * **Keep**  \n",
    "    * **Comment:** I decided to keep these codes because of its uniqueness, assuared by data provider.  \n",
    "    \n",
    "12.\t**OriginAirportSeqID / 21. DestAirportSeqID**  \n",
    "    * **Description:** Origin/Destination Airport, Airport Sequence ID. An identification number assigned by US DOT to identify a unique airport at a given point of time. Airport attributes, such as airport name or coordinates, may change over time.\n",
    "    * **Drop**\n",
    "13.\t**OriginCityMarketID / 22. DestCityMarketID**\n",
    "    * **Description:** Origin/Destination Airport, City Market ID. City Market ID is an identification number assigned by US DOT to identify a city market. Use this field to consolidate airports serving the same city market.\n",
    "    * **Drop**\n",
    "14.\t**Origin / 23. Dest**\n",
    "    * **Description:** Origin/Destination Airport\n",
    "    * **Data type:** category\n",
    "    * **Keep**\n",
    "    * **Comment:** This core is IATA code of the airport, which is represented in most traveling documents. It could be useful in the model.\n",
    "15.\t**OriginCityName / 24. DestCityName**\n",
    "    * **Description:** Origin/Destination Airport, City Name\n",
    "    * **Drop**\n",
    "16.\t**OriginState / 25. DestState**\n",
    "    * **Description:** Origin/Destination Airport, State Code\n",
    "    * **Drop**\n",
    "17.\t**OriginStateFips / 26. DestStateFips**\n",
    "    * **Description:** Origin/Destination Airport, State Fips\n",
    "    * **Drop**\n",
    "18.\t**OriginStateName / 27. DestStateName**\n",
    "    * **Description:** Origin/Destination Airport, State Name\n",
    "    * **Drop**\n",
    "19.\t**OriginWac / 28. DestWac**\n",
    "    * **Description:** Origin/Destination Airport, World Area Code\n",
    "    * **Drop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_2014_1.loc[:, 'OriginAirportID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_2014_1.loc[:, 'DestAirportID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_2014_1.loc[:, 'Origin'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_2014_1.loc[:, 'Dest'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for equal number of Origin Airport IDs and Origin (IATA codes)\n",
    "print('Number of unique OriginAirport IDs:', flights_2014_1.loc[:, 'OriginAirportID'].nunique(),\n",
    "      '\\nNumber of unique Origin codes:', flights_2014_1.loc[:, 'Origin'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for equal number of Origin Airport IDs and Origin (IATA codes)\n",
    "print('Number of unique DestAirport IDs:', flights_2014_1.loc[:, 'DestAirportID'].nunique(),\n",
    "      '\\nNumber of unique Destination codes:', flights_2014_1.loc[:, 'Dest'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NA-values in the fields, I suppose to keep\n",
    "flights_2014_1[['OriginAirportID', 'Origin', 'DestAirportID', 'Dest']].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numbers of unique code for OriginalAirportID/DestAirportID and Origin/Dest are equal, and they don't have NA-values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Departure and Arrival times (scheduled and actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample of the block of data for departure times\n",
    "DepFields = ['CRSDepTime', \n",
    "             'DepTime',\n",
    "             'DepDelay',\n",
    "             'DepDelayMinutes',\n",
    "             'DepDel15',\n",
    "             'DepartureDelayGroups',\n",
    "             'DepTimeBlk']\n",
    "flights_2014_1.loc[:5, DepFields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample of the block of data for arrival times\n",
    "ArrFields = ['CRSArrTime', \n",
    "             'ArrTime',\n",
    "             'ArrDelay',\n",
    "             'ArrDelayMinutes',\n",
    "             'ArrDel15',\n",
    "             'ArrivalDelayGroups',\n",
    "             'ArrTimeBlk']\n",
    "flights_2014_1.loc[:5, ArrFields]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two groups of data (for Departure and Arrival time) have the same stricture and similar meaning (with difference in departure or arrival), so I group and describe them togethher.\n",
    "\n",
    "All time date in dataset is integer in format HHMM. I think for the further analysis it's worth to convert it into the number of minutes from the start of the day.\n",
    "\n",
    "29.\t**CRSDepTime  40. CRSArrTime** \n",
    "    * **Description:** CRS Departure/Arrival Time (local time: hhmm)\n",
    "    * **Data type:** float\n",
    "    * **Keep**\n",
    "    * **Comment:** CRS (Computer Reservation System) represents the scuduled time for the flight. I decided to keep this data at this stage becuase it's not clear yet which will be the drivers of the future model - time or categorical time blocks, such as DepTimeBlk or ArrTimeBlk. I suppose to make this decision later. Needs to conver to the number of minutes.\n",
    "30.\t**DepTime  41. ArrTime**  \n",
    "    * **Description:** Actual Departure/Arrival Time (local time: hhmm)\n",
    "    * **Data type:** float\n",
    "    * **Keep**\n",
    "    * **Comment:** Needs to conver to the number of minutes.\n",
    "31.\t**DepDelay  42. ArrDelay**  \n",
    "    * **Description:** Difference in minutes between scheduled and actual departure/arrival time. Early departures/arrival show negative numbers.\n",
    "    * **Data type:** float\n",
    "    * **Keep**\n",
    "32.\t**DepDelayMinutes  43. ArrDelayMinutes**\n",
    "    * **Description:** Difference in minutes between scheduled and actual departure/arrival time. Early departures/arrival set to 0.\n",
    "    * **Drop**\n",
    "    * **Comment:** This data dublicates partially the field DepDelay and ArrDelay with only differency that this data doesnt't show the negative values - departures or arrivals earlier\n",
    "33.\t**DepDel15  44. ArrDel15**\n",
    "    * **Description:** Departure/Arrival Delay Indicator, 15 Minutes or More (1=Yes)\n",
    "    * **Drop**\n",
    "    * **Comment:** This field represents a boolean data indicating wheather or not the flight delayed. We have the same, and even more detailed information, in the fields with the delay in minutes\n",
    "34.\t**DepartureDelayGroups  45. ArrivalDelayGroups**\n",
    "    * **Description:** Departure/Arrival Delay intervals, every (15 minutes from <-15 to >180)\n",
    "    * **Data type:** category\n",
    "    * **Keep**\n",
    "    * **Comment:** This categorical data can be useful for prediction model instead of actual delay time. We have to decide and choose it later.\n",
    "35.\t**DepTimeBlk  46. ArrTimeBlk**\n",
    "    * **Description:** CRS Departure Time Block, Hourly Intervals\n",
    "    * **Data type:** category\n",
    "    * **Keep**\n",
    "    * **Comment:** This categorical data probably will be more usefull for the prediction model comparing to the acrual departure or arrival times in minutes. \n",
    "\n",
    "The folllowing data represent some time and duration for processes which I think highly correlated with data described above. I suppose this data (below) doesn't add any value to the prediction model, and I am going to DROP it.  \n",
    "36.\tTaxiOut: Taxi Out Time, in Minutes  \n",
    "37.\tWheelsOff: Wheels Off Time (local time: hhmm)  \n",
    "38.\tWheelsOn: Wheels On Time (local time: hhmm)  \n",
    "39.\tTaxiIn: Taxi In Time, in Minutes  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the fields supposed to be kept for null values and incosistent data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for values of the Departure block fields\n",
    "flights_2014_1.loc[:, DepFields].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for values of the Arrival block fields\n",
    "flights_2014_1.loc[:, ArrFields].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NA-values in the Departure block fields\n",
    "flights_2014_1.loc[:, DepFields].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NA-values in the Arrival block fields\n",
    "flights_2014_1.loc[:, ArrFields].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(flights_2014_1['DepartureDelayGroups'].unique())\n",
    "print(flights_2014_1['ArrivalDelayGroups'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(flights_2014_1['DepTimeBlk'].unique()))\n",
    "print(sorted(flights_2014_1['ArrTimeBlk'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problems to analyse and solve:\n",
    "1. **DepTime** and **ArrTime** contain time values '2400' (at the same time CRS times contain only 2359). I have to convert it into 0h00m of the next day.\n",
    "2. It is needed to convert time into simple number of minutes from the start of the day.\n",
    "3. DepTime has the same number of NA-values as DepDelay, but ArrTime and ArrDelay have number of NA-values different of those from NA-values in DepTime and DepDelay. Reason can be related to cancelled and diverted flights. There is need to check.\n",
    "4. Delay Groups (Arrival and Departure) contain NaN values. Need to investigate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test that all flight wtth NA Departure Time (DepTime) were cancelled\n",
    "print('The Cancelled field has only these values:', flights_2014_1['Cancelled'].unique())\n",
    "print('In this dataset there are', int(flights_2014_1['Cancelled'].sum()), 'cancelled flights in total')\n",
    "print('Among', flights_2014_1.DepTime.isna().sum(), 'flights with NA DepTime there are', \n",
    "      flights_2014_1[flights_2014_1.DepTime.isna()]['Cancelled'].count(),'cancelled flights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok. We see that all NA-values in DepTime field are explained by the flight cancellaiton. \n",
    "However, there is one more interesting thing: the total number of cancelled flight is higher than the number of NA-values in DepTime field. Does it mean that these flight were cancelled but still have departure time? Let's take a look at this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many Cancelled and Diverted flight are there in total?\n",
    "flights_2014_1[['Cancelled', 'Diverted']].agg('sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is a split of flights with/NA Departure Time vs. Cancelled and Diverted flights \n",
    "flights_2014_1.groupby(flights_2014_1['DepTime'].isna())[['Cancelled', 'Diverted']].agg('sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check all cancelled flight with existing departure time don't have Time in Air (flight time)\n",
    "departured_cancelled_flights = (~flights_2014_1['DepTime'].isna()) & (flights_2014_1['Cancelled'] == 1)\n",
    "print('Are all flights depatured but cancelled times have NA as AirTime?',\n",
    "      flights_2014_1[departured_cancelled_flights]['AirTime'].isna().all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigating which flights have NA DepartureDelayGroups\n",
    "NA_DepDelay_group = flights_2014_1['DepartureDelayGroups'].isna()\n",
    "print('Number of NA_values in DepartureDelayGoups:', NA_DepDelay_group.sum())\n",
    "\n",
    "cancelled_before_depurture = flights_2014_1['DepTime'].isna() & (flights_2014_1['Cancelled'] == 1)\n",
    "print('Are all cancelled prior departure flights have NA-value in DepartureDelayGroups?',\n",
    "      flights_2014_1[cancelled_before_depurture]['DepartureDelayGroups'].isna().all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Departured flights still could be cancelled after departure (didn't take off, ruturned to gate) OR diverted to a different destination.\n",
    "2. All flight with NA actual Departure Time ('DepTime' field) were canceled and have NA-Value in DepartureDelayGroups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s examine the Arrival times in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is a split of flights with/NA Arrival Time vs. Cancelled and Diverted flights \n",
    "flights_2014_1.groupby(flights_2014_1['ArrTime'].isna())[['Cancelled', 'Diverted']].agg('sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this split it is interesting that some diverted (directed to other airports) flights still have Arrival time. What does this arravel time mean? Is it the arrival time to the Destination airport or the airport where the flight had beed diverted?\n",
    "Le't examine this question using the field 'DivReachedDest' marking the flights reached Destination after being diverted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the numbers from diverted flights' split over w/NA ArrTime \n",
    "diverted_but_arrived = (~flights_2014_1['ArrTime'].isna()) & (flights_2014_1['Diverted'] == 1)\n",
    "print('Number of diverted flights that have ArrTime', \n",
    "      flights_2014_1[diverted_but_arrived]['Flight_Number_Reporting_Airline'].count())\n",
    "print('Number of diverted flights reached initial destination', \n",
    "      flights_2014_1['DivReachedDest'].sum())\n",
    "print('Are all these the same flitghts?',\n",
    "      flights_2014_1[diverted_but_arrived]['DivReachedDest'].sum() == flights_2014_1['DivReachedDest'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, yes, all diverted flights which finally reached their initial destination have the Arrival time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. All flights having an actual Arrival Time ('ArrTime') split over flied directly from Origin to Destination OR were diverted but finally reached the Destination\n",
    "2. All flights with NA ArrTime were wheather canceled or diverted and landed in different Destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigating which flights have NA ArrivalDelayGroups\n",
    "NA_ArrivalDelay_groups = flights_2014_1['ArrivalDelayGroups'].isna()\n",
    "flight_cancelled_OR_diverted = (flights_2014_1['Cancelled'] == 1) | (flights_2014_1['Diverted'] == 1)\n",
    "print('The number of flight with NA-value in ArrivalDelayGroups', NA_ArrivalDelay_groups.sum())\n",
    "print('Are all flights with NA-value ArrivalDelayGroups were canceled or diverted?',\n",
    "      flights_2014_1[NA_ArrivalDelay_groups & flight_cancelled_OR_diverted]['Flight_Number_Reporting_Airline'].count() ==\n",
    "      flights_2014_1[NA_ArrivalDelay_groups]['Flight_Number_Reporting_Airline'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All Diverted or Cancelled flights have NA-value ArrivalDelayGroup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flight Status and Reasons for Delay  \n",
    "\n",
    "I’m going to keep the following fields because they contain information that can be useful for interpreting the departure and arrival time fields and for calculating the actual elapsed time, respectively:\n",
    "\n",
    "47.\t**Cancelled**\n",
    "    * **Description:** Cancelled Flight Indicator (1=Yes)  \n",
    "    * **Data type:** boolean\n",
    "    * **Keep**\n",
    "\n",
    "48.\t**CancellationCode**\n",
    "    * **Description:** Specifies The Reason For Cancellation\n",
    "    * **Data type:**  category\n",
    "    * **Keep**\n",
    "\n",
    "49.\t**Diverted**\n",
    "    * **Description:** Diverted Flight Indicator (1=Yes)  \n",
    "    * **Data type:** boolean\n",
    "    * **Keep**\n",
    "    \n",
    "\n",
    "Next fileds I suppose to keep to analyse the correclation between these reasons for delay with specific airlines, airport or states:\n",
    "\n",
    "56.\t**CarrierDelay**\n",
    "    * **Description**: Carrier Delay, in Minutes  \n",
    "    * **Data type:** float\n",
    "    * **Keep**\n",
    "\n",
    "57.\t**WeatherDelay**  \n",
    "    * **Description**: Weather Delay, in Minutes  \n",
    "    * **Data type:** float\n",
    "    * **Keep**\n",
    "\n",
    "58.\t**NASDelay** \n",
    "    * **Description**: National Air System Delay, in Minutes  \n",
    "    * **Data type:** float\n",
    "    * **Keep**\n",
    "\n",
    "59.\t**SecurityDelay**  \n",
    "    * **Description**: Security Delay, in Minutes  \n",
    "    * **Data type:** float\n",
    "    * **Keep**\n",
    "\n",
    "60.\t**LateAircraftDelay**\n",
    "    * **Description**: Late Aircraft Delay, in Minutes  \n",
    "    * **Data type:** float\n",
    "    * **Keep**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discovering the values and NA-values\n",
    "flight_status_fields = ['Cancelled',\n",
    "                        'CancellationCode',\n",
    "                        'Diverted']\n",
    "print(flights_2014_1[flight_status_fields].describe())\n",
    "print(flights_2014_1[flight_status_fields].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which values does the Cancellatino Code field have?\n",
    "flights_2014_1['CancellationCode'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examining the presence of Cancellation Codes for all Cancelled flights\n",
    "print(flights_2014_1.groupby(['Cancelled', 'Diverted'])['CancellationCode'].agg('count'))\n",
    "no_cancellation_code = flights_2014_1['CancellationCode'].isna()\n",
    "print('Number of recortds (flights) with absent Cancellation Code but still were cancelled:',\n",
    "      len(flights_2014_1[no_cancellation_code & ('Cancelled' == 0)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The conclusion is that the data represented in the Flight Status and Cancellation Code fields is accurate and comprehensive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elapsed time  \n",
    "\n",
    "The scheduled and actual Elapsed Time data are the primary candidates for the outcome of the proposed prediction model, or at least one of the main components for constructing such a variable. This is why it is important to keep this data. Air Time can also be useful because, as we have already seen, it helps with identifying flights that were cancelled after departure.\n",
    "\n",
    "50.\t***CRSElapsedTime**\n",
    "    * **Description:** CRS Elapsed Time of Flight, in Minutes  \n",
    "    * **Data type:** float\n",
    "    * **Keep**\n",
    "\n",
    "51.\t**ActualElapsedTime**  \n",
    "    * **Description:** Elapsed Time of Flight, in Minutes  \n",
    "    * **Data type:** float\n",
    "    * **Keep**\n",
    "\n",
    "52.\t**AirTime:**  \n",
    "    * **Description:** Flight Time, in Minutes  \n",
    "    * **Data type:** float\n",
    "    * **Keep**\n",
    "\n",
    "\n",
    "The following data can be dropped because it is seemed irrelevand or can be obtaing from another fields:  \n",
    "\n",
    "53.\t**Flights**  \n",
    "    * **Description:** Number of Flights  \n",
    "    * **Drop**  \n",
    "\n",
    "54.\t**Distance**  \n",
    "    * **Description:** Distance between airports (miles)  \n",
    "    * **Drop**  \n",
    "\n",
    "55.\t**DistanceGroup**\n",
    "    * **Description:**  Distance Intervals, every 250 Miles, for Flight Segment  \n",
    "    * **Drop**\n",
    " \n",
    "61.\t**FirstDepTime**  \n",
    "    * **Description:** First Gate Departure Time at Origin Airport  \n",
    "    * **Drop**\n",
    "\n",
    "62.\t**TotalAddGTime**  \n",
    "    * **Description:** Total Ground Time Away from Gate for Gate Return or Cancelled Flight  \n",
    "    * **Drop**\n",
    "\n",
    "63.\t**LongestAddGTime**  \n",
    "    * **Description:** Longest Time Away from Gate for Gate Return or Cancelled Flight  \n",
    "    * **Drop**\n",
    "\n",
    "64.\t**DivAirportLandings**\n",
    "    * **Description:** Number of Diverted Airport Landings  \n",
    "    * **Drop**\n",
    "\n",
    "As we already know, the next fields can be useful in evaluation of an acrual elapsed time when the flight was diverted, so we need to keep them:  \n",
    "\n",
    "65.\t**DivReachedDest**  \n",
    "    * **Description:** Diverted Flight Reaching Scheduled Destination Indicator (1=Yes)  \n",
    "    * **Data type:** boolean\n",
    "    * **Keep**\n",
    "\n",
    "66.\t**DivActualElapsedTime**\n",
    "    * **Description:** Elapsed Time of Diverted Flight Reaching Scheduled Destination, in Minutes. The ActualElapsedTime column remains NULL for all diverted flights.  \n",
    "    * **Data type:** float\n",
    "    * **Keep**\n",
    "\n",
    "67.\t**DivArrDelay**  \n",
    "    * **Description:** Difference in minutes between scheduled and actual arrival time for a diverted flight reaching scheduled destination. The ArrDelay column remains NULL for all diverted flights.  \n",
    "    * **Data Type:** float\n",
    "    * **Keep**\n",
    "\n",
    "The distance beetween the scheduled destination and final diverted airport in miles is unimportant for the purposed model because if the flight landed in different location, it is reasonable for the purpose of model consider this fliaght as not arrived to the distanation.\n",
    "\n",
    "68.\t**DivDistance**\n",
    "    * **Description:** Distance between scheduled destination and final diverted airport (miles). Value will be 0 for diverted flight reaching scheduled destination.  \n",
    "    * **Drop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for possible and NA values for Elapsed time data block\n",
    "elapsed_time_fields = ['CRSElapsedTime',\n",
    "                       'ActualElapsedTime',\n",
    "                       'AirTime']\n",
    "print(flights_2014_1[elapsed_time_fields].describe())\n",
    "print(flights_2014_1[elapsed_time_fields].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for possible and NA values for Diverted flights data block\n",
    "diverted_flights_fields = ['DivReachedDest',\n",
    "                       'DivActualElapsedTime',\n",
    "                       'DivArrDelay']\n",
    "print(flights_2014_1[diverted_flights_fields].describe())\n",
    "print(flights_2014_1[diverted_flights_fields].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another infermation about diverted flights\n",
    "\n",
    "The rest of the dataset contains 5 equal blocks for five airports where the flight can be diverted consiquently. Each block contains:\n",
    "* Diverted Airport Code, Airport ID of Diverted Airport,  \n",
    "* Airport Sequence ID of Diverted Airport,  \n",
    "* Wheels On Time (local time: hhmm) at Diverted Airport Code,  \n",
    "* Total Ground Time Away from Gate at Diverted Airport Code,  \n",
    "* Longest Ground Time Away from Gate at Diverted Airport Code,  \n",
    "* Wheels Off Time (local time: hhmm) at Diverted Airport Code,  \n",
    "* Aircraft Tail Number for Diverted Airport Code\n",
    "\n",
    "All this information is not rellevant to the project. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclustion about data structure and quality:  \n",
    "\n",
    "1. The data needed for the project is selected\n",
    "2. The prpoesd data type for each field is selected\n",
    "3. The quality of the data is good. The data represented in the dataset is comprehesive\n",
    "4. The logic of data for calncelled and diverted flights and consiquencies for actual departure and arrival times, time delays and elapsed times was identified and recorded\n",
    "5. On the data transformaiton stage I have to change data types for selected for the model fields and solve the 'time-2400' problem.\n",
    "6. The calculation of the resulting elapsed time, which I suppose to take as a predicted variable of the model, will be realise further on the stage of features engeneering. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin with one file from 60 files to test the aproach. After testing we will use the same process for the rest of files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data_types = {\n",
    "    'Year':                 np.int16,               \n",
    "    'Quarter':              np.int8,                \n",
    "    'Month':                np.int8,                \n",
    "    'DayofMonth':           np.int8,\n",
    "    'DayOfWeek':            np.int8,\n",
    "    'FlightDate':           'str',\n",
    "    'Reporting_Airline':    'category',\n",
    "    'Flight_Number_Reporting_Airline':  np.int16,\n",
    "    'OriginAirportID':      'category',\n",
    "    'Origin':               'category',\n",
    "    'DestAirportID':        'category',\n",
    "    'Dest':                 'category',\n",
    "    'CRSDepTime':           np.int16,\n",
    "    'DepTime':              np.float32,\n",
    "    'DepDelay':             np.float32,\n",
    "    'DepartureDelayGroups': 'category',\n",
    "    'DepTimeBlk':           'category',\n",
    "    'CRSArrTime':           np.int16,\n",
    "    'ArrTime':              np.float32,\n",
    "    'ArrDelay':             np.float32,\n",
    "    'ArrivalDelayGroups':   'category',\n",
    "    'ArrTimeBlk':           'category',\n",
    "    'Cancelled':            np.int8,        # boolean\n",
    "    'CancellationCode':     'category',\n",
    "    'Diverted':             np.int8,        # boolean\n",
    "    'CarrierDelay':         np.float32,\n",
    "    'WeatherDelay':         np.float32,\n",
    "    'NASDelay':             np.float32,\n",
    "    'SecurityDelay':        np.float32,\n",
    "    'LateAircraftDelay':    np.float32,\n",
    "    'CRSElapsedTime':       np.float32,\n",
    "    'ActualElapsedTime':    np.float32,\n",
    "    'AirTime':              np.float32,\n",
    "    'DivReachedDest':       np.float32,        # boolean\n",
    "    'DivActualElapsedTime': np.float32,\n",
    "    'DivArrDelay':          np.float32,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data_from(zip_file, data_file, field_type=None):\n",
    "    # reading the file\n",
    "    with zipfile.ZipFile(zip_file) as zip_source:\n",
    "        with zip_source.open(data_file) as file:\n",
    "            if field_type != None:\n",
    "                df = pd.read_csv(file, header = 0, \n",
    "                                usecols = field_type.keys(),\n",
    "                                dtype = field_type)\n",
    "            else:\n",
    "                df = pd.read_csv(file, header = 0, low_memory=False)\n",
    "\n",
    "    # Converting dates and boolean        \n",
    "    if 'FlightDate' in df.columns:\n",
    "        df['FlightDate'] = pd.to_datetime(df['FlightDate'])\n",
    "    if 'DivReachedDest' in df.columns:\n",
    "        df['DivReachedDest'] = df['DivReachedDest'].fillna(0)\n",
    "    if 'Cancelled' in df.columns:\n",
    "        df['Cancelled'] = df['Cancelled'].astype('bool')\n",
    "    if 'Diverted' in df.columns:\n",
    "        df['Diverted'] = df['Diverted'].astype('bool')\n",
    "    if 'DivReachedDest' in df.columns:\n",
    "        df['DivReachedDest'] = df['DivReachedDest'].astype('bool')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_zip = 'data/interim/csv_flight.zip'\n",
    "source_data = 'csv_flight/report_2014_1.csv'\n",
    "\n",
    "flights_2014_1_new = transform_data_from(source_zip, source_data, data_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 200)\n",
    "flights_2014_1_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_2014_1_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just to see what was the original size of the dataset\n",
    "flights_2014_1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I converted data into new dataset. Elimination of redundant data and changing data types allowed to reduce the memery usage by more than 9 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To free the memory space I'm deliting datasets, used for discovering the data and testing the data transfortation ideas\n",
    "del(flights_2014_1, flights_2014_1_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_zip = 'data/interim/csv_flight.zip'\n",
    "source_path = 'csv_flight/report_'\n",
    "\n",
    "flights = pd.DataFrame()\n",
    "for year in range(2014, 2019):\n",
    "    for month in range(1, 13):\n",
    "        source_data = source_path + str(year) + '_' + str(month) + '.csv'\n",
    "        print(source_data)\n",
    "        flights = pd.concat([flights, transform_data_from(source_zip, source_data, data_types)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(flights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!!!!!!!![TEMP] Check for adequacy of elapsed times\n",
    "flights[elapsed_time_fields].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!!!!!!!![TEMP] Check for adequacy of elapsed times\n",
    "flights[flights['CRSElapsedTime'] <= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!!!!!!!![TEMP] Check for adequacy of elapsed times\n",
    "test = transform_data_from(source_zip, source_path + '2018_2.csv')\n",
    "test[test['CRSElapsedTime'] <=0][DepFields + ArrFields + elapsed_time_fields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!!!!!!!![TEMP] Check for adequacy of elapsed times\n",
    "test = transform_data_from(source_zip, source_path + '2018_10.csv')\n",
    "test[test['CRSElapsedTime'] <=0][DepFields + ArrFields + elapsed_time_fields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important variables, characterising the date and time, the origin and destination of the flight don't have NA values and so we don't need to do something at this stage.\n",
    "\n",
    "The fileds which I suppose to use to engineer the predicted variable (such as delays and arrival times) still have NA-values, but these values are not errors and have some logic behind thev. For example. as we have seen above, the acctual arrival time and delay have NA in case the flight was cancelled. I have to take this into account when I will engineer the predicted variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "bins = np.arange(1, 9) - 0.5\n",
    "plt.hist(flights['DayOfWeek'], bins = bins)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that Saturday has the fewest flights. On other days, the average airports load across the country appears to be similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(1, 14) - 0.5\n",
    "plt.hist(flights['Month'], bins = bins)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The least busy month is February, while the summer months have the highest number of flights with peak in July."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(flights['Year'], bins = [2013.5, 2014.5, 2015.5, 2016.5, 2017.5, 2018.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of flight increased significantly in 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now when we have the whole dataset with more than 30 mln of flights over 5 years period let's chech the data quality again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights[['Year', 'Quarter', 'Month', 'DayofMonth', 'DayOfWeek', 'FlightDate']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All fields related to the date and time of the flights are correct and dont have outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights[['Year', 'Quarter', 'Month', 'DayofMonth', 'DayOfWeek']].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights['Year'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also don't have missed data among data related to the date and time of flight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to correct the actual Departure and Arrival Time fields (‘DepTime’ and ‘ArrTime’) because some entries show a time of 2400, which does not align with the scheduled time format (the maximum time is 2359). These should be adjusted to 00:00 of the next day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!!!!! Delete before sending\n",
    "flights_etalon = flights.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights = flights_etalon.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrction of 2400 time (it works after change of dtype of datetime fields)\n",
    "\n",
    "import datetime\n",
    "time_2400_filter = (flights.ArrTime == 2400) | (flights.DepTime == 2400)\n",
    "print('There were', sum(time_2400_filter), 'rows having 2400 as Departure or Arrival Time')\n",
    "\n",
    "def fix_time_2400(df, field_name):\n",
    "    row_filter = (df[field_name] == 2400)\n",
    "    for ind in df[row_filter].index:\n",
    "        df.loc[ind, 'FlightDate'] += datetime.timedelta(days=1)\n",
    "        df.loc[ind, 'Month'] = df.loc[ind, 'FlightDate'].month\n",
    "        df.loc[ind, 'DayofMonth'] = df.loc[ind, 'FlightDate'].day\n",
    "        df.loc[ind, 'DayOfWeek'] = df.loc[ind, 'FlightDate'].weekday()\n",
    "        df.loc[ind, 'Year'] = df.loc[ind, 'FlightDate'].year\n",
    "        df.loc[ind, field_name] = 0\n",
    "    return df\n",
    "\n",
    "flights = fix_time_2400(flights, 'ArrTime')\n",
    "flights = fix_time_2400(flights, 'DepTime')\n",
    "\n",
    "print('There are now', sum(time_2400_filter), 'rows having 2400 as Departure or Arrival Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_time_format(name):\n",
    "    time_array = np.array(flights[name])\n",
    "    flights[name] = (time_array // 100) * 60 + (time_array % 100)\n",
    "\n",
    "for fld_name in ['ArrTime', 'DepTime', 'CRSArrTime', 'CRSDepTime']:\n",
    "    change_time_format(fld_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('data/processed/processed_flights.pickle', 'wb') as output_file:\n",
    "    pickle.dump(flights, output_file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!!!!!!!![TEMP] Check for adequacy of elapsed times\n",
    "wrong_CRSET_filter = (flights['CRSArrTime'] - flights['CRSDepTime'] - flights['CRSElapsedTime']) != 0\n",
    "a = flights[wrong_CRSET_filter][['CRSDepTime', 'CRSArrTime', 'CRSElapsedTime']]\n",
    "a.CRSArrTime - a.CRSDepTime - a.CRSElapsedTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights[['ArrTime', 'DepTime', 'CRSArrTime', 'CRSDepTime']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights[['ArrTime', 'DepTime', 'CRSArrTime', 'CRSDepTime']].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the scheduled and actual elapsed time becuase I suppose to use them building a predictive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights[['CRSElapsedTime', 'ActualElapsedTime']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of difference between 'ActualElapsedTime' and 'CRSElapsedTime'\n",
    "flights['ElapsedTimeDiff'] = flights['ActualElapsedTime'] - flights['CRSElapsedTime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "rng = np.random.default_rng(18)\n",
    "gauss_distr = rng.normal(flights['ElapsedTimeDiff'].mean(),\n",
    "                        flights['ElapsedTimeDiff'].std(),\n",
    "                        size=1000000)\n",
    "\n",
    "bins = np.arange(-50,50)\n",
    "\n",
    "plt.hist(flights['ElapsedTimeDiff'], bins=bins, density=True)\n",
    "plt.hist(gauss_distr, histtype='step', bins=bins, color='r', density=True)\n",
    "plt.xlim(-50,50)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean difference between scheduled and actual time', round(flights['ElapsedTimeDiff'].mean(), 2))\n",
    "print('Standard deviation of the difference', round(flights['ElapsedTimeDiff'].std(), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The diffence between acheduled and actual elapsed time is not normally distribute (despite being very close), In average the actual elapsed time less than the scheduled (-4.73 min). However, this is the duration of the flight and not a arrival time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is interesting to examine the most negative values of the difference between scheduled and actual elapsed time: how shorter the actual duration of flight can be against its scheduled duration?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights['ElapsedTimeDiff'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting!!!! Some flights lasted 250 minutes less than they were scheduled!!! Is it possiblethat these data can be wrong?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many flights have an elapsed time difference that is an outlier in the range?\n",
    "To answer this question let's first calculate the relative difference of elapsed time, because on long distanced the absolute difference in minutes can be higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the relative difference of elapsed time\n",
    "flights['RelElapTimeDiff'] = flights['ElapsedTimeDiff'] / flights['CRSElapsedTime']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean relative difference between scheduled and actual time (%)', round(flights['RelElapTimeDiff'].mean() * 100, 2))\n",
    "print('Standard deviation of the relative difference (%)', round(flights['RelElapTimeDiff'].std() * 100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(18)\n",
    "gauss_distr = rng.normal(flights['RelElapTimeDiff'].mean(),\n",
    "                        flights['RelElapTimeDiff'].std(),\n",
    "                        size=1000000)\n",
    "\n",
    "bins = np.arange(-1, 1, 0.01)\n",
    "\n",
    "plt.hist(flights['RelElapTimeDiff'], bins=bins, density=True)\n",
    "plt.hist(gauss_distr, histtype='step', bins=bins, color='r', density=True)\n",
    "plt.xlim(-0.5, 0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "q25, q50, q75 = flights['RelElapTimeDiff'].quantile([0.25, 0.5, 0.75])\n",
    "outlier_limit = q25 - (q75 - q25) * 1.5\n",
    "print('All flights with actual elapsed time', round(outlier_limit * 100, 2), 'percents of scheduled elapsed time are deffinitely outliers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights[elapsed_time_fields].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering flights that had actual elapsed time to short relative to scheduled \n",
    "actual_time_less_than_CRRS = flights['RelElapTimeDiff'] < outlier_limit\n",
    "\n",
    "# Printing the TOP-10 fasters flights\n",
    "SuperFastFlights = flights[actual_time_less_than_CRRS]\n",
    "print(SuperFastFlights[['Origin', \n",
    "                        'Dest',\n",
    "                        'ActualElapsedTime', \n",
    "                        'CRSElapsedTime', \n",
    "                        'ElapsedTimeDiff',\n",
    "                        'RelElapTimeDiff']]\n",
    "      .sort_values('RelElapTimeDiff', ascending=True).head(10))\n",
    "\n",
    "# Printing some summary for these flights\n",
    "print('In 2014-2018 there were', \n",
    "      SuperFastFlights['Flight_Number_Reporting_Airline'].count(), \n",
    "      'flight arrived earlier for more than', round(outlier_limit * 100, 2), '% (', \n",
    "      round(SuperFastFlights['Flight_Number_Reporting_Airline'].count() / len(flights) * 100, 2),\n",
    "      '% of total flights)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Details for the flight ind = 21568647 which has the most significant difference between scheduled and actual \n",
    "# elapsed times\n",
    "data_details = ['Year', 'Quarter', 'Month', 'DayofMonth', 'DayOfWeek', 'FlightDate']\n",
    "route_details = ['Origin', 'Dest']\n",
    "DepArr_details = ['CRSDepTime', 'CRSArrTime', 'DepTime', 'ArrTime']\n",
    "\n",
    "print(flights.iloc[28530440][data_details + route_details + DepArr_details + elapsed_time_fields])\n",
    "print('Flight number:', flights.iloc[28530440]['Flight_Number_Reporting_Airline'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems strange that this flight was scheduled with 302 min of elapsed time (more then 5 hours!!!), because according to Google [search](https://www.google.com/maps/dir/SBP,+Airport+Drive,+San+Luis+Obispo,+CA,+USA/San+Francisco+International+Airport+(SFO),+San+Francisco,+CA,+USA/@36.4210897,-122.8306609,8z/data=!3m1!4b1!4m14!4m13!1m5!1m1!1s0x80ecf6bf3876b9f1:0xf486acd07a0f3bd2!2m2!1d-120.6420121!2d35.2375699!1m5!1m1!1s0x808f778c55555555:0xa4f25c571acded3f!2m2!1d-122.3816274!2d37.6191145!3e4?entry=ttu&g_ep=EgoyMDI0MTAwMi4xIKXMDSoASAFQAw%3D%3D) shows that these airports are quite close to each other and estimated the direct flight time as 1h 5min, which is more close to the acctual elapsed time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Details for the flight ind = 26994453 which has the second most significant difference between scheduled and actual \n",
    "# elapsed times\n",
    "print(flights.iloc[21568647][data_details + route_details + DepArr_details + elapsed_time_fields])\n",
    "print('Flight number:', flights.iloc[21568647]['Flight_Number_Reporting_Airline'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second most differing flight has the same story: Google [search](https://www.google.com/maps/dir/LaGuardia+Airport+(LGA),+East+Elmhurst,+NY,+USA/Dallas+Fort+Worth+International+Airport+(DFW),+2400+Aviation+Dr,+Dallas,+TX+75261,+United+States/@36.3681193,-96.0279203,5z/data=!3m1!4b1!4m14!4m13!1m5!1m1!1s0x89c25f8983424db5:0x772fc4660e9666b3!2m2!1d-73.8742467!2d40.7766422!1m5!1m1!1s0x864c2a660d222aa7:0x73323f5e067d201c!2m2!1d-97.0335765!2d32.8990434!3e4?entry=ttu&g_ep=EgoyMDI0MTAwMi4xIKXMDSoASAFQAw%3D%3D) shows the estimated time of the direct flight 3h 40m which again closer to the actual elapsed time and far away from scheduled 431 min - more than 7h!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load source file for accessing some detailes that were deleted in the result dataset\n",
    "_fl = transform_data_from(source_zip, source_path + '2017_10.csv')\n",
    "\n",
    "# tiltering the flight of interest \n",
    "ind = _fl[(_fl['Flight_Number_Reporting_Airline'] == 5028) \n",
    "    & (_fl['DayofMonth'] == 9) \n",
    "    & (_fl['Origin'] == 'SBP')\n",
    "    & (_fl['Dest'] == 'SFO')].index\n",
    "flight_top1 = _fl.iloc[*ind]\n",
    "\n",
    "# Printing results \n",
    "pd.set_option('display.max_rows', 115)\n",
    "print(_fl.iloc[*ind][:70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load source file for accessing some detailes that were deleted in the result dataset\n",
    "_fl = transform_data_from(source_zip, source_path + '2018_7.csv')\n",
    "\n",
    "# tiltering the flight of interest \n",
    "ind = _fl[(_fl['Flight_Number_Reporting_Airline'] == 5935) \n",
    "    & (_fl['DayofMonth'] == 25) \n",
    "    & (_fl['Origin'] == 'DFW')\n",
    "    & (_fl['Dest'] == 'LGA')].index\n",
    "flight_top2 = _fl.iloc[*ind]\n",
    "\n",
    "# Printing results \n",
    "pd.set_option('display.max_rows', 115)\n",
    "print(_fl.iloc[*ind][:70])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two flight were quite ordinary flights: they were not canceled or diverted, they had just one flight (field 'Fligths'), and as we know from Google search above their actual elapsed time seems reasonable but their GRSElapsedTime doesn't. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Could the CRS Elapsed Time have been calculated incorrectly due to timezone differences?\n",
    "Let's check it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!!!!![TEMP][LOAD]\n",
    "# !!!!!!!!!!!!!!!!!!\n",
    "# !!!!!!!!!!!!!!!!!!\n",
    "# !!!!!!!!!!!!!!!!!!\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "os.chdir('/Users/a.kholodov/Documents/02. Personal/20. Education/50. Universities/Springboard/Springboard_git/Springboard _repo/CS2-flights-delay-REPO')\n",
    "\n",
    "\n",
    "with open('data/processed/processed_flights.pickle', 'rb') as source_file:\n",
    "    flights = pickle.load(source_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta, timezone\n",
    "from dateutil import tz\n",
    "\n",
    "# Loading timezones for IATA codes of airports\n",
    "IATAtz_df = pd.read_csv('https://raw.githubusercontent.com/hroptatyr/dateutils/tzmaps/iata.tzmap', \n",
    "                        sep = '\\t', \n",
    "                        index_col=0, \n",
    "                        header=None)\n",
    "IATAtz = IATAtz_df.to_dict('dict')[1]\n",
    "\n",
    "# Adding timezone to the local time\n",
    "def airport_time_tz(dt, IATA_code: str):\n",
    "    return dt.replace(tzinfo=tz.gettz(IATAtz[IATA_code]))\n",
    "\n",
    "# Converting timezone time to UTC\n",
    "def airport_time_UTC(dt, IATA_code: str):\n",
    "    return dt.replace(tzinfo=tz.gettz(IATAtz[IATA_code])).astimezone(tz.UTC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 372 unique airport in the dataset (both in Origin and Destination)\n"
     ]
    }
   ],
   "source": [
    "airports_IATACodes = set(flights['Dest'].unique())\n",
    "airports_IATACodes = airports_IATACodes.union(set(flights['Origin']))\n",
    "print('There are', len(airports_IATACodes), 'unique airport in the dataset (both in Origin and Destination)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ap_code for ap_code in airports_IATACodes if ap_code not in IATAtz.keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All airports are present in our IATA timezones dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The fastest flight - TOP1\n",
    "def time_chech(list_of_flights):\n",
    "    for a in list_of_flights:\n",
    "        CRSDepTime = datetime(a.Year, a.Month, a.DayofMonth, a.CRSDepTime // 100, a.CRSDepTime % 100)\n",
    "        CRSArrTime = datetime(a.Year, a.Month, a.DayofMonth, a.CRSArrTime // 100, a.CRSArrTime % 100)\n",
    "\n",
    "        print('Flight #', a.Flight_Number_Reporting_Airline)\n",
    "        print('CRS: ')\n",
    "        print(a.Origin, '\\nTime zone: ', tz.gettz(IATAtz[a.Origin]))\n",
    "        print('Local departure time:      ', CRSDepTime)\n",
    "        print('Local departure time (tz): ', airport_time_tz(CRSDepTime, a.Origin))\n",
    "        print('UTC Departure time:        ', airport_time_UTC(CRSDepTime, a.Origin))\n",
    "        print('')\n",
    "        print(a.Dest, '\\nTime zone: ', tz.gettz(IATAtz[a.Dest]))\n",
    "        print('Local departure time:      ', CRSArrTime)\n",
    "        print('Local departure time (tz): ', airport_time_tz(CRSArrTime, a.Dest))\n",
    "        print('UTC Departure time:        ', airport_time_UTC(CRSArrTime, a.Dest))\n",
    "        print('')\n",
    "        print('Elapsed time (CRS):', round(a.CRSElapsedTime / 60, 2))\n",
    "        print('Elapsed time (UTC):', round((airport_time_UTC(CRSArrTime, a.Dest) - airport_time_UTC(CRSDepTime, a.Origin)).seconds / 3600, 2))\n",
    "        print('\\n')\n",
    "\n",
    "time_chech([flight_top1, flight_top2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can wee there is no error due to incorrect calculatinb elapsed time for different timezones of Origin and Destination. \n",
    "Let's check all outliers flights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, we see that the data for the flight wiht the earliest arrival is correct. \n",
    "Let's check correctness of Elapsed times for the sample of 1000 flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of not cancelled or diverted flights 29588947\n"
     ]
    }
   ],
   "source": [
    "# Check for correctness of CRS ET (elapsed times) for all records (rows)\n",
    "from datetime import datetime\n",
    "\n",
    "# filtering only flights that were not cancelled or diverted\n",
    "not_canceled_or_diverted = (flights['Cancelled'] != 1) & (flights['Diverted'] != 1)\n",
    "ordinary_flights = flights[not_canceled_or_diverted]\n",
    "print('Number of not cancelled or diverted flights', len(ordinary_flights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(flights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename 'DayofMonth' to 'Day' for pd.to_datetime\n",
    "ordinary_flights = ordinary_flights.rename(columns= {'DayofMonth': 'Day'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create temporary field 'Minute' from 'CRSDepTime' to use with pd.to_datetime\n",
    "ordinary_flights['Minute'] = ordinary_flights['CRSDepTime']\n",
    "ordinary_flights['CRSDepDT'] = pd.to_datetime(ordinary_flights[['Year', 'Month', 'Day', 'Minute']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinary_flights['CRSDepDT'] = [row.CRSDepDT.tz_localize(tz.gettz(IATAtz[row.Origin]), ambiguous=True).\n",
    "                                astimezone(tz.UTC) for row in ordinary_flights[['CRSDepDT', 'Origin']].itertuples()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temporary field 'Minute' from 'CRSArrTime' to use with pd.to_datetime\n",
    "ordinary_flights['Minute'] = ordinary_flights['CRSArrTime']\n",
    "ordinary_flights['CRSArrDT'] = pd.to_datetime(ordinary_flights[['Year', 'Month', 'Day', 'Minute']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinary_flights['CRSArrDT'] = [row.CRSArrDT.tz_localize(tz.gettz(IATAtz[row.Dest]), ambiguous=True, \n",
    "                                                         nonexistent = 'NaT') #.astimezone(tz.UTC) \n",
    "                                for row in ordinary_flights[['CRSArrDT', 'Dest']].itertuples()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 41 flights with wrong spring DST\n"
     ]
    }
   ],
   "source": [
    "wrong_DST_filter = ordinary_flights['CRSArrDT'].isna()\n",
    "print('There are', wrong_DST_filter.sum(), 'flights with wrong spring DST')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, there are 41 flight with wrong spring DST time. I have saved them for future possible analysis. Let's try shift all incorrect flights forward, convert them to UTC and after that check the difference of scheduled and actual Elapsed time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At first, restore the 'CRSArrDT'\n",
    "ordinary_flights['Minute'] = ordinary_flights['CRSArrTime']\n",
    "ordinary_flights['CRSArrDT'] = pd.to_datetime(ordinary_flights[['Year', 'Month', 'Day', 'Minute']])\n",
    "\n",
    "# Taking only the flights with incorrect DST\n",
    "flights_with_wrong_DST = ordinary_flights[wrong_DST_filter].copy()\n",
    "\n",
    "# Shifting forward and converting to UTC\n",
    "flights_with_wrong_DST['CRSArrDT'] = [row.CRSArrDT.tz_localize(tz.gettz(IATAtz[row.Dest]), ambiguous=True, \n",
    "                                                         nonexistent = 'shift_forward').astimezone(tz.UTC) \n",
    "                                for row in flights_with_wrong_DST[['CRSArrDT', 'Dest']].itertuples()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flight_Number_Reporting_Airline</th>\n",
       "      <th>CRSDepTime</th>\n",
       "      <th>CRSArrTime</th>\n",
       "      <th>CRSDepDT</th>\n",
       "      <th>CRSArrDT</th>\n",
       "      <th>CRSElapsedTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>988959</th>\n",
       "      <td>121</td>\n",
       "      <td>1430</td>\n",
       "      <td>142</td>\n",
       "      <td>2014-03-10 06:50:00+00:00</td>\n",
       "      <td>2014-03-09 12:00:00+00:00</td>\n",
       "      <td>212.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310801</th>\n",
       "      <td>414</td>\n",
       "      <td>1295</td>\n",
       "      <td>120</td>\n",
       "      <td>2014-03-10 04:35:00+00:00</td>\n",
       "      <td>2014-03-09 08:00:00+00:00</td>\n",
       "      <td>145.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6874992</th>\n",
       "      <td>121</td>\n",
       "      <td>1435</td>\n",
       "      <td>147</td>\n",
       "      <td>2015-03-09 06:55:00+00:00</td>\n",
       "      <td>2015-03-08 12:00:00+00:00</td>\n",
       "      <td>212.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6874996</th>\n",
       "      <td>127</td>\n",
       "      <td>1410</td>\n",
       "      <td>128</td>\n",
       "      <td>2015-03-09 06:30:00+00:00</td>\n",
       "      <td>2015-03-08 12:00:00+00:00</td>\n",
       "      <td>218.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7186735</th>\n",
       "      <td>855</td>\n",
       "      <td>1305</td>\n",
       "      <td>129</td>\n",
       "      <td>2015-03-09 04:45:00+00:00</td>\n",
       "      <td>2015-03-08 08:00:00+00:00</td>\n",
       "      <td>144.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12650587</th>\n",
       "      <td>1248</td>\n",
       "      <td>1423</td>\n",
       "      <td>174</td>\n",
       "      <td>2016-03-14 04:43:00+00:00</td>\n",
       "      <td>2016-03-13 07:00:00+00:00</td>\n",
       "      <td>131.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12667064</th>\n",
       "      <td>2394</td>\n",
       "      <td>1420</td>\n",
       "      <td>161</td>\n",
       "      <td>2016-03-14 04:40:00+00:00</td>\n",
       "      <td>2016-03-13 07:00:00+00:00</td>\n",
       "      <td>121.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12668617</th>\n",
       "      <td>2490</td>\n",
       "      <td>1429</td>\n",
       "      <td>133</td>\n",
       "      <td>2016-03-14 03:49:00+00:00</td>\n",
       "      <td>2016-03-13 08:00:00+00:00</td>\n",
       "      <td>204.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12670641</th>\n",
       "      <td>2724</td>\n",
       "      <td>1435</td>\n",
       "      <td>126</td>\n",
       "      <td>2016-03-14 04:55:00+00:00</td>\n",
       "      <td>2016-03-13 10:00:00+00:00</td>\n",
       "      <td>251.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12670665</th>\n",
       "      <td>2727</td>\n",
       "      <td>1430</td>\n",
       "      <td>132</td>\n",
       "      <td>2016-03-14 04:50:00+00:00</td>\n",
       "      <td>2016-03-13 08:00:00+00:00</td>\n",
       "      <td>142.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Flight_Number_Reporting_Airline  CRSDepTime  CRSArrTime  \\\n",
       "988959                                121        1430         142   \n",
       "1310801                               414        1295         120   \n",
       "6874992                               121        1435         147   \n",
       "6874996                               127        1410         128   \n",
       "7186735                               855        1305         129   \n",
       "12650587                             1248        1423         174   \n",
       "12667064                             2394        1420         161   \n",
       "12668617                             2490        1429         133   \n",
       "12670641                             2724        1435         126   \n",
       "12670665                             2727        1430         132   \n",
       "\n",
       "                          CRSDepDT                  CRSArrDT  CRSElapsedTime  \n",
       "988959   2014-03-10 06:50:00+00:00 2014-03-09 12:00:00+00:00           212.0  \n",
       "1310801  2014-03-10 04:35:00+00:00 2014-03-09 08:00:00+00:00           145.0  \n",
       "6874992  2015-03-09 06:55:00+00:00 2015-03-08 12:00:00+00:00           212.0  \n",
       "6874996  2015-03-09 06:30:00+00:00 2015-03-08 12:00:00+00:00           218.0  \n",
       "7186735  2015-03-09 04:45:00+00:00 2015-03-08 08:00:00+00:00           144.0  \n",
       "12650587 2016-03-14 04:43:00+00:00 2016-03-13 07:00:00+00:00           131.0  \n",
       "12667064 2016-03-14 04:40:00+00:00 2016-03-13 07:00:00+00:00           121.0  \n",
       "12668617 2016-03-14 03:49:00+00:00 2016-03-13 08:00:00+00:00           204.0  \n",
       "12670641 2016-03-14 04:55:00+00:00 2016-03-13 10:00:00+00:00           251.0  \n",
       "12670665 2016-03-14 04:50:00+00:00 2016-03-13 08:00:00+00:00           142.0  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights_with_wrong_DST[['Flight_Number_Reporting_Airline', 'CRSDepTime', 'CRSArrTime', 'CRSDepDT', 'CRSArrDT', 'CRSElapsedTime']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "source_zip = 'data/interim/csv_flight.zip'\n",
    "source_path = 'csv_flight/report_'\n",
    "\n",
    "test = transform_data_from(source_zip, source_path + '2014_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>FlightDate</th>\n",
       "      <th>CRSDepTime</th>\n",
       "      <th>CRSArrTime</th>\n",
       "      <th>CRSElapsedTime</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86408</th>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>2014-03-09</td>\n",
       "      <td>2350</td>\n",
       "      <td>222</td>\n",
       "      <td>212.0</td>\n",
       "      <td>SEA</td>\n",
       "      <td>ANC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106306</th>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>2014-03-09</td>\n",
       "      <td>843</td>\n",
       "      <td>1203</td>\n",
       "      <td>200.0</td>\n",
       "      <td>BOS</td>\n",
       "      <td>PBI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264710</th>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>2014-03-09</td>\n",
       "      <td>850</td>\n",
       "      <td>940</td>\n",
       "      <td>50.0</td>\n",
       "      <td>ITO</td>\n",
       "      <td>HNL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464191</th>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>2014-03-09</td>\n",
       "      <td>850</td>\n",
       "      <td>1100</td>\n",
       "      <td>130.0</td>\n",
       "      <td>STL</td>\n",
       "      <td>SAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465257</th>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>2014-03-09</td>\n",
       "      <td>720</td>\n",
       "      <td>825</td>\n",
       "      <td>65.0</td>\n",
       "      <td>MDW</td>\n",
       "      <td>STL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Year  Month  DayofMonth  DayOfWeek FlightDate  CRSDepTime  CRSArrTime  \\\n",
       "86408   2014      3           9          7 2014-03-09        2350         222   \n",
       "106306  2014      3           9          7 2014-03-09         843        1203   \n",
       "264710  2014      3           9          7 2014-03-09         850         940   \n",
       "464191  2014      3           9          7 2014-03-09         850        1100   \n",
       "465257  2014      3           9          7 2014-03-09         720         825   \n",
       "\n",
       "        CRSElapsedTime Origin Dest  \n",
       "86408            212.0    SEA  ANC  \n",
       "106306           200.0    BOS  PBI  \n",
       "264710            50.0    ITO  HNL  \n",
       "464191           130.0    STL  SAT  \n",
       "465257            65.0    MDW  STL  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Date_details = ['Year', 'Month', 'DayofMonth', 'DayOfWeek', 'FlightDate']\n",
    "DepTime_details = ['CRSDepTime', 'DepTime']\n",
    "ArrTime_details = ['CRSArrTime', 'ArrTime']\n",
    "ElapsedTime_details = ['CRSElapsedTime', 'ActualElapsedTime']\n",
    "CRS_details = ['CRSDepTime', 'CRSArrTime', 'CRSElapsedTime']\n",
    "Route_datails = ['Origin', 'Dest']\n",
    "test[(test['Flight_Number_Reporting_Airline'] == 121) & \n",
    "     (test['DayofMonth'] == 9)][Date_details + \n",
    "     CRS_details +\n",
    "     Route_datails]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create temporary field 'Minute' from 'DepTime' to use with pd.to_datetime\n",
    "ordinary_flights['Minute'] = ordinary_flights['DepTime']\n",
    "ordinary_flights['DepDT'] = pd.to_datetime(ordinary_flights[['Year', 'Month', 'Day', 'Minute']])\n",
    "\n",
    "# Create temporary field 'Minute' from 'ArrTime' to use with pd.to_datetime\n",
    "ordinary_flights['Minute'] = ordinary_flights['ArrTime']\n",
    "ordinary_flights['ArrDT'] = pd.to_datetime(ordinary_flights[['Year', 'Month', 'Day', 'Minute']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind in ordinary_flights.index:\n",
    "       ordinary_flights.loc[ind, 'CRSET_Diff'] = round(ordinary_flights.loc[ind, 'CRSElapsedTime'] / 60, 2) - \\\n",
    "                                        round((airport_time_UTC(ordinary_flights.loc[ind, 'CRSArrDT'], ordinary_flights.loc[ind, 'Dest']) - \\\n",
    "                                               airport_time_UTC(ordinary_flights.loc[ind, 'CRSDepDT'], ordinary_flights.loc[ind, 'Origin'])).seconds / 3600, 2)\n",
    "\n",
    "       ordinary_flights.loc[ind, 'ActET_Diff'] = round(ordinary_flights.loc[ind, 'ActualElapsedTime'] / 60, 2) - \\\n",
    "                                        round((airport_time_UTC(ordinary_flights.loc[ind, 'ArrDT'], ordinary_flights.loc[ind, 'Dest']) - \\\n",
    "                                               airport_time_UTC(ordinary_flights.loc[ind, 'DepDT'], ordinary_flights.loc[ind, 'Origin'])).seconds / 3600, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinary_flights[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
