{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection\n",
    "\n",
    "The original dataset, US Domestic Flights Delay Prediction (2013 - 2018) (Source: [Kaggle](https://www.kaggle.com/datasets/gabrielluizone/us-domestic-flights-delay-prediction-2013-2018)), is provided as a zip archive of 1.54 GB. When decompressed, the archive contains 60 files with a total size of 13.6 GB. Each file corresponds to one month of data, starting from January 2014 and ending in December 2018.\n",
    "\n",
    "Steps for collecting and cleaning the data:\n",
    "\n",
    "*\tLoading the first file\n",
    "*\tEvaluating the data’s size and quality\n",
    "*\tDefining the specific data needed for the project\n",
    "*\tDeveloping a process for data organization and cleaning\n",
    "*\tTesting the code on one month’s data file\n",
    "*\tApplying the code to all files\n",
    "*\tAccumulating the complete dataset\n",
    "\n",
    "\n",
    "The archive file (csv_flight.zip) was downloaded and saved locally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the first file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/a.kholodov/Documents/02. Personal/20. Education/50. Universities/Springboard/Springboard_git/Springboard/capstone-two-flights-delay'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import required modules\n",
    "import zipfile\n",
    "import os\n",
    "import pandas as pd\n",
    "os.chdir('/Users/a.kholodov/Documents/02. Personal/20. Education/50. Universities/Springboard/Springboard_git/Springboard/capstone-two-flights-delay')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "BadZipFile",
     "evalue": "File is not a zip file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m data_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcsv_flight/report_2014_1.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# reading the first file to evaluate the data\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m zipfile\u001b[38;5;241m.\u001b[39mZipFile(source_zip_file) \u001b[38;5;28;01mas\u001b[39;00m zip_source:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m zip_source\u001b[38;5;241m.\u001b[39mopen(data_file) \u001b[38;5;28;01mas\u001b[39;00m data_file:\n\u001b[1;32m      7\u001b[0m         flights_2014_1 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(data_file, low_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/01_Education/SpringBoard/anaconda3/lib/python3.12/zipfile/__init__.py:1349\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[1;32m   1347\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1348\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m-> 1349\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_RealGetContents()\n\u001b[1;32m   1350\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m   1351\u001b[0m         \u001b[38;5;66;03m# set the modified flag so central directory gets written\u001b[39;00m\n\u001b[1;32m   1352\u001b[0m         \u001b[38;5;66;03m# even if no files are added to the archive\u001b[39;00m\n\u001b[1;32m   1353\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_didModify \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/01_Education/SpringBoard/anaconda3/lib/python3.12/zipfile/__init__.py:1416\u001b[0m, in \u001b[0;36mZipFile._RealGetContents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadZipFile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile is not a zip file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m endrec:\n\u001b[0;32m-> 1416\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadZipFile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile is not a zip file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebug \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1418\u001b[0m     \u001b[38;5;28mprint\u001b[39m(endrec)\n",
      "\u001b[0;31mBadZipFile\u001b[0m: File is not a zip file"
     ]
    }
   ],
   "source": [
    "\n",
    "source_zip_file = 'data/interim/csv_flight.zip'\n",
    "data_file = 'csv_flight/report_2014_1.csv'\n",
    "\n",
    "# reading the first file to evaluate the data\n",
    "with zipfile.ZipFile(source_zip_file) as zip_source:\n",
    "    with zip_source.open(data_file) as data_file:\n",
    "        flights_2014_1 = pd.read_csv(data_file, low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'flights_2014_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(flights_2014_1\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(flights_2014_1\u001b[38;5;241m.\u001b[39minfo())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'flights_2014_1' is not defined"
     ]
    }
   ],
   "source": [
    "print(flights_2014_1.shape)\n",
    "print(flights_2014_1.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data for one month contains 471,949 rows and 110 columns, with a total memory size of 396 MB. The estimated size of the entire dataset, without reorganization or cleaning, may exceed 23 GB, which could be challenging to process locally. Therefore, one of the goals of data preparation will be to reduce the dataset size without compromising quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data structure and check\n",
    "### Date of the flight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_2014_1.iloc[:,:6].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. **Year**\n",
    "    * **Description:** Year\n",
    "    * **Data type:** int16\n",
    "    * **Keep**\n",
    "    * **Comment:** Despite there is a field FlightData, I decided to keep separat fileds because they can correlate with flights delay\n",
    "\n",
    "1. **Quarter**  \n",
    "    * **Description:** Quarter (1-4)  \n",
    "    * **Data type:** int8\n",
    "    * **Keep**\n",
    "\n",
    "2. **Month**  \n",
    "    * **Description:** Month (1-12)  \n",
    "    * **Data type:** int8\n",
    "    * **Keep**\n",
    "\n",
    "3. **DayofMonth**  \n",
    "    * **Description:** Day of month  \n",
    "    * **Data type:** int8\n",
    "    * **Keep**\n",
    "\n",
    "4. **DayOfWeek**  \n",
    "    * **Description:** Day of week  \n",
    "    * **Data type:** int8\n",
    "    * **Keep**  \n",
    "\n",
    "5. **FlightDate**  \n",
    "    * **Description:** Flight Date (yyyymmdd)\n",
    "    * **Data type:** datetime\n",
    "    * **Keep**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Values check for fields of Date of the flight: the data accurate, there is no outliers or NA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_2014_1.loc[:5, ['Year', 'Quarter', 'Month', 'DayofMonth', 'DayOfWeek', 'FlightDate']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_2014_1.iloc[:,5].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we need to change the data type during the data transformation from current type to the types in the table above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_2014_1.iloc[:,:6].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_2014_1.iloc[:,:6].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Airline's and flight's details "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_2014_1.iloc[:, 6:10].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "6. **Reporting_Airline**\n",
    "    * **Description:**  Unique Carrier Code. When the same code has been used by multiple carriers, a numeric suffix is used for earlier users, for example, PA, PA(1), PA(2). Use this field for analysis across a range of years. \n",
    "    * **Data type:** category \n",
    "    * **Keep**\n",
    "    * **Comment:** I decided to keep this field and drop DOT_ID_Reporting_Airline and IATA_CODE_Reporting_Airline because it is declared as unique and recomended by data provider as such | \n",
    "\n",
    "7. **DOT_ID_Reporting_Airline**\n",
    "    * **Description** An identification number assigned by US DOT to identify a unique airline (carrier). A unique airline (carrier) is defined as one holding and reporting under the same DOT certificate regardless of its Code, Name, or holding company/corporation.\n",
    "    * **Drop**\n",
    "    * **Comment:** Not unique\n",
    "    \n",
    "8. **IATA_CODE_Reporting_Airline**\n",
    "    * **Description:** Code assigned by IATA and commonly used to identify a carrier. As the same code may have been assigned to different carriers over time, the code is not always unique. For analysis, use the Unique Carrier Code.\n",
    "    * **Drop**\n",
    "    * **Comment:** Not unique\n",
    "\n",
    "9. **Tail_Number**\n",
    "    * **Description:** Tail Number\n",
    "    * **Drop**\n",
    "    * **Comment:** Irrelevant to the purposes of the project\n",
    "\n",
    "10. **Flight_Number_Reporting_Airline**\n",
    "    * **Description:** Flight Number\n",
    "    * **Data type:** int16\n",
    "    * **Keep**\n",
    "    * **Comment:** Unique number of the flight at a specific day/time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_2014_1.iloc[:, 6].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_2014_1['Flight_Number_Reporting_Airline'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_2014_1[['Reporting_Airline', 'Flight_Number_Reporting_Airline']].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_2014_1[['Reporting_Airline', 'Flight_Number_Reporting_Airline']].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data in the fields Reporting_Airline and Flight_Number_Reporting_Airline is accurate, there is no outliers or NA, But I need to change the data type during the data transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Origin and Destination detailes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DestFields = ['DestAirportID', \n",
    "                'DestAirportSeqID', \n",
    "                'DestCityMarketID',\n",
    "                'Dest',\n",
    "                'DestCityName',\n",
    "                'DestState',\n",
    "                'DestStateFips',\n",
    "                'DestStateName',\n",
    "                'DestWac']\n",
    "flights_2014_1.loc[:5, DestFields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OriginFields = ['OriginAirportID', \n",
    "                'OriginAirportSeqID', \n",
    "                'OriginCityMarketID',\n",
    "                'Origin',\n",
    "                'OriginCityName',\n",
    "                'OriginState',\n",
    "                'OriginStateFips',\n",
    "                'OriginStateName',\n",
    "                'OriginWac']\n",
    "flights_2014_1.loc[:5, OriginFields]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Origin and Destination data has the same structure so I will treat it the same way.\n",
    "\n",
    "11.\t**OriginAirportID / 20. DestAirportID**  \n",
    "    * **Description:** Origin/Destination Airport, Airport ID. An identification number assigned by US DOT to identify a unique airport. Use this field for airport analysis across a range of years because an airport can change its airport code and airport codes can be reused.  \n",
    "    * **Data type:** category  \n",
    "    * **Keep**  \n",
    "    * **Comment:** I decided to keep these codes because of its uniqueness, assuared by data provider.  \n",
    "    \n",
    "12.\t**OriginAirportSeqID / 21. DestAirportSeqID**  \n",
    "    * **Description:** Origin/Destination Airport, Airport Sequence ID. An identification number assigned by US DOT to identify a unique airport at a given point of time. Airport attributes, such as airport name or coordinates, may change over time.\n",
    "    * **Drop**\n",
    "13.\t**OriginCityMarketID / 22. DestCityMarketID**\n",
    "    * **Description:** Origin/Destination Airport, City Market ID. City Market ID is an identification number assigned by US DOT to identify a city market. Use this field to consolidate airports serving the same city market.\n",
    "    * **Drop**\n",
    "14.\t**Origin / 23. Dest**\n",
    "    * **Description:** Origin/Destination Airport\n",
    "    * **Data type:** category\n",
    "    * **Keep**\n",
    "    * **Comment:** This core is IATA code of the airport, which is represented in most traveling documents. It could be useful in the model.\n",
    "15.\t**OriginCityName / 24. DestCityName**\n",
    "    * **Description:** Origin/Destination Airport, City Name\n",
    "    * **Drop**\n",
    "16.\t**OriginState / 25. DestState**\n",
    "    * **Description:** Origin/Destination Airport, State Code\n",
    "    * **Drop**\n",
    "17.\t**OriginStateFips / 26. DestStateFips**\n",
    "    * **Description:** Origin/Destination Airport, State Fips\n",
    "    * **Drop**\n",
    "18.\t**OriginStateName / 27. DestStateName**\n",
    "    * **Description:** Origin/Destination Airport, State Name\n",
    "    * **Drop**\n",
    "19.\t**OriginWac / 28. DestWac**\n",
    "    * **Description:** Origin/Destination Airport, World Area Code\n",
    "    * **Drop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_2014_1.loc[:, 'OriginAirportID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_2014_1.loc[:, 'DestAirportID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_2014_1.loc[:, 'Origin'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_2014_1.loc[:, 'Dest'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for equal number of Origin Airport IDs and Origin (IATA codes)\n",
    "print('Number of unique OriginAirport IDs:', flights_2014_1.loc[:, 'OriginAirportID'].nunique(),\n",
    "      '\\nNumber of unique Origin codes:', flights_2014_1.loc[:, 'Origin'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for equal number of Origin Airport IDs and Origin (IATA codes)\n",
    "print('Number of unique DestAirport IDs:', flights_2014_1.loc[:, 'DestAirportID'].nunique(),\n",
    "      '\\nNumber of unique Destination codes:', flights_2014_1.loc[:, 'Dest'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NA-values in the fields, I suppose to keep\n",
    "flights_2014_1[['OriginAirportID', 'Origin', 'DestAirportID', 'Dest']].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numbers of unique code for OriginalAirportID/DestAirportID and Origin/Dest are equal, and they don't have NA-values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Departure and Arrival times (scheduled and actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample of the block of data for departure times\n",
    "DepFields = ['CRSDepTime', \n",
    "             'DepTime',\n",
    "             'DepDelay',\n",
    "             'DepDelayMinutes',\n",
    "             'DepDel15',\n",
    "             'DepartureDelayGroups',\n",
    "             'DepTimeBlk']\n",
    "flights_2014_1.loc[:5, DepFields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample of the block of data for arrival times\n",
    "ArrFields = ['CRSArrTime', \n",
    "             'ArrTime',\n",
    "             'ArrDelay',\n",
    "             'ArrDelayMinutes',\n",
    "             'ArrDel15',\n",
    "             'ArrivalDelayGroups',\n",
    "             'ArrTimeBlk']\n",
    "flights_2014_1.loc[:5, ArrFields]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two groups of data (for Departure and Arrival time) have the same stricture and similar meaning (with difference in departure or arrival), so I group and describe them togethher.\n",
    "\n",
    "All time date in dataset is integer in format HHMM. I think for the further analysis it's worth to convert it into the number of minutes from the start of the day.\n",
    "\n",
    "29.\t**CRSDepTime  40. CRSArrTime** \n",
    "    * **Description:** CRS Departure/Arrival Time (local time: hhmm)\n",
    "    * **Data type:** float\n",
    "    * **Keep**\n",
    "    * **Comment:** CRS (Computer Reservation System) represents the scuduled time for the flight. I decided to keep this data at this stage becuase it's not clear yet which will be the drivers of the future model - time or categorical time blocks, such as DepTimeBlk or ArrTimeBlk. I suppose to make this decision later. Needs to conver to the number of minutes.\n",
    "30.\t**DepTime  41. ArrTime**  \n",
    "    * **Description:** Actual Departure/Arrival Time (local time: hhmm)\n",
    "    * **Data type:** float\n",
    "    * **Keep**\n",
    "    * **Comment:** Needs to conver to the number of minutes.\n",
    "31.\t**DepDelay  42. ArrDelay**  \n",
    "    * **Description:** Difference in minutes between scheduled and actual departure/arrival time. Early departures/arrival show negative numbers.\n",
    "    * **Data type:** float\n",
    "    * **Keep**\n",
    "32.\t**DepDelayMinutes  43. ArrDelayMinutes**\n",
    "    * **Description:** Difference in minutes between scheduled and actual departure/arrival time. Early departures/arrival set to 0.\n",
    "    * **Drop**\n",
    "    * **Comment:** This data dublicates partially the field DepDelay and ArrDelay with only differency that this data doesnt't show the negative values - departures or arrivals earlier\n",
    "33.\t**DepDel15  44. ArrDel15**\n",
    "    * **Description:** Departure/Arrival Delay Indicator, 15 Minutes or More (1=Yes)\n",
    "    * **Drop**\n",
    "    * **Comment:** This field represents a boolean data indicating wheather or not the flight delayed. We have the same, and even more detailed information, in the fields with the delay in minutes\n",
    "34.\t**DepartureDelayGroups  45. ArrivalDelayGroups**\n",
    "    * **Description:** Departure/Arrival Delay intervals, every (15 minutes from <-15 to >180)\n",
    "    * **Data type:** category\n",
    "    * **Keep**\n",
    "    * **Comment:** This categorical data can be useful for prediction model instead of actual delay time. We have to decide and choose it later.\n",
    "35.\t**DepTimeBlk  46. ArrTimeBlk**\n",
    "    * **Description:** CRS Departure Time Block, Hourly Intervals\n",
    "    * **Data type:** category\n",
    "    * **Keep**\n",
    "    * **Comment:** This categorical data probably will be more usefull for the prediction model comparing to the acrual departure or arrival times in minutes. \n",
    "\n",
    "The folllowing data represent some time and duration for processes which I think highly correlated with data described above. I suppose this data (below) doesn't add any value to the prediction model, and I am going to DROP it.  \n",
    "36.\tTaxiOut: Taxi Out Time, in Minutes  \n",
    "37.\tWheelsOff: Wheels Off Time (local time: hhmm)  \n",
    "38.\tWheelsOn: Wheels On Time (local time: hhmm)  \n",
    "39.\tTaxiIn: Taxi In Time, in Minutes  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the fields supposed to be kept for null values and incosistent data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for values of the Departure block fields\n",
    "flights_2014_1.loc[:, DepFields].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for values of the Arrival block fields\n",
    "flights_2014_1.loc[:, ArrFields].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NA-values in the Departure block fields\n",
    "flights_2014_1.loc[:, DepFields].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NA-values in the Arrival block fields\n",
    "flights_2014_1.loc[:, ArrFields].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(flights_2014_1['DepartureDelayGroups'].unique())\n",
    "print(flights_2014_1['ArrivalDelayGroups'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(flights_2014_1['DepTimeBlk'].unique()))\n",
    "print(sorted(flights_2014_1['ArrTimeBlk'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problems to analyse and solve:\n",
    "1. **DepTime** and **ArrTime** contain time values '2400' (at the same time CRS times contain only 2359). I have to convert it into 0h00m of the next day.\n",
    "2. It is needed to convert time into simple number of minutes from the start of the day.\n",
    "3. DepTime has the same number of NA-values as DepDelay, but ArrTime and ArrDelay have number of NA-values different of those from NA-values in DepTime and DepDelay. Reason can be related to cancelled and diverted flights. There is need to check.\n",
    "4. Delay Groups (Arrival and Departure) contain NaN values. Need to investigate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test that all flight wtth NA Departure Time (DepTime) were cancelled\n",
    "print('The Cancelled field has only these values:', flights_2014_1['Cancelled'].unique())\n",
    "print('In this dataset there are', int(flights_2014_1['Cancelled'].sum()), 'cancelled flights in total')\n",
    "print('Among', flights_2014_1.DepTime.isna().sum(), 'flights with NA DepTime there are', \n",
    "      flights_2014_1[flights_2014_1.DepTime.isna()]['Cancelled'].count(),'cancelled flights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok. We see that all NA-values in DepTime field are explained by the flight cancellaiton. \n",
    "However, there is one more interesting thing: the total number of cancelled flight is higher than the number of NA-values in DepTime field. Does it mean that these flight were cancelled but still have departure time? Let's take a look at this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many Cancelled and Diverted flight are there in total?\n",
    "flights_2014_1[['Cancelled', 'Diverted']].agg('sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is a split of flights with/NA Departure Time vs. Cancelled and Diverted flights \n",
    "flights_2014_1.groupby(flights_2014_1['DepTime'].isna())[['Cancelled', 'Diverted']].agg('sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check all cancelled flight with existing departure time don't have Time in Air (flight time)\n",
    "departured_cancelled_flights = (~flights_2014_1['DepTime'].isna()) & (flights_2014_1['Cancelled'] == 1)\n",
    "print('Are all flights depatured but cancelled times have NA as AirTime?',\n",
    "      flights_2014_1[departured_cancelled_flights]['AirTime'].isna().all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigating which flights have NA DepartureDelayGroups\n",
    "NA_DepDelay_group = flights_2014_1['DepartureDelayGroups'].isna()\n",
    "print('Number of NA_values in DepartureDelayGoups:', NA_DepDelay_group.sum())\n",
    "\n",
    "cancelled_before_depurture = flights_2014_1['DepTime'].isna() & (flights_2014_1['Cancelled'] == 1)\n",
    "print('Are all cancelled prior departure flights have NA-value in DepartureDelayGroups?',\n",
    "      flights_2014_1[cancelled_before_depurture]['DepartureDelayGroups'].isna().all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Departured flights still could be cancelled after departure (didn't take off, ruturned to gate) OR diverted to a different destination.\n",
    "2. All flight with NA actual Departure Time ('DepTime' field) were canceled and have NA-Value in DepartureDelayGroups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s examine the Arrival times in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is a split of flights with/NA Arrival Time vs. Cancelled and Diverted flights \n",
    "flights_2014_1.groupby(flights_2014_1['ArrTime'].isna())[['Cancelled', 'Diverted']].agg('sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this split it is interesting that some diverted (directed to other airports) flights still have Arrival time. What does this arravel time mean? Is it the arrival time to the Destination airport or the airport where the flight had beed diverted?\n",
    "Le't examine this question using the field 'DivReachedDest' marking the flights reached Destination after being diverted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the numbers from diverted flights' split over w/NA ArrTime \n",
    "diverted_but_arrived = (~flights_2014_1['ArrTime'].isna()) & (flights_2014_1['Diverted'] == 1)\n",
    "print('Number of diverted flights that have ArrTime', \n",
    "      flights_2014_1[diverted_but_arrived]['Flight_Number_Reporting_Airline'].count())\n",
    "print('Number of diverted flights reached initial destination', \n",
    "      flights_2014_1['DivReachedDest'].sum())\n",
    "print('Are all these the same flitghts?',\n",
    "      flights_2014_1[diverted_but_arrived]['DivReachedDest'].sum() == flights_2014_1['DivReachedDest'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, yes, all diverted flights which finally reached their initial destination have the Arrival time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. All flights having an actual Arrival Time ('ArrTime') split over flied directly from Origin to Destination OR were diverted but finally reached the Destination\n",
    "2. All flights with NA ArrTime were wheather canceled or diverted and landed in different Destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigating which flights have NA ArrivalDelayGroups\n",
    "NA_ArrivalDelay_groups = flights_2014_1['ArrivalDelayGroups'].isna()\n",
    "flight_cancelled_OR_diverted = (flights_2014_1['Cancelled'] == 1) | (flights_2014_1['Diverted'] == 1)\n",
    "print('The number of flight with NA-value in ArrivalDelayGroups', NA_ArrivalDelay_groups.sum())\n",
    "print('Are all flights with NA-value ArrivalDelayGroups were canceled or diverted?',\n",
    "      flights_2014_1[NA_ArrivalDelay_groups & flight_cancelled_OR_diverted]['Flight_Number_Reporting_Airline'].count() ==\n",
    "      flights_2014_1[NA_ArrivalDelay_groups]['Flight_Number_Reporting_Airline'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All Diverted or Cancelled flights have NA-value ArrivalDelayGroup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flight Status and Reasons for Delay  \n",
    "\n",
    "I’m going to keep the following fields because they contain information that can be useful for interpreting the departure and arrival time fields and for calculating the actual elapsed time, respectively:\n",
    "\n",
    "47.\t**Cancelled**\n",
    "    * **Description:** Cancelled Flight Indicator (1=Yes)  \n",
    "    * **Data type:** boolean\n",
    "    * **Keep**\n",
    "\n",
    "48.\t**CancellationCode**\n",
    "    * **Description:** Specifies The Reason For Cancellation\n",
    "    * **Data type:**  category\n",
    "    * **Keep**\n",
    "\n",
    "49.\t**Diverted**\n",
    "    * **Description:** Diverted Flight Indicator (1=Yes)  \n",
    "    * **Data type:** boolean\n",
    "    * **Keep**\n",
    "    \n",
    "\n",
    "Next fileds I suppose to keep to analyse the correclation between these reasons for delay with specific airlines, airport or states:\n",
    "\n",
    "56.\t**CarrierDelay**\n",
    "    * **Description**: Carrier Delay, in Minutes  \n",
    "    * **Data type:** float\n",
    "    * **Keep**\n",
    "\n",
    "57.\t**WeatherDelay**  \n",
    "    * **Description**: Weather Delay, in Minutes  \n",
    "    * **Data type:** float\n",
    "    * **Keep**\n",
    "\n",
    "58.\t**NASDelay** \n",
    "    * **Description**: National Air System Delay, in Minutes  \n",
    "    * **Data type:** float\n",
    "    * **Keep**\n",
    "\n",
    "59.\t**SecurityDelay**  \n",
    "    * **Description**: Security Delay, in Minutes  \n",
    "    * **Data type:** float\n",
    "    * **Keep**\n",
    "\n",
    "60.\t**LateAircraftDelay**\n",
    "    * **Description**: Late Aircraft Delay, in Minutes  \n",
    "    * **Data type:** float\n",
    "    * **Keep**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discovering the values and NA-values\n",
    "flight_status_fields = ['Cancelled',\n",
    "                        'CancellationCode',\n",
    "                        'Diverted']\n",
    "print(flights_2014_1[flight_status_fields].describe())\n",
    "print(flights_2014_1[flight_status_fields].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which values does the Cancellatino Code field have?\n",
    "flights_2014_1['CancellationCode'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examining the presence of Cancellation Codes for all Cancelled flights\n",
    "print(flights_2014_1.groupby(['Cancelled', 'Diverted'])['CancellationCode'].agg('count'))\n",
    "no_cancellation_code = flights_2014_1['CancellationCode'].isna()\n",
    "print('Number of recortds (flights) with absent Cancellation Code but still were cancelled:',\n",
    "      len(flights_2014_1[no_cancellation_code & ('Cancelled' == 0)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The conclusion is that the data represented in the Flight Status and Cancellation Code fields is accurate and comprehensive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elapsed time  \n",
    "\n",
    "The scheduled and actual Elapsed Time data are the primary candidates for the outcome of the proposed prediction model, or at least one of the main components for constructing such a variable. This is why it is important to keep this data. Air Time can also be useful because, as we have already seen, it helps with identifying flights that were cancelled after departure.\n",
    "\n",
    "50.\t***CRSElapsedTime**\n",
    "    * **Description:** CRS Elapsed Time of Flight, in Minutes  \n",
    "    * **Data type:** float\n",
    "    * **Keep**\n",
    "\n",
    "51.\t**ActualElapsedTime**  \n",
    "    * **Description:** Elapsed Time of Flight, in Minutes  \n",
    "    * **Data type:** float\n",
    "    * **Keep**\n",
    "\n",
    "52.\t**AirTime:**  \n",
    "    * **Description:** Flight Time, in Minutes  \n",
    "    * **Data type:** float\n",
    "    * **Keep**\n",
    "\n",
    "\n",
    "The following data can be dropped because it is seemed irrelevand or can be obtaing from another fields:  \n",
    "\n",
    "53.\t**Flights**  \n",
    "    * **Description: Number of Flights**  \n",
    "    * **Drop**  \n",
    "\n",
    "54.\t**Distance**  \n",
    "    * **Description:** Distance between airports (miles)  \n",
    "    * **Drop**  \n",
    "\n",
    "55.\t**DistanceGroup**\n",
    "    * **Description:**  Distance Intervals, every 250 Miles, for Flight Segment  \n",
    "    * **Drop**\n",
    " \n",
    "61.\t**FirstDepTime**  \n",
    "    * **Description:** First Gate Departure Time at Origin Airport  \n",
    "    * **Drop**\n",
    "\n",
    "62.\t**TotalAddGTime**  \n",
    "    * **Description:** Total Ground Time Away from Gate for Gate Return or Cancelled Flight  \n",
    "    * **Drop**\n",
    "\n",
    "63.\t**LongestAddGTime**  \n",
    "    * **Description:** Longest Time Away from Gate for Gate Return or Cancelled Flight  \n",
    "    * **Drop**\n",
    "\n",
    "64.\t**DivAirportLandings**\n",
    "    * **Description:** Number of Diverted Airport Landings  \n",
    "    * **Drop**\n",
    "\n",
    "As we already know, the next fields can be useful in evaluation of an acrual elapsed time when the flight was diverted, so we need to keep them:  \n",
    "\n",
    "65.\t**DivReachedDest**  \n",
    "    * **Description:** Diverted Flight Reaching Scheduled Destination Indicator (1=Yes)  \n",
    "    * **Data type:** boolean\n",
    "    * **Keep**\n",
    "\n",
    "66.\t**DivActualElapsedTime**\n",
    "    * **Description:** Elapsed Time of Diverted Flight Reaching Scheduled Destination, in Minutes. The ActualElapsedTime column remains NULL for all diverted flights.  \n",
    "    * **Data type:** float\n",
    "    * **Keep**\n",
    "\n",
    "67.\t**DivArrDelay**  \n",
    "    * **Description:** Difference in minutes between scheduled and actual arrival time for a diverted flight reaching scheduled destination. The ArrDelay column remains NULL for all diverted flights.  \n",
    "    * **Data Type:** float\n",
    "    * **Keep**\n",
    "\n",
    "The distance beetween the scheduled destination and final diverted airport in miles is unimportant for the purposed model because if the flight landed in different location, it is reasonable for the purpose of model consider this fliaght as not arrived to the distanation.\n",
    "\n",
    "68.\t**DivDistance**\n",
    "    * **Description:** Distance between scheduled destination and final diverted airport (miles). Value will be 0 for diverted flight reaching scheduled destination.  \n",
    "    * **Drop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for possible and NA values for Elapsed time data block\n",
    "elapsed_time_fields = ['CRSElapsedTime',\n",
    "                       'ActualElapsedTime',\n",
    "                       'AirTime']\n",
    "print(flights_2014_1[elapsed_time_fields].describe())\n",
    "print(flights_2014_1[elapsed_time_fields].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for possible and NA values for Diverted flights data block\n",
    "diverted_flights_fields = ['DivReachedDest',\n",
    "                       'DivActualElapsedTime',\n",
    "                       'DivArrDelay']\n",
    "print(flights_2014_1[diverted_flights_fields].describe())\n",
    "print(flights_2014_1[diverted_flights_fields].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another infermation about diverted flights\n",
    "\n",
    "The rest of the dataset contains 5 equal blocks for five airports where the flight can be diverted consiquently. Each block contains:\n",
    "* Diverted Airport Code, Airport ID of Diverted Airport,  \n",
    "* Airport Sequence ID of Diverted Airport,  \n",
    "* Wheels On Time (local time: hhmm) at Diverted Airport Code,  \n",
    "* Total Ground Time Away from Gate at Diverted Airport Code,  \n",
    "* Longest Ground Time Away from Gate at Diverted Airport Code,  \n",
    "* Wheels Off Time (local time: hhmm) at Diverted Airport Code,  \n",
    "* Aircraft Tail Number for Diverted Airport Code\n",
    "\n",
    "All this information is not rellevant to the project. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclustion about data structure and quality:  \n",
    "\n",
    "1. The data needed for the project is selected\n",
    "2. The prpoesd data type for each field is selected\n",
    "3. The quality of the data is good. The data represented in the dataset is comprehesive\n",
    "4. The logic of data for calncelled and diverted flights and consiquencies for actual departure and arrival times, time delays and elapsed times was identified and recorded\n",
    "5. On the data transformaiton stage I have to change data types for selected for the model fields and solve the 'time-2400' problem.\n",
    "6. The calculation of the resulting elapsed time, which I suppose to take as a predicted variable of the model, will be realise further on the stage of features engeneering. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin with one file from 60 files to test the aproach. After testing we will use the same process for the rest of files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data_types = {\n",
    "    'Year':                 np.int16,               \n",
    "    'Quarter':              np.int8,                \n",
    "    'Month':                np.int8,                \n",
    "    'DayofMonth':           np.int8,\n",
    "    'DayOfWeek':            np.int8,\n",
    "    'FlightDate':           'str',\n",
    "    'Reporting_Airline':    'category',\n",
    "    'Flight_Number_Reporting_Airline':  np.int16,\n",
    "    'OriginAirportID':      'category',\n",
    "    'Origin':               'category',\n",
    "    'DestAirportID':        'category',\n",
    "    'Dest':                 'category',\n",
    "    'CRSDepTime':           np.int16,\n",
    "    'DepTime':              np.float32,\n",
    "    'DepDelay':             np.float32,\n",
    "    'DepartureDelayGroups': 'category',\n",
    "    'DepTimeBlk':           'category',\n",
    "    'CRSArrTime':           np.int16,\n",
    "    'ArrTime':              np.float32,\n",
    "    'ArrDelay':             np.float32,\n",
    "    'ArrivalDelayGroups':   'category',\n",
    "    'ArrTimeBlk':           'category',\n",
    "    'Cancelled':            np.int8,        # boolean\n",
    "    'CancellationCode':     'category',\n",
    "    'Diverted':             np.int8,        # boolean\n",
    "    'CarrierDelay':         np.float32,\n",
    "    'WeatherDelay':         np.float32,\n",
    "    'NASDelay':             np.float32,\n",
    "    'SecurityDelay':        np.float32,\n",
    "    'LateAircraftDelay':    np.float32,\n",
    "    'CRSElapsedTime':       np.float32,\n",
    "    'ActualElapsedTime':    np.float32,\n",
    "    'AirTime':              np.float32,\n",
    "    'DivReachedDest':       np.float32,        # boolean\n",
    "    'DivActualElapsedTime': np.float32,\n",
    "    'DivArrDelay':          np.float32,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data_from(zip_file, data_file):\n",
    "    # reading the file\n",
    "    with zipfile.ZipFile(zip_file) as zip_source:\n",
    "        with zip_source.open(data_file) as file:\n",
    "            df = pd.read_csv(file, header = 0, \n",
    "                            usecols = data_types.keys(),\n",
    "                            dtype = data_types)\n",
    "\n",
    "    # Converting dates and boolean        \n",
    "    df['FlightDate'] = pd.to_datetime(df['FlightDate'])\n",
    "    df['DivReachedDest'] = df['DivReachedDest'].fillna(0)\n",
    "    df[['Cancelled', 'Diverted', 'DivReachedDest']] = df[['Cancelled', 'Diverted', 'DivReachedDest']].astype('bool')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_zip = 'data/interim/csv_flight.zip'\n",
    "source_data = 'csv_flight/report_2014_1.csv'\n",
    "\n",
    "flights_2014_1_new = transform_data_from(source_zip, source_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 200)\n",
    "flights_2014_1_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_2014_1_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just to see what was the original size of the dataset\n",
    "flights_2014_1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I converted data into new dataset. Elimination of redundant data and changing data types allowed to reduce the memery usage by more than 9 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To free the memory space I'm deliting datasets, used for discovering the data and testing the data transfortation ideas\n",
    "del(flights_2014_1, flights_2014_1_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_zip = 'data/interim/csv_flight.zip'\n",
    "source_path = 'csv_flight/report_'\n",
    "\n",
    "flights = pd.DataFrame()\n",
    "for year in range(2014, 2019):\n",
    "    for month in range(1, 13):\n",
    "        source_data = source_path + str(year) + '_' + str(month) + '.csv'\n",
    "        print(source_data)\n",
    "        flights = pd.concat([flights, transform_data_from(source_zip, source_data)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(flights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important variables, characterising the date and time, the origin and destination of the flight don't have NA values and so we don't need to do something at this stage.\n",
    "\n",
    "The fileds which I suppose to use to engineer the predicted variable (such as delays and arrival times) still have NA-values, but these values are not errors and have some logic behind thev. For example. as we have seen above, the acctual arrival time and delay have NA in case the flight was cancelled. I have to take this into account when I will engineer the predicted variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "bins = np.arange(1, 9) - 0.5\n",
    "plt.hist(flights['DayOfWeek'], bins = bins)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that Saturday has the fewest flights. On other days, the average airports load across the country appears to be similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(1, 14) - 0.5\n",
    "plt.hist(flights['Month'], bins = bins)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The least busy month is February, while the summer months have the highest number of flights with peak in July."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(flights['Year'], bins = [2013.5, 2014.5, 2015.5, 2016.5, 2017.5, 2018.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of flight increased significantly in 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now when we have the whole dataset with more than 30 mln of flights over 5 years period let's chech the data quality again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights[['Year', 'Quarter', 'Month', 'DayofMonth', 'DayOfWeek', 'FlightDate']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All fields related to the date and time of the flights are correct and dont have outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights[['Year', 'Quarter', 'Month', 'DayofMonth', 'DayOfWeek']].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights['Year'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also don't have missed data among data related to the date and time of flight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to correct the actual Departure and Arrival Time fields (‘DepTime’ and ‘ArrTime’) because some entries show a time of 2400, which does not align with the scheduled time format (the maximum time is 2359). These should be adjusted to 00:00 of the next day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_etalon = flights.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrction of 2400 time (it works after change of dtype of datetime fields)\n",
    "\n",
    "import datetime\n",
    "time_2400_filter = (flights.ArrTime == 2400) | (flights.DepTime == 2400)\n",
    "print('There were', sum(time_2400_filter), 'rows having 2400 as Departure or Arrival Time')\n",
    "\n",
    "def fix_time_2400(df, field_name):\n",
    "    row_filter = (df[field_name] == 2400)\n",
    "    for ind in df[row_filter].index:\n",
    "        df.loc[ind, 'FlightDate'] += datetime.timedelta(days=1)\n",
    "        df.loc[ind, 'Month'] = df.loc[ind, 'FlightDate'].month\n",
    "        df.loc[ind, 'DayofMonth'] = df.loc[ind, 'FlightDate'].day\n",
    "        df.loc[ind, 'DayOfWeek'] = df.loc[ind, 'FlightDate'].weekday()\n",
    "        df.loc[ind, 'Year'] = df.loc[ind, 'FlightDate'].year\n",
    "        df.loc[ind, field_name] == 0\n",
    "    return df\n",
    "\n",
    "flights = fix_time_2400(flights, 'ArrTime')\n",
    "flights = fix_time_2400(flights, 'DepTime')\n",
    "\n",
    "print('There are now', sum(time_2400_filter), 'rows having 2400 as Departure or Arrival Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_time_format(name):\n",
    "    time_array = np.array(flights[name])\n",
    "    flights[name] = (time_array // 100) * 60 + (time_array % 100)\n",
    "\n",
    "for fld_name in ['ArrTime', 'DepTime', 'CRSArrTime', 'CRSDepTime']:\n",
    "    change_time_format(fld_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights[['ArrTime', 'DepTime', 'CRSArrTime', 'CRSDepTime']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights[['ArrTime', 'DepTime', 'CRSArrTime', 'CRSDepTime']].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights[['CRSElapsedTime', 'ActualElapsedTime']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of difference between 'ActualElapsedTime' and 'CRSElapsedTime'\n",
    "flights_2014_1['ElapsedTimeDiff'] = flights_2014_1['ActualElapsedTime'] - flights_2014_1['CRSElapsedTime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.histplot(flights_2014_1.ElapsedTimeDiff)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is interesting that there are a lot of negative differencies. Let's take a look how big this negative differencies are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_2014_1.ElapsedTimeDiff.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many flights did arrive more than 30 minutes earlier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_time_less_than_CRRS = flights_2014_1['ElapsedTimeDiff'] < -30\n",
    "print(flights_2014_1[actual_time_less_than_CRRS][['Origin', 'Dest','ActualElapsedTime', 'CRSElapsedTime', 'ElapsedTimeDiff']].sort_values('ElapsedTimeDiff', ascending=True).head(10))\n",
    "print('In January 2014 there were', flights_2014_1[actual_time_less_than_CRRS]['Flight_Number_Reporting_Airline'].count(), \n",
    "      'flight arrived earlier for more than 30 minutes (', \n",
    "      round(flights_2014_1[actual_time_less_than_CRRS]['Flight_Number_Reporting_Airline'].count() / len(flights_2014_1) * 100, 2),\n",
    "      '%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite 1.12% is not segnificant, let's check is the Elapsed time counted correctly, taking into account the difference in timezones of the Origin and Destinion ariports.\n",
    "\n",
    "NOTE: acctually I did this part just for practice, for demonstration and for fun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta, timezone\n",
    "from dateutil import tz\n",
    "\n",
    "# Loading timezones for IATA codes of airports\n",
    "IATAtz_df = pd.read_csv('https://raw.githubusercontent.com/hroptatyr/dateutils/tzmaps/iata.tzmap', \n",
    "                        sep = '\\t', \n",
    "                        index_col=0, \n",
    "                        header=None)\n",
    "IATAtz = IATAtz_df.to_dict('dict')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def airport_time_tz(dt, IATA_code: str):\n",
    "    return dt.replace(tzinfo=tz.gettz(IATAtz[IATA_code]))\n",
    "\n",
    "def airport_time_UTC(dt, IATA_code: str):\n",
    "    return dt.replace(tzinfo=tz.gettz(IATAtz[IATA_code])).astimezone(tz.UTC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = flights_2014_1.iloc[418380]\n",
    "CRSDepTime = datetime(a.Year, a.Month, a.DayofMonth, a.CRSDepTime // 100, a.CRSDepTime % 100)\n",
    "CRSArrTime = datetime(a.Year, a.Month, a.DayofMonth, a.CRSArrTime // 100, a.CRSArrTime % 100)\n",
    "\n",
    "print('CRS: ')\n",
    "print(a.Origin, '\\nTime zone: ', tz.gettz(IATAtz[a.Origin]))\n",
    "print('Local departure time:      ', CRSDepTime)\n",
    "print('Local departure time (tz): ', airport_time_tz(CRSDepTime, a.Origin))\n",
    "print('UTC Departure time:        ', airport_time_UTC(CRSDepTime, a.Origin))\n",
    "print('')\n",
    "print(a.Dest, '\\nTime zone: ', tz.gettz(IATAtz[a.Dest]))\n",
    "print('Local departure time:      ', CRSArrTime)\n",
    "print('Local departure time (tz): ', airport_time_tz(CRSArrTime, a.Dest))\n",
    "print('UTC Departure time:        ', airport_time_UTC(CRSArrTime, a.Dest))\n",
    "print('')\n",
    "print('Elapsed time (CRS):', round(a.CRSElapsedTime / 60, 2))\n",
    "print('Elapsed time (UTC):', round((airport_time_UTC(CRSArrTime, a.Dest) - airport_time_UTC(CRSDepTime, a.Origin)).seconds / 3600, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta, timezone\n",
    "from dateutil import tz\n",
    "\n",
    "a = flights_2014_1.iloc[418380]\n",
    "DepTime = datetime(a.Year, a.Month, a.DayofMonth, int(a.DepTime // 100), int(a.DepTime % 100))\n",
    "ArrTime = datetime(a.Year, a.Month, a.DayofMonth, int(a.ArrTime // 100), int(a.ArrTime % 100))\n",
    "\n",
    "print('Actual: ')\n",
    "print(a.Origin, '\\nTime zone: ', tz.gettz(IATAtz[a.Origin]))\n",
    "print('Local departure time:      ', DepTime)\n",
    "print('Local departure time (tz): ', airport_time_tz(DepTime, a.Origin))\n",
    "print('UTC Departure time:        ', airport_time_UTC(DepTime, a.Origin))\n",
    "print('')\n",
    "print(a.Dest, '\\nTime zone: ', tz.gettz(IATAtz[a.Dest]))\n",
    "print('Local departure time:      ', ArrTime)\n",
    "print('Local departure time (tz): ', airport_time_tz(ArrTime, a.Dest))\n",
    "print('UTC Departure time:        ', airport_time_UTC(ArrTime, a.Dest))\n",
    "print('')\n",
    "print('Elapsed time (Act):', round(a.ActualElapsedTime / 60, 2))\n",
    "print('Elapsed time (UTC):', round((airport_time_UTC(ArrTime, a.Dest) - airport_time_UTC(DepTime, a.Origin)).seconds / 3600, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, we see that the data for the flight wiht the earliest arrival is correct. \n",
    "Let's check correctness of Elapsed times for the sample of 1000 flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "n = 10000\n",
    "\n",
    "for i in random.sample(range(0, len(flights_2014_1)), n):\n",
    "    a = flights_2014_1.iloc[i]\n",
    "    flag = True\n",
    "    if ~a.Cancelled & ~a.Diverted:\n",
    "        CRSDepTime = datetime(a.Year, a.Month, a.DayofMonth, a.CRSDepTime // 100, a.CRSDepTime % 100)\n",
    "        CRSArrTime = datetime(a.Year, a.Month, a.DayofMonth, a.CRSArrTime // 100, a.CRSArrTime % 100)\n",
    "        DepTime = datetime(a.Year, a.Month, a.DayofMonth, int(a.DepTime // 100), int(a.DepTime % 100))\n",
    "        ArrTime = datetime(a.Year, a.Month, a.DayofMonth, int(a.ArrTime // 100), int(a.ArrTime % 100))\n",
    "        CRSElapseTimeDiff = round(a.CRSElapsedTime / 60, 2) - round((airport_time_UTC(CRSArrTime, a.Dest) - airport_time_UTC(CRSDepTime, a.Origin)).seconds / 3600, 2)\n",
    "        ActElapseTimeDiff = round(a.ActualElapsedTime / 60, 2) - round((airport_time_UTC(ArrTime, a.Dest) - airport_time_UTC(DepTime, a.Origin)).seconds / 3600, 2)\n",
    "        if (CRSElapseTimeDiff != 0) | (ActElapseTimeDiff != 0):\n",
    "            print(a.Flight_Number_Reporting_Airline, CRSElapseTimeDiff, ActElapseTimeDiff)\n",
    "            flag = False\n",
    "if flag:\n",
    "    print('For the sample', n, 'flights all elapsed time calculated correctly')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
