{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection\n",
    "\n",
    "The original dataset, US Domestic Flights Delay Prediction (2013 - 2018) (Source: [Kaggle](https://www.kaggle.com/datasets/gabrielluizone/us-domestic-flights-delay-prediction-2013-2018)), is provided as a zip archive of 1.54 GB. When decompressed, the archive contains 60 files with a total size of 13.6 GB. Each file corresponds to one month of data, starting from January 2014 and ending in December 2018.\n",
    "\n",
    "Steps for collecting and cleaning the data:\n",
    "\n",
    "*\tLoading the first file\n",
    "*\tEvaluating the data’s size and quality\n",
    "*\tDefining the specific data needed for the project\n",
    "*\tDeveloping a process for data organization and cleaning\n",
    "*\tTesting the code on one month’s data file\n",
    "*\tApplying the code to all files\n",
    "*\tAccumulating the complete dataset\n",
    "\n",
    "\n",
    "The archive file (csv_flight.zip) was downloaded and saved locally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the first file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime\n",
    "from dateutil import tz\n",
    "from time import time\n",
    "import pickle\n",
    "\n",
    "os.chdir('/Users/a.kholodov/Documents/02. Personal/20. Education/50. Universities/Springboard/Springboard_git/Springboard _repo/CS2-flights-delay-REPO')\n",
    "\n",
    "# pd.set_option('display.max_rows', 130)\n",
    "# pd.set_option('display.width', 200)\n",
    "\n",
    "# Loading timezones for IATA codes of airports\n",
    "IATAtz_df = pd.read_csv('https://raw.githubusercontent.com/hroptatyr/dateutils/tzmaps/iata.tzmap', \n",
    "                        sep = '\\t', \n",
    "                        index_col=0, \n",
    "                        header=None)\n",
    "\n",
    "# Dictionary with IATA codes as keys and timezones as values\n",
    "IATAtz = IATAtz_df.to_dict('dict')[1]\n",
    "del(IATAtz_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_zip_file = 'data/interim/csv_flight.zip'\n",
    "data_file = 'csv_flight/report_2014_1.csv'\n",
    "\n",
    "# reading the first file to evaluate the data\n",
    "with zipfile.ZipFile(source_zip_file) as zip_source:\n",
    "    with zip_source.open(data_file) as data_file:\n",
    "        flights_2014_1 = pd.read_csv(data_file, low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(flights_2014_1.shape)\n",
    "print(flights_2014_1.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data for one month contains 471,949 rows and 110 columns, with a total memory size of 396 MB. The estimated size of the entire dataset, without reorganization or cleaning, may exceed 23 GB, which could be challenging to process locally. Therefore, one of the goals of data preparation will be to reduce the dataset size without compromising quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data structure and check\n",
    "### Date of the flight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_2014_1.iloc[:,:6].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. **Year**\n",
    "    * **Description:** Year\n",
    "    * **Data type:** int16\n",
    "    * **Drop**\n",
    "    * **Comment:** We have a flight date which includes this data\n",
    "\n",
    "1. **Quarter**  \n",
    "    * **Description:** Quarter (1-4)  \n",
    "    * **Data type:** int8\n",
    "    * **Drop**\n",
    "    * **Comment:** We have a flight date which includes this data\n",
    "\n",
    "2. **Month**  \n",
    "    * **Description:** Month (1-12)  \n",
    "    * **Data type:** int8\n",
    "    * **Drop**\n",
    "    * **Comment:** We have a flight date which includes this data\n",
    "\n",
    "3. **DayofMonth**  \n",
    "    * **Description:** Day of month  \n",
    "    * **Data type:** int8\n",
    "    * **Drop**\n",
    "    * **Comment:** We have a flight date which includes this data\n",
    "\n",
    "4. **DayOfWeek**  \n",
    "    * **Description:** Day of week  \n",
    "    * **Data type:** int8\n",
    "    * **Drop**\n",
    "    * **Comment:** We have a flight date which includes this data\n",
    "\n",
    "5. **FlightDate**  \n",
    "    * **Description:** Flight Date (yyyymmdd)\n",
    "    * **Data type:** datetime\n",
    "    * **Keep**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Values check for Date of the flight: the data accurate, there is no outliers or NA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_2014_1['FlightDate'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_2014_1['FlightDate'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we need to change the data type during the data transformation from current type to datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_2014_1['FlightDate'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_2014_1['FlightDate'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Airline's and flight's details "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_2014_1.iloc[:, 6:10].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "6. **Reporting_Airline**\n",
    "    * **Description:**  Unique Carrier Code. When the same code has been used by multiple carriers, a numeric suffix is used for earlier users, for example, PA, PA(1), PA(2). Use this field for analysis across a range of years. \n",
    "    * **Data type:** category \n",
    "    * **Keep**\n",
    "    * **Comment:** I decided to keep this field and drop DOT_ID_Reporting_Airline and IATA_CODE_Reporting_Airline because it is declared as unique and recomended by data provider as such | \n",
    "\n",
    "7. **DOT_ID_Reporting_Airline**\n",
    "    * **Description** An identification number assigned by US DOT to identify a unique airline (carrier). A unique airline (carrier) is defined as one holding and reporting under the same DOT certificate regardless of its Code, Name, or holding company/corporation.\n",
    "    * **Drop**\n",
    "    * **Comment:** Not unique\n",
    "    \n",
    "8. **IATA_CODE_Reporting_Airline**\n",
    "    * **Description:** Code assigned by IATA and commonly used to identify a carrier. As the same code may have been assigned to different carriers over time, the code is not always unique. For analysis, use the Unique Carrier Code.\n",
    "    * **Drop**\n",
    "    * **Comment:** Not unique\n",
    "\n",
    "9. **Tail_Number**\n",
    "    * **Description:** Tail Number\n",
    "    * **Drop**\n",
    "    * **Comment:** Irrelevant to the purposes of the project\n",
    "\n",
    "10. **Flight_Number_Reporting_Airline**\n",
    "    * **Description:** Flight Number\n",
    "    * **Data type:** int16\n",
    "    * **Keep**\n",
    "    * **Comment:** Unique number of the flight at a specific day/time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_2014_1.iloc[:, 6].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_2014_1['Flight_Number_Reporting_Airline'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_2014_1[['Reporting_Airline', 'Flight_Number_Reporting_Airline']].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_2014_1[['Reporting_Airline', 'Flight_Number_Reporting_Airline']].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data in the fields Reporting_Airline and Flight_Number_Reporting_Airline is accurate, there is no outliers or NA, But I need to change the data type during the data transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Origin and Destination detailes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DestFields = ['DestAirportID', \n",
    "                'DestAirportSeqID', \n",
    "                'DestCityMarketID',\n",
    "                'Dest',\n",
    "                'DestCityName',\n",
    "                'DestState',\n",
    "                'DestStateFips',\n",
    "                'DestStateName',\n",
    "                'DestWac']\n",
    "flights_2014_1.loc[:5, DestFields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OriginFields = ['OriginAirportID', \n",
    "                'OriginAirportSeqID', \n",
    "                'OriginCityMarketID',\n",
    "                'Origin',\n",
    "                'OriginCityName',\n",
    "                'OriginState',\n",
    "                'OriginStateFips',\n",
    "                'OriginStateName',\n",
    "                'OriginWac']\n",
    "flights_2014_1.loc[:5, OriginFields]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Origin and Destination data has the same structure so I will treat it the same way.\n",
    "\n",
    "11.\t**OriginAirportID / 20. DestAirportID**  \n",
    "    * **Description:** Origin/Destination Airport, Airport ID. An identification number assigned by US DOT to identify a unique airport. Use this field for airport analysis across a range of years because an airport can change its airport code and airport codes can be reused.  \n",
    "    * **Data type:** category  \n",
    "    * **Keep**  \n",
    "    * **Comment:** I decided to keep these codes because of its uniqueness, assuared by data provider.  \n",
    "    \n",
    "12.\t**OriginAirportSeqID / 21. DestAirportSeqID**  \n",
    "    * **Description:** Origin/Destination Airport, Airport Sequence ID. An identification number assigned by US DOT to identify a unique airport at a given point of time. Airport attributes, such as airport name or coordinates, may change over time.\n",
    "    * **Drop**\n",
    "13.\t**OriginCityMarketID / 22. DestCityMarketID**\n",
    "    * **Description:** Origin/Destination Airport, City Market ID. City Market ID is an identification number assigned by US DOT to identify a city market. Use this field to consolidate airports serving the same city market.\n",
    "    * **Drop**\n",
    "14.\t**Origin / 23. Dest**\n",
    "    * **Description:** Origin/Destination Airport\n",
    "    * **Data type:** category\n",
    "    * **Keep**\n",
    "    * **Comment:** This core is IATA code of the airport, which is represented in most traveling documents. It could be useful in the model.\n",
    "15.\t**OriginCityName / 24. DestCityName**\n",
    "    * **Description:** Origin/Destination Airport, City Name\n",
    "    * **Drop**\n",
    "16.\t**OriginState / 25. DestState**\n",
    "    * **Description:** Origin/Destination Airport, State Code\n",
    "    * **Drop**\n",
    "17.\t**OriginStateFips / 26. DestStateFips**\n",
    "    * **Description:** Origin/Destination Airport, State Fips\n",
    "    * **Drop**\n",
    "18.\t**OriginStateName / 27. DestStateName**\n",
    "    * **Description:** Origin/Destination Airport, State Name\n",
    "    * **Drop**\n",
    "19.\t**OriginWac / 28. DestWac**\n",
    "    * **Description:** Origin/Destination Airport, World Area Code\n",
    "    * **Drop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_2014_1.loc[:, 'OriginAirportID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_2014_1.loc[:, 'DestAirportID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_2014_1.loc[:, 'Origin'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_2014_1.loc[:, 'Dest'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for equal number of Origin Airport IDs and Origin (IATA codes)\n",
    "print('Number of unique OriginAirport IDs:', flights_2014_1.loc[:, 'OriginAirportID'].nunique(),\n",
    "      '\\nNumber of unique Origin codes:', flights_2014_1.loc[:, 'Origin'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for equal number of Origin Airport IDs and Origin (IATA codes)\n",
    "print('Number of unique DestAirport IDs:', flights_2014_1.loc[:, 'DestAirportID'].nunique(),\n",
    "      '\\nNumber of unique Destination codes:', flights_2014_1.loc[:, 'Dest'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NA-values in the fields, I suppose to keep\n",
    "flights_2014_1[['OriginAirportID', 'Origin', 'DestAirportID', 'Dest']].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numbers of unique code for OriginalAirportID/DestAirportID and Origin/Dest are equal, and they don't have NA-values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Departure and Arrival times (scheduled and actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample of the block of data for departure times\n",
    "DepFields = ['CRSDepTime', \n",
    "             'DepTime',\n",
    "             'DepDelay',\n",
    "             'DepDelayMinutes',\n",
    "             'DepDel15',\n",
    "             'DepartureDelayGroups',\n",
    "             'DepTimeBlk']\n",
    "flights_2014_1.loc[:5, DepFields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample of the block of data for arrival times\n",
    "ArrFields = ['CRSArrTime', \n",
    "             'ArrTime',\n",
    "             'ArrDelay',\n",
    "             'ArrDelayMinutes',\n",
    "             'ArrDel15',\n",
    "             'ArrivalDelayGroups',\n",
    "             'ArrTimeBlk']\n",
    "flights_2014_1.loc[:5, ArrFields]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two groups of data (for Departure and Arrival time) have the same stricture and similar meaning (with difference in departure or arrival), so I group and describe them togethher.\n",
    "\n",
    "All time date in dataset is integer in format HHMM. I think for the further analysis it's worth to convert it into the number of minutes from the start of the day.\n",
    "\n",
    "29.\t**CRSDepTime  40. CRSArrTime** \n",
    "    * **Description:** CRS Departure/Arrival Time (local time: hhmm)\n",
    "    * **Data type:** float\n",
    "    * **Keep**\n",
    "    * **Comment:** CRS (Computer Reservation System) represents the scuduled time for the flight. I decided to keep this data at this stage becuase it's not clear yet which will be the drivers of the future model - time or categorical time blocks, such as DepTimeBlk or ArrTimeBlk. I suppose to make this decision later. Needs to conver to the number of minutes.\n",
    "30.\t**DepTime  41. ArrTime**  \n",
    "    * **Description:** Actual Departure/Arrival Time (local time: hhmm)\n",
    "    * **Data type:** float\n",
    "    * **Keep**\n",
    "    * **Comment:** Needs to conver to the number of minutes.\n",
    "31.\t**DepDelay  42. ArrDelay**  \n",
    "    * **Description:** Difference in minutes between scheduled and actual departure/arrival time. Early departures/arrival show negative numbers.\n",
    "    * **Data type:** float\n",
    "    * **Keep**\n",
    "32.\t**DepDelayMinutes  43. ArrDelayMinutes**\n",
    "    * **Description:** Difference in minutes between scheduled and actual departure/arrival time. Early departures/arrival set to 0.\n",
    "    * **Drop**\n",
    "    * **Comment:** This data dublicates partially the field DepDelay and ArrDelay with only differency that this data doesnt't show the negative values - departures or arrivals earlier\n",
    "33.\t**DepDel15  44. ArrDel15**\n",
    "    * **Description:** Departure/Arrival Delay Indicator, 15 Minutes or More (1=Yes)\n",
    "    * **Drop**\n",
    "    * **Comment:** This field represents a boolean data indicating wheather or not the flight delayed. We have the same, and even more detailed information, in the fields with the delay in minutes\n",
    "34.\t**DepartureDelayGroups  45. ArrivalDelayGroups**\n",
    "    * **Description:** Departure/Arrival Delay intervals, every (15 minutes from <-15 to >180)\n",
    "    * **Data type:** category\n",
    "    * **Keep**\n",
    "    * **Comment:** This categorical data can be useful for prediction model instead of actual delay time. We have to decide and choose it later.\n",
    "35.\t**DepTimeBlk  46. ArrTimeBlk**\n",
    "    * **Description:** CRS Departure Time Block, Hourly Intervals\n",
    "    * **Data type:** category\n",
    "    * **Keep**\n",
    "    * **Comment:** This categorical data probably will be more usefull for the prediction model comparing to the acrual departure or arrival times in minutes. \n",
    "\n",
    "The folllowing data represent some time and duration for processes which I think highly correlated with data described above. I suppose this data (below) doesn't add any value to the prediction model, and I am going to DROP it.  \n",
    "36.\tTaxiOut: Taxi Out Time, in Minutes  \n",
    "37.\tWheelsOff: Wheels Off Time (local time: hhmm)  \n",
    "38.\tWheelsOn: Wheels On Time (local time: hhmm)  \n",
    "39.\tTaxiIn: Taxi In Time, in Minutes  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the fields supposed to be kept for null values and incosistent data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for values of the Departure block fields\n",
    "flights_2014_1.loc[:, DepFields].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for values of the Arrival block fields\n",
    "flights_2014_1.loc[:, ArrFields].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NA-values in the Departure block fields\n",
    "flights_2014_1.loc[:, DepFields].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NA-values in the Arrival block fields\n",
    "flights_2014_1.loc[:, ArrFields].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(flights_2014_1['DepartureDelayGroups'].unique())\n",
    "print(flights_2014_1['ArrivalDelayGroups'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(flights_2014_1['DepTimeBlk'].unique()))\n",
    "print(sorted(flights_2014_1['ArrTimeBlk'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problems to analyse and solve:\n",
    "1. **DepTime** and **ArrTime** contain time values '2400' (at the same time CRS times contain only 2359). I have to convert it into 0h00m of the next day.\n",
    "2. It is needed to convert time into simple number of minutes from the start of the day.\n",
    "3. DepTime has the same number of NA-values as DepDelay, but ArrTime and ArrDelay have number of NA-values different of those from NA-values in DepTime and DepDelay. Reason can be related to cancelled and diverted flights. There is need to check.\n",
    "4. Delay Groups (Arrival and Departure) contain NaN values. Need to investigate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test that all flight wtth NA Departure Time (DepTime) were cancelled\n",
    "print('The Cancelled field has only these values:', flights_2014_1['Cancelled'].unique())\n",
    "print('In this dataset there are', int(flights_2014_1['Cancelled'].sum()), 'cancelled flights in total')\n",
    "print('Among', flights_2014_1.DepTime.isna().sum(), 'flights with NA DepTime there are', \n",
    "      flights_2014_1[flights_2014_1.DepTime.isna()]['Cancelled'].count(),'cancelled flights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok. We see that all NA-values in DepTime field are explained by the flight cancellaiton. \n",
    "However, there is one more interesting thing: the total number of cancelled flight is higher than the number of NA-values in DepTime field. Does it mean that these flight were cancelled but still have departure time? Let's take a look at this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many Cancelled and Diverted flight are there in total?\n",
    "flights_2014_1[['Cancelled', 'Diverted']].agg('sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is a split of flights with/NA Departure Time vs. Cancelled and Diverted flights \n",
    "flights_2014_1.groupby(flights_2014_1['DepTime'].isna())[['Cancelled', 'Diverted']].agg('sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check all cancelled flight with existing departure time don't have Time in Air (flight time)\n",
    "departured_cancelled_flights = (~flights_2014_1['DepTime'].isna()) & (flights_2014_1['Cancelled'] == 1)\n",
    "print('Are all flights depatured but cancelled times have NA as AirTime?',\n",
    "      flights_2014_1[departured_cancelled_flights]['AirTime'].isna().all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigating which flights have NA DepartureDelayGroups\n",
    "NA_DepDelay_group = flights_2014_1['DepartureDelayGroups'].isna()\n",
    "print('Number of NA_values in DepartureDelayGoups:', NA_DepDelay_group.sum())\n",
    "\n",
    "cancelled_before_depurture = flights_2014_1['DepTime'].isna() & (flights_2014_1['Cancelled'] == 1)\n",
    "print('Are all cancelled prior departure flights have NA-value in DepartureDelayGroups?',\n",
    "      flights_2014_1[cancelled_before_depurture]['DepartureDelayGroups'].isna().all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Departured flights still could be cancelled after departure (didn't take off, ruturned to gate) OR diverted to a different destination.\n",
    "2. All flight with NA actual Departure Time ('DepTime' field) were canceled and have NA-Value in DepartureDelayGroups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s examine the Arrival times in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is a split of flights with/NA Arrival Time vs. Cancelled and Diverted flights \n",
    "flights_2014_1.groupby(flights_2014_1['ArrTime'].isna())[['Cancelled', 'Diverted']].agg('sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this split it is interesting that some diverted (directed to other airports) flights still have Arrival time. What does this arravel time mean? Is it the arrival time to the Destination airport or the airport where the flight had beed diverted?\n",
    "Le't examine this question using the field 'DivReachedDest' marking the flights reached Destination after being diverted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the numbers from diverted flights' split over w/NA ArrTime \n",
    "diverted_but_arrived = (~flights_2014_1['ArrTime'].isna()) & (flights_2014_1['Diverted'] == 1)\n",
    "print('Number of diverted flights that have ArrTime', \n",
    "      flights_2014_1[diverted_but_arrived]['Flight_Number_Reporting_Airline'].count())\n",
    "print('Number of diverted flights reached initial destination', \n",
    "      flights_2014_1['DivReachedDest'].sum())\n",
    "print('Are all these the same flitghts?',\n",
    "      flights_2014_1[diverted_but_arrived]['DivReachedDest'].sum() == flights_2014_1['DivReachedDest'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, yes, all diverted flights which finally reached their initial destination have the Arrival time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. All flights having an actual Arrival Time ('ArrTime') split over flied directly from Origin to Destination OR were diverted but finally reached the Destination\n",
    "2. All flights with NA ArrTime were wheather canceled or diverted and landed in different Destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigating which flights have NA ArrivalDelayGroups\n",
    "NA_ArrivalDelay_groups = flights_2014_1['ArrivalDelayGroups'].isna()\n",
    "flight_cancelled_OR_diverted = (flights_2014_1['Cancelled'] == 1) | (flights_2014_1['Diverted'] == 1)\n",
    "print('The number of flight with NA-value in ArrivalDelayGroups', NA_ArrivalDelay_groups.sum())\n",
    "print('Are all flights with NA-value ArrivalDelayGroups were canceled or diverted?',\n",
    "      flights_2014_1[NA_ArrivalDelay_groups & flight_cancelled_OR_diverted]['Flight_Number_Reporting_Airline'].count() ==\n",
    "      flights_2014_1[NA_ArrivalDelay_groups]['Flight_Number_Reporting_Airline'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All Diverted or Cancelled flights have NA-value ArrivalDelayGroup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flight Status and Reasons for Delay  \n",
    "\n",
    "I’m going to keep the following fields because they contain information that can be useful for interpreting the departure and arrival time fields and for calculating the actual elapsed time, respectively:\n",
    "\n",
    "47.\t**Cancelled**\n",
    "    * **Description:** Cancelled Flight Indicator (1=Yes)  \n",
    "    * **Data type:** boolean\n",
    "    * **Keep**\n",
    "\n",
    "48.\t**CancellationCode**\n",
    "    * **Description:** Specifies The Reason For Cancellation\n",
    "    * **Data type:**  category\n",
    "    * **Keep**\n",
    "\n",
    "49.\t**Diverted**\n",
    "    * **Description:** Diverted Flight Indicator (1=Yes)  \n",
    "    * **Data type:** boolean\n",
    "    * **Keep**\n",
    "    \n",
    "\n",
    "Next fileds I suppose to keep to analyse the correclation between these reasons for delay with specific airlines, airport or states:\n",
    "\n",
    "56.\t**CarrierDelay**\n",
    "    * **Description**: Carrier Delay, in Minutes  \n",
    "    * **Data type:** float\n",
    "    * **Keep**\n",
    "\n",
    "57.\t**WeatherDelay**  \n",
    "    * **Description**: Weather Delay, in Minutes  \n",
    "    * **Data type:** float\n",
    "    * **Keep**\n",
    "\n",
    "58.\t**NASDelay** \n",
    "    * **Description**: National Air System Delay, in Minutes  \n",
    "    * **Data type:** float\n",
    "    * **Keep**\n",
    "\n",
    "59.\t**SecurityDelay**  \n",
    "    * **Description**: Security Delay, in Minutes  \n",
    "    * **Data type:** float\n",
    "    * **Keep**\n",
    "\n",
    "60.\t**LateAircraftDelay**\n",
    "    * **Description**: Late Aircraft Delay, in Minutes  \n",
    "    * **Data type:** float\n",
    "    * **Keep**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discovering the values and NA-values\n",
    "flight_status_fields = ['Cancelled',\n",
    "                        'CancellationCode',\n",
    "                        'Diverted']\n",
    "print(flights_2014_1[flight_status_fields].describe())\n",
    "print(flights_2014_1[flight_status_fields].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which values does the Cancellatino Code field have?\n",
    "flights_2014_1['CancellationCode'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examining the presence of Cancellation Codes for all Cancelled flights\n",
    "print(flights_2014_1.groupby(['Cancelled', 'Diverted'])['CancellationCode'].agg('count'))\n",
    "no_cancellation_code = flights_2014_1['CancellationCode'].isna()\n",
    "print('Number of recortds (flights) with absent Cancellation Code but still were cancelled:',\n",
    "      len(flights_2014_1[no_cancellation_code & ('Cancelled' == 0)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The conclusion is that the data represented in the Flight Status and Cancellation Code fields is accurate and comprehensive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elapsed time  \n",
    "\n",
    "The scheduled and actual Elapsed Time data are the primary candidates for the outcome of the proposed prediction model, or at least one of the main components for constructing such a variable. This is why it is important to keep this data. Air Time can also be useful because, as we have already seen, it helps with identifying flights that were cancelled after departure.\n",
    "\n",
    "50.\t***CRSElapsedTime**\n",
    "    * **Description:** CRS Elapsed Time of Flight, in Minutes  \n",
    "    * **Data type:** float\n",
    "    * **Keep**\n",
    "\n",
    "51.\t**ActualElapsedTime**  \n",
    "    * **Description:** Elapsed Time of Flight, in Minutes  \n",
    "    * **Data type:** float\n",
    "    * **Keep**\n",
    "\n",
    "52.\t**AirTime:**  \n",
    "    * **Description:** Flight Time, in Minutes  \n",
    "    * **Data type:** float\n",
    "    * **Keep**\n",
    "\n",
    "\n",
    "The following data can be dropped because it is seemed irrelevand or can be obtaing from another fields:  \n",
    "\n",
    "53.\t**Flights**  \n",
    "    * **Description:** Number of Flights  \n",
    "    * **Drop**  \n",
    "\n",
    "54.\t**Distance**  \n",
    "    * **Description:** Distance between airports (miles)  \n",
    "    * **Drop**  \n",
    "\n",
    "55.\t**DistanceGroup**\n",
    "    * **Description:**  Distance Intervals, every 250 Miles, for Flight Segment  \n",
    "    * **Drop**\n",
    " \n",
    "61.\t**FirstDepTime**  \n",
    "    * **Description:** First Gate Departure Time at Origin Airport  \n",
    "    * **Drop**\n",
    "\n",
    "62.\t**TotalAddGTime**  \n",
    "    * **Description:** Total Ground Time Away from Gate for Gate Return or Cancelled Flight  \n",
    "    * **Drop**\n",
    "\n",
    "63.\t**LongestAddGTime**  \n",
    "    * **Description:** Longest Time Away from Gate for Gate Return or Cancelled Flight  \n",
    "    * **Drop**\n",
    "\n",
    "64.\t**DivAirportLandings**\n",
    "    * **Description:** Number of Diverted Airport Landings  \n",
    "    * **Drop**\n",
    "\n",
    "As we already know, the next fields can be useful in evaluation of an acrual elapsed time when the flight was diverted, so we need to keep them:  \n",
    "\n",
    "65.\t**DivReachedDest**  \n",
    "    * **Description:** Diverted Flight Reaching Scheduled Destination Indicator (1=Yes)  \n",
    "    * **Data type:** boolean\n",
    "    * **Keep**\n",
    "\n",
    "66.\t**DivActualElapsedTime**\n",
    "    * **Description:** Elapsed Time of Diverted Flight Reaching Scheduled Destination, in Minutes. The ActualElapsedTime column remains NULL for all diverted flights.  \n",
    "    * **Data type:** float\n",
    "    * **Keep**\n",
    "\n",
    "67.\t**DivArrDelay**  \n",
    "    * **Description:** Difference in minutes between scheduled and actual arrival time for a diverted flight reaching scheduled destination. The ArrDelay column remains NULL for all diverted flights.  \n",
    "    * **Data Type:** float\n",
    "    * **Keep**\n",
    "\n",
    "The distance beetween the scheduled destination and final diverted airport in miles is unimportant for the purposed model because if the flight landed in different location, it is reasonable for the purpose of model consider this fliaght as not arrived to the distanation.\n",
    "\n",
    "68.\t**DivDistance**\n",
    "    * **Description:** Distance between scheduled destination and final diverted airport (miles). Value will be 0 for diverted flight reaching scheduled destination.  \n",
    "    * **Drop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for possible and NA values for Elapsed time data block\n",
    "elapsed_time_fields = ['CRSElapsedTime',\n",
    "                       'ActualElapsedTime',\n",
    "                       'AirTime']\n",
    "print(flights_2014_1[elapsed_time_fields].describe())\n",
    "print(flights_2014_1[elapsed_time_fields].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for possible and NA values for Diverted flights data block\n",
    "diverted_flights_fields = ['DivReachedDest',\n",
    "                       'DivActualElapsedTime',\n",
    "                       'DivArrDelay']\n",
    "print(flights_2014_1[diverted_flights_fields].describe())\n",
    "print(flights_2014_1[diverted_flights_fields].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another infermation about diverted flights\n",
    "\n",
    "The rest of the dataset contains 5 equal blocks for five airports where the flight can be diverted consiquently. Each block contains:\n",
    "* Diverted Airport Code, Airport ID of Diverted Airport,  \n",
    "* Airport Sequence ID of Diverted Airport,  \n",
    "* Wheels On Time (local time: hhmm) at Diverted Airport Code,  \n",
    "* Total Ground Time Away from Gate at Diverted Airport Code,  \n",
    "* Longest Ground Time Away from Gate at Diverted Airport Code,  \n",
    "* Wheels Off Time (local time: hhmm) at Diverted Airport Code,  \n",
    "* Aircraft Tail Number for Diverted Airport Code\n",
    "\n",
    "All this information is not rellevant to the project. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclustion about data structure and quality:  \n",
    "\n",
    "1. The data needed for the project is selected\n",
    "2. The proposed data type for each field is selected\n",
    "3. The quality of the data is good. The data represented in the dataset is mostly comprehesive, but I will examine it in more detail in next section.\n",
    "4. The logic of data for calncelled and diverted flights and consiquencies for actual departure and arrival times, time delays and elapsed times was identified and recorded\n",
    "5. On the data transformaiton stage I have to change data types for selected for the model fields and solve the 'time-2400' problem.\n",
    "6. The calculation of the resulting elapsed time, which I suppose to take as a predicted variable of the model, will be realise further on the stage of features engeneering. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Accuracy of Scheduled and Actual Elapsed Times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The elapsed times (scheduled and actual), along with departure and arrival times, are expected to play a crucial role in the model. Therefore, I must give special attention to their quality and accuracy.\n",
    "\n",
    "There are 60 data files, which makes it difficult to check all the data at once, so I plan to start by examining one file, ‘report_2014_3.csv,’ to design an approach for handling potential errors. In the future, I will apply this approach to the remaining files.\n",
    "\n",
    "I chose March because the start of Daylight Saving Time (DST) occurs in this month, which may introduce errors into our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are fields I plan to examine\n",
    "data_types = {\n",
    "    'FlightDate':           'str',\n",
    "    'Flight_Number_Reporting_Airline':  np.int16,\n",
    "    'Origin':               'category',\n",
    "    'Dest':                 'category',\n",
    "    'CRSDepTime':           np.int16,\n",
    "    'DepTime':              np.float32,\n",
    "    'DepDelay':             np.float32,\n",
    "    'CRSArrTime':           np.int16,\n",
    "    'ArrTime':              np.float32,\n",
    "    'ArrDelay':             np.float32,\n",
    "    'Cancelled':            np.int8,        # boolean\n",
    "    'Diverted':             np.int8,        # boolean\n",
    "    'CRSElapsedTime':       np.float32,\n",
    "    'ActualElapsedTime':    np.float32,\n",
    "    'AirTime':              np.float32}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from(zip_file, data_file, field_type=None):\n",
    "    '''\n",
    "    Description\n",
    "    -----------\n",
    "    Load data specified as field_type from one data file from zip-archive \n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    zip_file - path and name of source zip-file contaning 60 csv files\n",
    "    dat_faile - path and name of csv-file with data\n",
    "    field_type - dictinary with fields to load and thiers relative data types\n",
    "\n",
    "    Returns\n",
    "    ==========\n",
    "    DataFrame with data loaded\n",
    "    '''\n",
    "\n",
    "    # reading the file\n",
    "    with zipfile.ZipFile(zip_file) as zip_source:\n",
    "        with zip_source.open(data_file) as file:\n",
    "            if field_type != None:\n",
    "                df = pd.read_csv(file, header = 0, \n",
    "                                usecols = field_type.keys(),\n",
    "                                dtype = field_type)\n",
    "            else:\n",
    "                df = pd.read_csv(file, header = 0, low_memory=False)\n",
    "\n",
    "    # Converting dates and boolean        \n",
    "    if 'FlightDate' in df.columns:\n",
    "        df['FlightDate'] = pd.to_datetime(df['FlightDate'])\n",
    "    if 'DivReachedDest' in df.columns:\n",
    "        df['DivReachedDest'] = df['DivReachedDest'].fillna(0)\n",
    "    if 'Cancelled' in df.columns:\n",
    "        df['Cancelled'] = df['Cancelled'].astype('bool')\n",
    "    if 'Diverted' in df.columns:\n",
    "        df['Diverted'] = df['Diverted'].astype('bool')\n",
    "    if 'DivReachedDest' in df.columns:\n",
    "        df['DivReachedDest'] = df['DivReachedDest'].astype('bool')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The most important combinations of fields for analysis\n",
    "Date_details = ['FlightDate']\n",
    "DepTime_details = ['CRSDepTime', 'DepTime']\n",
    "ArrTime_details = ['CRSArrTime', 'ArrTime']\n",
    "DepTime_min_details = ['CRSDepTime_min', 'DepTime_min']\n",
    "ArrTime_min_details = ['CRSArrTime_min', 'ArrTime_min']\n",
    "ElapsedTime_details = ['CRSElapsedTime', 'ActualElapsedTime']\n",
    "CRS_details = ['CRSDepTime', 'CRSArrTime', 'CRSElapsedTime']\n",
    "CRS_min_details = ['CRSDepTime_min', 'CRSArrTime_min', 'CRSElapsedTime']\n",
    "Route_datails = ['Origin', 'Dest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading some dataset just for tests\n",
    "source_zip = 'data/interim/csv_flight.zip'\n",
    "source_path = 'csv_flight/report_'\n",
    "\n",
    "flights = load_data_from(source_zip, source_path + '2014_3.csv', data_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the accuracy of departure times, arrival times, and durations (both scheduled and actual), I need to calculate the UTC datetimes for both departure and arrival. The original data includes the scheduled flight date, along with two sets of data (scheduled and actual) for departure and arrival times, as well as elapsed time. To calculate the scheduled departure datetime in the local timezone, I can combine the ‘FlightDate’ with the departure time from ‘CRSDepTime.’ For the arrival time, I first need to determine the correct date, as flights may arrive on the next day — or even the previous day — due to timezone differences. I plan to use a criterion based on the difference between the departure and arrival times to indicate a change in date. A threshold for this time difference could serve as the indicator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In original data set all time data is provided in format HHMM, which is not conviniet for the purposes of calculation and comparison. I convert it into the simple number of minutes from midnight. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [TRANSFORMATION]\n",
    "# # Convert Arrival and Departure times (CRS and Actual) to minutes\n",
    "def time_to_minutes(df):\n",
    "    return df // 100 * 60 + df % 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights['CRSArrTime_min'] = time_to_minutes(flights['CRSArrTime'])\n",
    "flights['CRSDepTime_min'] = time_to_minutes(flights['CRSDepTime'])\n",
    "flights['ArrTime_min'] = time_to_minutes(flights['ArrTime'])\n",
    "flights['DepTime_min'] = time_to_minutes(flights['DepTime'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My hypothesis is that all flights arriving the next day will have a significant negative difference between arrival and departure times (in minutes). For example, if a flight departs at 1420 min (equivalent to 23:40) and arrives at 75 minutes  (equivalent to 1:15 AM), it definitely arrived the next day. However, the negative differece can occur not only when the date changes but also when a flight departs from one timezone and arrives in another where the time difference with UTC is larger. In this case, the flight’s duration should be less than the time difference. Let’s examine this for short flights (less than 60 minutes) to chose a correct threshhold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for flights when CRS Arrival time is less of equal than CRS Departure time\n",
    "CRSArr_less_than_CRSDep_min = flights['CRSArrTime_min'] <= flights['CRSDepTime_min']\n",
    "less_than_60_min = flights['CRSElapsedTime'] < 60\n",
    "\n",
    "# FOR TIMES EXPRESSED IN MINUTES !!!\n",
    "# Flights where CRS Arrival time less than CRS Departure time AND a flight was less than 60 min\n",
    "# To evaluate is it possible to 'travel in time' - to arrive the same day earlier \n",
    "flights[CRSArr_less_than_CRSDep_min & less_than_60_min][Date_details + CRS_min_details] \\\n",
    "    .sort_values('CRSElapsedTime').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see in the table above the first three flight have negative difference and definitely arrived the next day, but the last two also have negative difference but arrived the same day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... and the END of the table\n",
    "flights[CRSArr_less_than_CRSDep_min & less_than_60_min][Date_details + CRS_min_details] \\\n",
    "    .sort_values('CRSElapsedTime').tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this table all flights have negative difference between arrival and departure time but all of them arrived the same day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [TRANSFORMATION]\n",
    "# Calculation of the difference between departure and arrival time \n",
    "flights['CRS_Arr_minus_Dep'] = flights['CRSArrTime_min'] - flights['CRSDepTime_min'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the difference between CRS Arrival and Departure times\n",
    "bins = np.arange(-1440, 1440, 100)\n",
    "plt.hist(flights['CRS_Arr_minus_Dep'], density=True,  bins = bins)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the time difference between arrival and departure can be negative or possitive but it seems that there is a certain gap in negative values. Let's zoom this histogram in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine MORE CLOSELY the difference between CRS Arrival and Departure times \n",
    "bins = np.arange(-540, 60, 60)\n",
    "plt.hist(flights['CRS_Arr_minus_Dep'], density=True,  bins = bins)\n",
    "plt.xticks(bins)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there is no negative values between -8 hours (-480 min) and -1 hour (-60 min). However, to be sure let's examine the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are there any values between -900 and -200\n",
    "diff_between_900_200 = (flights['CRS_Arr_minus_Dep'] > -480) & (flights['CRS_Arr_minus_Dep'] < -60)\n",
    "print(flights[diff_between_900_200])\n",
    "\n",
    "del(diff_between_900_200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, there is no values between -480 and -60 minutes. \n",
    "It is possible to ‘travel in time’ only for a maximum of 60 minutes. All other differences occur when flights take off before midnight and land the next day. I can use a threshold of -60 minutes to adjust the departure date by adding one day in order to calculate the arrival date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are there any values between -900 and -200\n",
    "diff_greater_than_1300 = (flights['CRS_Arr_minus_Dep'] > 1300)\n",
    "print(flights[diff_greater_than_1300])\n",
    "\n",
    "del(diff_greater_than_1300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no records with positive difference more than 1300 minutes, but when this occures it means the flight has arrived at the previouse day due to timezone difference. I will use this calculating arrival dates. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating dates of departure and arrivel timezone naive "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scheduled dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_CRS_datetime(dates, dep_m, arr_m):\n",
    "    \"\"\"\n",
    "    Description\n",
    "    ------------\n",
    "    Calculate scheduled(CRS) Departure datetime (timezone naive) based on Flight Date and Departure time (minutes)\n",
    "    Calculate scheduled(CRS) Arrival datetiem (timezone naive) based on Flight Date and Arrival time (minutes). \n",
    "        Arrival time is increased by one day from Fllght Date if the difference between CRS Arrival and Departure time \n",
    "        is equal or less than -60 minutes, and decreased by one day if the difference is at least +1380 minutes.\n",
    "\n",
    "    Parameters:\n",
    "    ------------\n",
    "    dates - pandas Series with FlightDate\n",
    "    dep_m - pandas Seiries with CRS Departure time in minutes \n",
    "    arr_m - pandas Seiries with CRS Arrival time in minutes\n",
    "\n",
    "    Returns:\n",
    "    ------------\n",
    "    departure_datetime - CRS Departure datetime (timezone naive) (pd.Series)\n",
    "    arrival_datetime - CRS Arrival datetime (timezone naive) (pd.Series)\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.DataFrame() \n",
    "    df['departure_datetime'] = pd.to_datetime(dates) + pd.to_timedelta(dep_m, unit='min')\n",
    "\n",
    "    # Filter for scheduled flights arriving next or privios day\n",
    "    arr_next_day_filter = arr_m - dep_m  <= -60\n",
    "    arr_previous_day_filter = arr_m - dep_m  >= 1380\n",
    "\n",
    "    # For all scheduled flights by default arrival date is eaueal to departure date\n",
    "    df['arrival_datetime'] = dates\n",
    "\n",
    "    # Adding one day to the date if flight arrived next day\n",
    "    df.loc[arr_next_day_filter, 'arrival_datetime'] = df.loc[arr_next_day_filter, 'arrival_datetime'] \\\n",
    "                                                        + datetime.timedelta(1)\n",
    "    # Adding one day to the date if flight arrived day befor departure day\n",
    "    df.loc[arr_previous_day_filter, 'arrival_datetime'] = df.loc[arr_previous_day_filter, 'arrival_datetime'] \\\n",
    "                                                        + datetime.timedelta(-1)\n",
    "    # Finally adding actual arrival time to get actual arrival datetime\n",
    "    df['arrival_datetime'] = df['arrival_datetime'] + pd.to_timedelta(arr_m, 'm')\n",
    "\n",
    "    return df['departure_datetime'], df['arrival_datetime']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting CRS times (departure and arrival into datetime with correct arrival date - the previous, the same or the next day)\n",
    "flights['CRSDepTime'], flights['CRSArrTime'] = get_CRS_datetime(flights['FlightDate'], \n",
    "                                                                              flights['CRSDepTime_min'], \n",
    "                                                                              flights['CRSArrTime_min'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check for actual departure and arrival datetimes \n",
    "pd.set_option('display.width', 200)\n",
    "\n",
    "CRS_Arrived_next_day = flights['CRSArrTime_min'] - flights['CRSDepTime_min']  <= -60\n",
    "CRS_Arrived_previous_day = flights['CRSArrTime_min'] - flights['CRSDepTime_min']  >= 1380\n",
    "print('Flights arrived next day after departure\\n', \n",
    "      flights[CRS_Arrived_next_day]\n",
    "      [['FlightDate', 'CRSDepTime', 'CRSDepTime', 'DepDelay', 'CRSArrTime', 'CRSArrTime']].head())\n",
    "print('Flights arrived the same day as departured\\n',\n",
    "      flights[~CRS_Arrived_next_day]\n",
    "      [['FlightDate', 'CRSDepTime', 'CRSDepTime', 'DepDelay', 'CRSArrTime', 'CRSArrTime']].head())\n",
    "print('Flights arrived the previous day as departured\\n',\n",
    "      flights[CRS_Arrived_previous_day]\n",
    "      [['FlightDate', 'CRSDepTime', 'CRSDepTime', 'DepDelay', 'CRSArrTime', 'CRSArrTime']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actual dates\n",
    "\n",
    "Calculating actual date we have to take into account that even the departure date can differ from the dataset's flight date, because this date is for scheduled time, but actual time can move to the next or previous day due to flight positive or negative delay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields_to_load = {\n",
    "    # 'Year':                 np.int16,               \n",
    "    # 'Quarter':              np.int8,                \n",
    "    # 'Month':                np.int8,                \n",
    "    # 'DayofMonth':           np.int8,\n",
    "    # 'DayOfWeek':            np.int8,\n",
    "    'FlightDate':           'str',\n",
    "    'Reporting_Airline':    'category',\n",
    "    'Flight_Number_Reporting_Airline':  np.int16,\n",
    "    'OriginAirportID':      'category',\n",
    "    'Origin':               'category',\n",
    "    'DestAirportID':        'category',\n",
    "    'Dest':                 'category',\n",
    "    'CRSDepTime':           np.int16,\n",
    "    'DepTime':              np.float32,\n",
    "    'DepDelay':             np.float32,\n",
    "    'DepartureDelayGroups': 'category',\n",
    "    'DepTimeBlk':           'category',\n",
    "    'CRSArrTime':           np.int16,\n",
    "    'ArrTime':              np.float32,\n",
    "    'ArrDelay':             np.float32,\n",
    "    'ArrivalDelayGroups':   'category',\n",
    "    'ArrTimeBlk':           'category',\n",
    "    'Cancelled':            np.int8,        # boolean\n",
    "    'CancellationCode':     'category',\n",
    "    'Diverted':             np.int8,        # boolean\n",
    "    'CarrierDelay':         np.float32,\n",
    "    'WeatherDelay':         np.float32,\n",
    "    'NASDelay':             np.float32,\n",
    "    'SecurityDelay':        np.float32,\n",
    "    'LateAircraftDelay':    np.float32,\n",
    "    'CRSElapsedTime':       np.float32,\n",
    "    'ActualElapsedTime':    np.float32,\n",
    "    'AirTime':              np.float32,\n",
    "    'DivReachedDest':       np.float32,        # boolean\n",
    "    'DivActualElapsedTime': np.float32,\n",
    "    'DivArrDelay':          np.float32}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Actual_datetime(dates, dep_m, arr_m, dep_delay):\n",
    "    \"\"\"\n",
    "    Description\n",
    "    ------------\n",
    "    Calculate Actual Departure datetime (timezone naive) based on Flight Date, Departure time (minutes) and Departure \n",
    "        delay (minutes)\n",
    "    Calculate Actual Arrival datetiem (timezone naive) based on Flight Date, Actual Departure date in accordance with \n",
    "        Departure delay and Arrival time (minutes). Arrival time is increased by one day from Departure Date if \n",
    "        the difference between CRS Arrival and Departure time is equal or less than -60 minutes, and decreased by one day \n",
    "        if the difference is at least +1380 minutes.\n",
    "\n",
    "    Parameters:\n",
    "    ------------\n",
    "    dates - FlightDate (pd.Series)\n",
    "    dep_m - Actual Departure time in minutes (pd.Series)\n",
    "    arr_m - Actual Arrival time in minutes (pd.Series)\n",
    "    dep_delay - departure delay in minutes (pd.Series)\n",
    "\n",
    "    Returns:\n",
    "    ------------\n",
    "    departure_datetime - Actual Departure datetime (timezone naive) (pd.Series)\n",
    "    arrival_datetime - Actual Arrival datetime (timezone naive) (pd.Series)\n",
    "    \"\"\"\n",
    "\n",
    "    # Filters for flights having DepTime_min and ArrTime_min \n",
    "    # These filters actually for not cancelled flights, but they differ each other because some flights cancelles after departure\n",
    "    # So they have departure time but didn't fly \n",
    "    Dep_exists_filter = ~dep_m.isna()\n",
    "    Arr_exists_filter = ~arr_m.isna()\n",
    "\n",
    "    # Array with 'day shift' due to flight delay. NOTICE: some flights have -1 day shift because day had a small negative delay \n",
    "    # having a scheduled departure time several minutes after midnight\n",
    "\n",
    "    d = np.zeros([len(dates)], dtype='int')\n",
    "    d = ((dep_m.fillna(0) + dep_delay.fillna(0)) // 1440).astype(int)\n",
    "    day_deltas_due_to_delay = pd.to_timedelta(d, unit='days')\n",
    "\n",
    "    # Calculating actual departure datetime\n",
    "    df = pd.DataFrame() #pd.NaT, index = [*range(0, len(dates))], columns= ['departure_datetime', 'arrival_datetime'])\n",
    "    df.loc[Dep_exists_filter, 'departure_datetime'] = dates[Dep_exists_filter] \\\n",
    "                                                + day_deltas_due_to_delay[Dep_exists_filter] \\\n",
    "                                                + pd.to_timedelta(dep_m[Dep_exists_filter], 'm')\n",
    "\n",
    "    # Calculating actual arrival datetime\n",
    "\n",
    "    # Filter for flights arrived next or previous day\n",
    "    Arrived_next_day = arr_m - dep_m  <= -60\n",
    "    Arrived_previous_day = arr_m - dep_m  >= 1380\n",
    "\n",
    "    # For all arrived flights at first arrival date is eaueal to departure date\n",
    "    df.loc[Arr_exists_filter, 'arrival_datetime'] = dates[Arr_exists_filter] \\\n",
    "                                                + day_deltas_due_to_delay[Arr_exists_filter] \n",
    "    # Adding one day to the date if flight arrived next day\n",
    "    df.loc[Arr_exists_filter & Arrived_next_day, 'arrival_datetime'] = \\\n",
    "            df.loc[Arr_exists_filter & Arrived_next_day, 'arrival_datetime'] + datetime.timedelta(1)\n",
    "    \n",
    "    # Adding one day to the date if flight arrived previous day\n",
    "    df.loc[Arr_exists_filter & Arrived_previous_day, 'arrival_datetime'] = \\\n",
    "            df.loc[Arr_exists_filter & Arrived_previous_day, 'arrival_datetime'] + datetime.timedelta(-1)\n",
    "    \n",
    "    # Finally adding actual arrival time to get actual arrival datetime\n",
    "    df.loc[Arr_exists_filter, 'arrival_datetime'] = \\\n",
    "            df.loc[Arr_exists_filter, 'arrival_datetime'] + pd.to_timedelta(arr_m.loc[Arr_exists_filter], 'm')\n",
    "    \n",
    "    return df['departure_datetime'], df['arrival_datetime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights['ActDepTime'], flights['ActArrTime'] = get_Actual_datetime(flights['FlightDate'], \n",
    "                                                                                  flights['DepTime_min'], \n",
    "                                                                                  flights['ArrTime_min'],\n",
    "                                                                                  flights['DepDelay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for actual departure and arrival datetimes \n",
    "Arrived_next_day = flights['ArrTime_min'] - flights['DepTime_min']  <= -60\n",
    "Arrived_previous_day = flights['ArrTime_min'] - flights['DepTime_min']  >= 1380\n",
    "check_fields = ['FlightDate', 'DepTime', 'ActDepTime', 'DepDelay', 'ActArrTime', 'ArrTime']\n",
    "\n",
    "print('Flights arrived next day after departure\\n', flights[Arrived_next_day][check_fields].head())\n",
    "print('Flights arrived the same day as departured\\n', flights[~Arrived_next_day][check_fields].head())\n",
    "print('Flights arrived the previous day as departured\\n', flights[Arrived_previous_day][check_fields].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding local timezone derived from IATA code of airport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [TRANSFORMATION]\n",
    "# Function to add to the series of datetime a timezone specified by airports IATA codes\n",
    "def add_local_tz(df, dt_field, IATA_code_field):\n",
    "    return [row[dt_field].tz_localize(tz=tz.gettz(IATAtz[row[IATA_code_field]]), ambiguous=True ,nonexistent='shift_forward')\n",
    "        for _, row in df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# [TRANSFORMATION]\n",
    "# Adding local timezones to the Departure and Arrival times \n",
    "flights['CRSDepTime'] = add_local_tz(flights, 'CRSDepTime', 'Origin')\n",
    "flights['CRSArrTime'] = add_local_tz(flights, 'CRSArrTime', 'Dest')\n",
    "flights['ActDepTime'] = add_local_tz(flights, 'ActDepTime', 'Origin')\n",
    "flights['ActArrTime'] = add_local_tz(flights, 'ActArrTime', 'Dest')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check CRS fields\n",
    "check_fields_CRS = ['FlightDate', 'CRSDepTime', 'CRSDepTime', 'CRSArrTime', 'CRSArrTime', 'CRSElapsedTime']\n",
    "print(flights[CRSArr_less_than_CRSDep_min][check_fields_CRS].head())\n",
    "print(flights[~CRSArr_less_than_CRSDep_min][check_fields_CRS].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check ACTUAL fields\n",
    "check_fields_CRS = ['FlightDate', 'ActDepTime', 'DepTime', 'ActArrTime', 'ArrTime', 'ActualElapsedTime']\n",
    "print(flights[Arrived_next_day][check_fields_CRS].head())\n",
    "print(flights[~Arrived_next_day][check_fields_CRS].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, it seems that our dates are properly localized to the respective timezone. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting datetimes to UTC timezone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert datetime timezone naive to UTC timezone\n",
    "def convert_to_UTC(df, dt_field, IATA_code_field):\n",
    "    return [row[dt_field].tz_localize(tz=tz.gettz(IATAtz[row[IATA_code_field]]), ambiguous=True, nonexistent='shift_forward')\n",
    "             .astimezone(tz.UTC) for _, row in df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting UTC timezone for scheduled (CRS) departure and arrival times\n",
    "flights['CRSDep_UTC'] = convert_to_UTC(flights, 'CRSDepTime', 'Origin')\n",
    "flights['CRSArr_UTC'] = convert_to_UTC(flights, 'CRSArrTime', 'Dest')\n",
    "\n",
    "# We have to filter for non-NA values because astimezone doesn't work wiht NaN/NaT\n",
    "nonNA_Dep = ~flights['ActDepTime'].isna()\n",
    "flights.loc[nonNA_Dep, 'ActDep_UTC'] = convert_to_UTC(flights[nonNA_Dep], 'ActDepTime', 'Origin')\n",
    "\n",
    "# We have to filter for non-NA values because astimezone doesn't work wiht NaN/NaT\n",
    "nonNA_Arr = ~flights['ActArrTime'].isna()\n",
    "flights.loc[nonNA_Arr, 'ActArr_UTC'] = convert_to_UTC(flights[nonNA_Arr], 'ActArrTime', 'Dest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check CRS\n",
    "fields_to_check_UTC_CRS = ['CRSDepTime', 'CRSDep_UTC', 'CRSArrTime', 'CRSArr_UTC']\n",
    "print(flights[fields_to_check_UTC_CRS].head())\n",
    "\n",
    "# Check ACTUAL\n",
    "fields_to_check_UTC_Act = ['ActDepTime', 'ActDep_UTC', 'ActArrTime', 'ActArr_UTC']\n",
    "print(flights[fields_to_check_UTC_Act].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating scheduled and actual elapsed times based on UTC departure and arrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [TRANSFORTATION]\n",
    "# Calculating Elapsed time based on UTC times\n",
    "flights['UTCElapsedTime_CRS'] = (flights['CRSArr_UTC'] - flights['CRSDep_UTC']).dt.total_seconds() / 60\n",
    "\n",
    "flights.loc[nonNA_Arr, 'UTCElapsedTime_Act'] = pd.to_timedelta((flights.loc[nonNA_Arr, 'ActArr_UTC'] - \n",
    "                                                                flights.loc[nonNA_Arr, 'ActDep_UTC'])).dt.total_seconds() / 60\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [TRANSFORMATINO]\n",
    "# The difference between UTC-based Elapsed time and CRS/ACTUAL Elapsed time\n",
    "flights['diff_CRS'] = flights['UTCElapsedTime_CRS'] - flights['CRSElapsedTime']\n",
    "flights['diff_Act'] = flights['UTCElapsedTime_Act'] - flights['ActualElapsedTime']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining the accuracy of CRS Elapsed time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the flights having difference between UTC-Based and CRS Elapsed times \n",
    "diff_not_zero = flights[flights['diff_CRS'] != 0][fields_to_check_UTC_CRS + ['CRSElapsedTime', 'UTCElapsedTime_CRS']]\n",
    "print('There are', len(diff_not_zero), 'flights where CRS Elapsed time differ from CRS Elapsed time culculated based on UTC')\n",
    "diff_not_zero.head()\n",
    "\n",
    "del(diff_not_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights['diff_CRS'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 76 flights in the datased where we have a difference between UTC and CRS elapsed time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s take a detailed look at one of these flights: the first one from the table above, with ID = 86022, which has a -60 minute difference between UTC and CRS elapsed times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look on the first flight with diffeence\n",
    "flights.iloc[86022]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we see that this flight took place during the spring 2014 DST, and the difference between UTC and CRS elapsed times is exactly 60 minutes. But which time is correct? Let’s take a look at this flight on other days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights[(flights['Flight_Number_Reporting_Airline'] == 103) &\n",
    "         (flights['Origin'] == 'SEA')][['CRSArrTime', 'CRSElapsedTime', 'UTCElapsedTime_CRS', 'diff_CRS']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the only flight having the difference is the filight landed 9th March 2014 and the UTC-based elapsed time is correct (CRSElapsedTime has the wrong value for DST day). Let's examine other flights having difference of 60 min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_60_min = flights[flights['diff_CRS'] == -60][['CRSDepTime', 'CRSArrTime', 'CRSElapsedTime', 'UTCElapsedTime_CRS', 'diff_CRS']]\n",
    "print(len(diff_60_min), 'records')\n",
    "diff_60_min\n",
    "\n",
    "del(diff_60_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that all flights with a -60 minute difference between UTC and CRS elapsed times occurred during DST. There are 13 such records in the dataset.\n",
    "\n",
    "We can conclude that the CRS elapsed time is incorrect for all 13 flights that passed through DST.\n",
    "\n",
    "This explains the discrepancy between UTC and CRS elapsed times for 13 out of the 76 flights in the dataset. But what about the remaining flights with a similar difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights['UTCElapsedTime_CRS'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is another interesting fact - some flights has also engative UTC elapsed time! How is this possible?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_less_0 = flights[flights['UTCElapsedTime_CRS'] < 0]\n",
    "print(len(error_less_0))\n",
    "error_less_0[\n",
    "    ['CRSDepTime', \n",
    "     'Origin', \n",
    "     'CRSArrTime', \n",
    "     'Dest', \n",
    "     'CRSElapsedTime', \n",
    "     'UTCElapsedTime_CRS', \n",
    "     'diff_CRS']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 31 flights with a negative UTC elapsed time. Previously, we analyzed the differences between UTC and CRS elapsed times and found that 31 flights had a -1440 minute difference. These are the same flights. A difference of 1440 minutes is equivalent to 24 hours.\n",
    "\n",
    "All 31 flights were from HNL to GUM, which is interesting because HNL is in the UTC-10 timezone, while GUM is in the UTC+10 timezone. These two airports are located across the International Date Line (IDL)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(error_less_0[['CRSDep_UTC', 'CRSDepTime', 'Origin', 'CRSArr_UTC', 'CRSArrTime', 'Dest', 'diff_CRS']].head())\n",
    "\n",
    "del(error_less_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The easiest way to correct this is to find all flight with UTC Departures less than UTC Arrival and add 24 x 60 minutes to the UTC Elapsed time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There ara other flights which have the \"oposite\" difference - they differ on +1440 minutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_plus_1440 = flights[flights['diff_CRS'] == 1440]\n",
    "print(len(error_plus_1440))\n",
    "print(error_plus_1440[['CRSDep_UTC', 'CRSDepTime', 'Origin', 'CRSArr_UTC', 'CRSArrTime', 'Dest', 'diff_CRS']])\n",
    "\n",
    "del(error_plus_1440)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All these flight are back flights from GUM to HLN across Internation Date Line (IDL). The ramedy is simillar - to subtract 24 x 60 (1440) minutes from UTC elapsed time. \n",
    "\n",
    "There is just one flight with unexamined yet difference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_minus_36 = flights[flights['diff_CRS'] == -36]\n",
    "print(len(error_minus_36), 'records')\n",
    "print(error_minus_36[['Flight_Number_Reporting_Airline', 'CRSDep_UTC', 'CRSDepTime', 'Origin', 'CRSArr_UTC', \n",
    "               'CRSArrTime', 'Dest', 'CRSElapsedTime', 'UTCElapsedTime_CRS', \n",
    "               'ActualElapsedTime', 'diff_CRS', 'Cancelled', 'Diverted']].T)\n",
    "\n",
    "del(error_minus_36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights[(flights['Flight_Number_Reporting_Airline'] == 317) &\n",
    "        (flights['Origin'] == 'DEN') &\n",
    "        (flights['Dest'] == 'PSP')] [['CRSElapsedTime', 'UTCElapsedTime_CRS', 'diff_CRS']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we see that CRS Elapsed time is:\n",
    "1. also inconsistent with CRS Departure and CRS Arrival times\n",
    "2. all other flights for this route have the equal CRS and UTC elapsed times which is 129 minutes  \n",
    "\n",
    "So this can be an error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking ACTUAL time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights['diff_Act'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that the actual elapsed time shows the same differences as the scheduled elapsed time between the two types of flight duration: one calculated using UTC arrival and departure times, and the other based on the ActualElapsedTime provided in the dataset. Let’s take a closer look.\n",
    "\n",
    "The total number of discrepancies is 78, with the following breakdown:\n",
    "*\t+/-1440 minutes: 60 records, likely related to flights crossing the International Date Line (IDL) from HNL to GUM and back.\n",
    "*\t-60 minutes: 15 records, possibly due to flights occurring during the transition to Daylight Saving Time (DST) in the spring.\n",
    "*\tOther: 3 records with small, random differences, which could be attributed to minor errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_1440 = flights[flights['diff_Act'].isin([1440, -1440])]\n",
    "print('There are:', len(error_1440), 'records with differenc +/-1440 min (equal to 24 hours)')\n",
    "print('Which airports are presented among these flights:', *set(error_1440['Origin']).union(set(error_1440['Origin'])))\n",
    "\n",
    "del(error_1440)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All these flights are again between two airports across IDL. We already know this problem and know how to cue it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_60 = flights[flights['diff_Act'] == -60][['Flight_Number_Reporting_Airline', 'ActDepTime', 'ActArrTime',\n",
    "                                           'ActDep_UTC', 'ActArr_UTC', 'Origin', 'Dest', 'ActualElapsedTime', 'UTCElapsedTime_Act']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_60['DST_Origin'] = pd.to_datetime(\"2014-03-09 01:59:59\")\n",
    "error_60['DST_Dest'] = pd.to_datetime(\"2014-03-09 02:00:01\")\n",
    "error_60['DST_Origin'] = add_local_tz(error_60, 'DST_Origin', 'Origin')\n",
    "error_60['DST_Dest'] = add_local_tz(error_60, 'DST_Dest', 'Dest')\n",
    "\n",
    "print((error_60['ActDepTime'] < error_60['DST_Origin']).all())\n",
    "print(error_60[~(error_60['ActArrTime'] > error_60['DST_Dest'])].T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All these flights departured before the transition to DST and arrived after it. This is the reason they have a wrong ActualElapsedTime. It's worth to mention that theirs arrival time is correct.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other = flights[(flights['diff_Act'] > -60) & (flights['diff_Act'] < 10) & (flights['diff_Act'] != 0)]\n",
    "print(len(other))\n",
    "other[['Flight_Number_Reporting_Airline',\n",
    "       'ActDepTime', \n",
    "       'ActArrTime',\n",
    "       'Origin', \n",
    "       'Dest', \n",
    "       'ActDep_UTC',\n",
    "       'ActArr_UTC',\n",
    "       'diff_Act', \n",
    "       'ActualElapsedTime', \n",
    "       'UTCElapsedTime_Act']].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we notice that all these differences appear again on the spring DST start date.\n",
    "Secondly, it looks like the first two flights have minor errors that we can disregard, and we can use UTC elapsed time instead of Actual elapsed time. However, the third flight has a significant difference. Let’s examine it in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights[(flights['Flight_Number_Reporting_Airline'] == 5702) &\\\n",
    "        (flights['Origin'] == 'ORD') &\\\n",
    "        (flights['Dest'] == 'CAE')] [['Flight_Number_Reporting_Airline',\n",
    "       'ActDepTime', \n",
    "       'ActArrTime',\n",
    "       'Origin', \n",
    "       'Dest', \n",
    "       'ActDep_UTC',\n",
    "       'ActArr_UTC',\n",
    "       'diff_Act', \n",
    "       'ActualElapsedTime', \n",
    "       'UTCElapsedTime_Act']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the same flight on other days has a duration close to the actual elapsed time recorded on March 9th. The elapsed time based on UTC, however, is significantly different from the real duration, which suggests that either the actual departure or arrival time (or both) is incorrect. There are several options to address this, such as adjusting the departure or arrival time based on the average duration of similar flights. However, due to the insignificance of this error (1 out of almost 500k flights in total, and 25 flights on this route in the same month), the simplest solution is to drop this record on the next stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions for evaluation of the accuracy of Scheduled and Actual Elapsed Times  \n",
    "1. The most of data accurate\n",
    "2. The flights across IDL (particularly GUM and HNL airports) reqieres substructuo of 1440 minutes (24hours) due to the date change.\n",
    "3. The start of DST creates minor errors in elapsed time calculation and requires correction.\n",
    "4. Therea are absulute minorite of flights that have indiscrepencies between elapsed time and departur and arrival time (3 flight for more about 500k records for March 2014.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields_to_load = {\n",
    "    # 'Year':                 np.int16,               \n",
    "    # 'Quarter':              np.int8,                \n",
    "    # 'Month':                np.int8,                \n",
    "    # 'DayofMonth':           np.int8,\n",
    "    # 'DayOfWeek':            np.int8,\n",
    "    'FlightDate':           'str',\n",
    "    'Reporting_Airline':    'category',\n",
    "    'Flight_Number_Reporting_Airline':  np.int16,\n",
    "    # 'OriginAirportID':      'category',\n",
    "    'Origin':               'category',\n",
    "    # 'DestAirportID':        'category',\n",
    "    'Dest':                 'category',\n",
    "    'CRSDepTime':           np.int16,\n",
    "    'DepTime':              'float32',\n",
    "    'DepDelay':             'float32',\n",
    "    'DepartureDelayGroups': 'category',\n",
    "    'DepTimeBlk':           'category',\n",
    "    'CRSArrTime':           np.int16,\n",
    "    'ArrTime':              'float32',\n",
    "    'ArrDelay':             'float32',\n",
    "    'ArrivalDelayGroups':   'category',\n",
    "    'ArrTimeBlk':           'category',\n",
    "    'Cancelled':            np.int8,        # boolean\n",
    "    'CancellationCode':     'category',\n",
    "    'Diverted':             np.int8,        # boolean\n",
    "    'CarrierDelay':         'float32',\n",
    "    'WeatherDelay':         'float32',\n",
    "    'NASDelay':             'float32',\n",
    "    'SecurityDelay':        'float32',\n",
    "    'LateAircraftDelay':    'float32',\n",
    "    'CRSElapsedTime':       'float32',\n",
    "    'ActualElapsedTime':    'float32',\n",
    "    'AirTime':              'float32',\n",
    "    'DivReachedDest':       'float32',      # boolean\n",
    "    'DivActualElapsedTime': 'float32',\n",
    "    'DivArrDelay':          'float32'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv_flight/report_2014_1.csv "
     ]
    }
   ],
   "source": [
    "source_zip = 'data/interim/csv_flight.zip'\n",
    "source_path = 'csv_flight/report_'\n",
    "counter = 0\n",
    "total_time = 0\n",
    "\n",
    "# Fields to downcast type from 'float32' to 'float16'\n",
    "downcast_fields = ['DepDelay', 'ArrDelay', 'CarrierDelay', 'WeatherDelay','NASDelay', 'SecurityDelay', 'LateAircraftDelay', \n",
    "                   'CRSElapsedTime', 'ActualElapsedTime', 'AirTime', 'DivActualElapsedTime', 'DivArrDelay', 'UTCElapsedTime_CRS',\n",
    "                   'UTCElapsedTime_Act', 'diff_CRS', 'diff_Act']\n",
    "\n",
    "for year in range(2014, 2019):\n",
    "    for month in range(1, 13): \n",
    "        t_start = time()\n",
    "        counter += 1\n",
    "        source_data = source_path + str(year) + '_' + str(month) + '.csv'\n",
    "        print(source_data + ' ', end='')\n",
    "\n",
    "        flights = pd.DataFrame()\n",
    "        flights = load_data_from(source_zip, source_data, fields_to_load)\n",
    "\n",
    "        flights['CRSArrTime_min'] = time_to_minutes(flights['CRSArrTime'])\n",
    "        flights['CRSDepTime_min'] = time_to_minutes(flights['CRSDepTime'])\n",
    "        flights['ArrTime_min'] = time_to_minutes(flights['ArrTime'])\n",
    "        flights['DepTime_min'] = time_to_minutes(flights['DepTime'])\n",
    "\n",
    "        flights['CRSDepDT'], flights['CRSArrDT'] = get_CRS_datetime(flights['FlightDate'], \n",
    "                                                                    flights['CRSDepTime_min'], \n",
    "                                                                    flights['CRSArrTime_min'])\n",
    "\n",
    "        flights['DepDT'], flights['ArrDT'] = get_Actual_datetime(flights['FlightDate'], \n",
    "                                                                flights['DepTime_min'], \n",
    "                                                                flights['ArrTime_min'],\n",
    "                                                                flights['DepDelay'])\n",
    "\n",
    "        # Getting UTC timezone for scheduled (CRS) departure and arrival times\n",
    "        flights['CRSDep_UTC'] = convert_to_UTC(flights, 'CRSDepDT', 'Origin')\n",
    "        flights['CRSArr_UTC'] = convert_to_UTC(flights, 'CRSArrDT', 'Dest')\n",
    "\n",
    "        # We have to filter for non-NA values because astimezone doesn't work wiht NaN/NaT\n",
    "        nonNA_Dep = ~flights['DepTime'].isna()\n",
    "        flights['Dep_UTC'] = pd.NaT\n",
    "        flights['Dep_UTC'] = flights['Dep_UTC'].dt.tz_localize(tz.UTC)\n",
    "        flights.loc[nonNA_Dep, 'Dep_UTC'] = pd.to_datetime(convert_to_UTC(flights[nonNA_Dep], 'DepDT', 'Origin'))\n",
    "\n",
    "        # We have to filter for non-NA values because astimezone doesn't work wiht NaN/NaT\n",
    "        nonNA_Arr = ~flights['ArrTime'].isna()\n",
    "        flights['Arr_UTC'] = pd.NaT\n",
    "        flights['Arr_UTC'] = flights['Arr_UTC'].dt.tz_localize(tz.UTC)\n",
    "        flights.loc[nonNA_Arr, 'Arr_UTC'] = convert_to_UTC(flights[nonNA_Arr], 'ArrDT', 'Dest')\n",
    "\n",
    "        # Calculating Elapsed time based on UTC times\n",
    "        flights['UTCElapsedTime_CRS'] = (flights['CRSArr_UTC'] - flights['CRSDep_UTC']).dt.total_seconds() / 60\n",
    "        flights.loc[nonNA_Arr, 'UTCElapsedTime_Act'] = pd.to_timedelta((flights.loc[nonNA_Arr, 'Arr_UTC'] - \n",
    "                                                                flights.loc[nonNA_Arr, 'Dep_UTC'])).dt.total_seconds() / 60\n",
    "\n",
    "        flights['diff_CRS'] = flights['UTCElapsedTime_CRS'] - flights['CRSElapsedTime']\n",
    "        flights['diff_Act'] = flights['UTCElapsedTime_Act'] - flights['ActualElapsedTime']\n",
    "       \n",
    "        # Cleaning the dataset\n",
    "        flights.drop(['FlightDate', \n",
    "                    'DepTime', 'DepTime_min', 'ArrTime', 'ArrTime_min',\n",
    "                    'CRSDepTime', 'CRSDepTime_min', 'CRSArrTime', 'CRSArrTime_min'], axis = 1, inplace = True)\n",
    "        flights[downcast_fields] = flights[downcast_fields].astype('float16')\n",
    "\n",
    "        # Export data\n",
    "        output_file_name = 'data/processed/processed_' + str(year) + '_' + str(month) + '.pickle'\n",
    "        with open(output_file_name, 'wb') as out_file:\n",
    "            pickle.dump(flights, out_file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        del(flights)\n",
    "\n",
    "        t_end = time()\n",
    "        elapsed_t = t_end - t_start\n",
    "        total_time += elapsed_t\n",
    "        print(round(elapsed_t, 1), 'sec, total time:', round(total_time, 1), \\\n",
    "            'sec, avg: ', round(total_time / counter, 1), 'sec, remaining time (estimate)', \n",
    "            round(total_time / counter * (60 - counter) /60), 'min.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/processed/processed_2014_1.pickle\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 471949 entries, 0 to 471948\n",
      "Data columns (total 47 columns):\n",
      " #   Column                           Non-Null Count   Dtype                  \n",
      "---  ------                           --------------   -----                  \n",
      " 0   FlightDate                       471949 non-null  datetime64[ns]         \n",
      " 1   Reporting_Airline                471949 non-null  category               \n",
      " 2   Flight_Number_Reporting_Airline  471949 non-null  int16                  \n",
      " 3   OriginAirportID                  471949 non-null  category               \n",
      " 4   Origin                           471949 non-null  category               \n",
      " 5   DestAirportID                    471949 non-null  category               \n",
      " 6   Dest                             471949 non-null  category               \n",
      " 7   CRSDepTime                       471949 non-null  int16                  \n",
      " 8   DepTime                          441622 non-null  float32                \n",
      " 9   DepDelay                         441622 non-null  float32                \n",
      " 10  DepartureDelayGroups             441622 non-null  category               \n",
      " 11  DepTimeBlk                       471949 non-null  category               \n",
      " 12  CRSArrTime                       471949 non-null  int16                  \n",
      " 13  ArrTime                          440453 non-null  float32                \n",
      " 14  ArrDelay                         439620 non-null  float32                \n",
      " 15  ArrivalDelayGroups               439620 non-null  category               \n",
      " 16  ArrTimeBlk                       471949 non-null  category               \n",
      " 17  Cancelled                        471949 non-null  bool                   \n",
      " 18  CancellationCode                 30852 non-null   category               \n",
      " 19  Diverted                         471949 non-null  bool                   \n",
      " 20  CRSElapsedTime                   471949 non-null  float32                \n",
      " 21  ActualElapsedTime                439620 non-null  float32                \n",
      " 22  AirTime                          439620 non-null  float32                \n",
      " 23  CarrierDelay                     119994 non-null  float32                \n",
      " 24  WeatherDelay                     119994 non-null  float32                \n",
      " 25  NASDelay                         119994 non-null  float32                \n",
      " 26  SecurityDelay                    119994 non-null  float32                \n",
      " 27  LateAircraftDelay                119994 non-null  float32                \n",
      " 28  DivReachedDest                   471949 non-null  bool                   \n",
      " 29  DivActualElapsedTime             833 non-null     float32                \n",
      " 30  DivArrDelay                      833 non-null     float32                \n",
      " 31  CRSArrTime_min                   471949 non-null  int16                  \n",
      " 32  CRSDepTime_min                   471949 non-null  int16                  \n",
      " 33  ArrTime_min                      440453 non-null  float32                \n",
      " 34  DepTime_min                      441622 non-null  float32                \n",
      " 35  CRSDepDT                         471949 non-null  datetime64[ns]         \n",
      " 36  CRSArrDT                         471949 non-null  datetime64[ns]         \n",
      " 37  DepDT                            441622 non-null  datetime64[ns]         \n",
      " 38  ArrDT                            440453 non-null  datetime64[ns]         \n",
      " 39  CRSDep_UTC                       471949 non-null  datetime64[ns, tzutc()]\n",
      " 40  CRSArr_UTC                       471949 non-null  datetime64[ns, tzutc()]\n",
      " 41  Dep_UTC                          441622 non-null  datetime64[ns, tzutc()]\n",
      " 42  Arr_UTC                          440453 non-null  datetime64[ns, tzutc()]\n",
      " 43  UTCElapsedTime_CRS               471949 non-null  float64                \n",
      " 44  UTCElapsedTime_Act               440453 non-null  float64                \n",
      " 45  diff_CRS                         471949 non-null  float64                \n",
      " 46  diff_Act                         439620 non-null  float64                \n",
      "dtypes: bool(3), category(10), datetime64[ns, tzutc()](4), datetime64[ns](5), float32(16), float64(4), int16(5)\n",
      "memory usage: 87.8 MB\n"
     ]
    }
   ],
   "source": [
    "flights = pd.DataFrame()\n",
    "input_file_name = 'data/processed/processed_' + str(2014) + '_' + str(1) + '.pickle'\n",
    "print(input_file_name)\n",
    "with open(input_file_name, 'rb') as in_file:\n",
    "    flights = pickle.load(in_file)\n",
    "flights.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def memory_usage_per_type(data_frame):\n",
    "    '''\n",
    "    Source: https://medium.com/@alielagrebi/optimize-the-pandas-dataframe-memory-consuming-for-low-environment-24aa74cf9413\n",
    "    '''\n",
    "    types = ['number', 'object', 'datetimetz', 'category', 'bool']\n",
    "    for tp in types:\n",
    "        selected_col = data_frame.select_dtypes(include=[tp])\n",
    "        memory_usage_per_type_b = selected_col.memory_usage(deep=True).sum()\n",
    "        memory_usage_per_type_mb = memory_usage_per_type_b / 1024**2\n",
    "        print('memory usage for {} columns: {:03.3f} MB'.format(tp, memory_usage_per_type_mb))\n",
    "    \n",
    "\n",
    "def memory_usage(data_frame):\n",
    "    return data_frame.memory_usage(deep=True).sum() / 1024**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory usage for number columns: 47.709 MB\n",
      "memory usage for object columns: 0.000 MB\n",
      "memory usage for datetimetz columns: 14.403 MB\n",
      "memory usage for category columns: 6.367 MB\n",
      "memory usage for bool columns: 1.350 MB\n",
      "Memory usage by dataframe 87.83 MB\n"
     ]
    }
   ],
   "source": [
    "memory_usage_per_type(flights)\n",
    "print('Memory usage by dataframe {:.2f} MB'.format(memory_usage(flights)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights = pd.DataFrame()\n",
    "flights_list = []\n",
    "for year in range(2014, 2019):\n",
    "    for month in range(1, 13): \n",
    "        input_file_name = 'data/processed/processed_' + str(year) + '_' + str(month) + '_v2.pickle'\n",
    "        print(input_file_name)\n",
    "        with open(input_file_name, 'rb') as in_file:\n",
    "            flights_list.append(pickle.load(in_file))\n",
    "\n",
    "flights = pd.concat(flights_list, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(flights_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(flights.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_name = 'data/processed/processed_2014_2018.pickle'\n",
    "with open(output_file_name, 'wb') as out_file:\n",
    "    pickle.dump(flights, out_file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights.to_csv('data/processed/processed_2014_2018.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_col = flights['ActArrTime'].memory_usage(deep=True)\n",
    "selected_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights['ActArrTime'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_col = flights['CRSDep_UTC'].memory_usage(deep=True)\n",
    "selected_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(flights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis of difference between 'ActualElapsedTime' and 'CRSElapsedTime'\n",
    "flights['ElapsedTimeDiff'] = flights['ActualElapsedTime'] - flights['CRSElapsedTime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "rng = np.random.default_rng(18)\n",
    "gauss_distr = rng.normal(flights['ElapsedTimeDiff'].mean(),\n",
    "                        flights['ElapsedTimeDiff'].std(),\n",
    "                        size=1000000)\n",
    "\n",
    "bins = np.arange(-50,50)\n",
    "\n",
    "plt.hist(flights['ElapsedTimeDiff'], bins=bins, density=True)\n",
    "plt.hist(gauss_distr, histtype='step', bins=bins, color='r', density=True)\n",
    "plt.xlim(-50,50)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean difference between scheduled and actual time', round(flights['ElapsedTimeDiff'].mean(), 2))\n",
    "print('Standard deviation of the difference', round(flights['ElapsedTimeDiff'].std(), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The diffence between acheduled and actual elapsed time is not normally distribute (despite being very close), In average the actual elapsed time less than the scheduled (-4.73 min). However, this is the duration of the flight and not a arrival time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is interesting to examine the most negative values of the difference between scheduled and actual elapsed time: how shorter the actual duration of flight can be against its scheduled duration?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights['ElapsedTimeDiff'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting!!!! Some flights lasted 250 minutes less than they were scheduled!!! Is it possiblethat these data can be wrong?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many flights have an elapsed time difference that is an outlier in the range?\n",
    "To answer this question let's first calculate the relative difference of elapsed time, because on long distanced the absolute difference in minutes can be higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the relative difference of elapsed time\n",
    "flights['RelElapTimeDiff'] = flights['ElapsedTimeDiff'] / flights['CRSElapsedTime']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean relative difference between scheduled and actual time (%)', round(flights['RelElapTimeDiff'].mean() * 100, 2))\n",
    "print('Standard deviation of the relative difference (%)', round(flights['RelElapTimeDiff'].std() * 100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(18)\n",
    "gauss_distr = rng.normal(flights['RelElapTimeDiff'].mean(),\n",
    "                        flights['RelElapTimeDiff'].std(),\n",
    "                        size=1000000)\n",
    "\n",
    "bins = np.arange(-1, 1, 0.01)\n",
    "\n",
    "plt.hist(flights['RelElapTimeDiff'], bins=bins, density=True)\n",
    "plt.hist(gauss_distr, histtype='step', bins=bins, color='r', density=True)\n",
    "plt.xlim(-0.5, 0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "q25, q50, q75 = flights['RelElapTimeDiff'].quantile([0.25, 0.5, 0.75])\n",
    "outlier_limit = q25 - (q75 - q25) * 1.5\n",
    "print('All flights with actual elapsed time', round(outlier_limit * 100, 2), 'percents of scheduled elapsed time are deffinitely outliers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering flights that had actual elapsed time to short relative to scheduled \n",
    "actual_time_less_than_CRRS = flights['RelElapTimeDiff'] < outlier_limit\n",
    "\n",
    "# Printing the TOP-10 fasters flights\n",
    "SuperFastFlights = flights[actual_time_less_than_CRRS]\n",
    "print(SuperFastFlights[['FlightDate',\n",
    "                        'Origin', \n",
    "                        'Dest',\n",
    "                        'ActualElapsedTime', \n",
    "                        'CRSElapsedTime', \n",
    "                        'ElapsedTimeDiff',\n",
    "                        'RelElapTimeDiff']]\n",
    "      .sort_values('RelElapTimeDiff', ascending=True).head(10))\n",
    "\n",
    "# Printing some summary for these flights\n",
    "print('In 2014-2018 there were', \n",
    "      SuperFastFlights['Flight_Number_Reporting_Airline'].count(), \n",
    "      'flight arrived earlier for more than', round(outlier_limit * 100, 2), '% (', \n",
    "      round(SuperFastFlights['Flight_Number_Reporting_Airline'].count() / len(flights) * 100, 2),\n",
    "      '% of total flights)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Details for the flight ind = 21568647 which has the most significant difference between scheduled and actual \n",
    "# elapsed times\n",
    "data_details = ['FlightDate']\n",
    "route_details = ['Origin', 'Dest']\n",
    "DepArr_details = ['CRSDepTime', 'CRSArrTime', 'DepTime', 'ArrTime']\n",
    "\n",
    "print(flights.iloc[28530440][data_details + route_details + DepArr_details + elapsed_time_fields])\n",
    "print('Flight number:', flights.iloc[28530440]['Flight_Number_Reporting_Airline'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems strange that this flight was scheduled with 302 min of elapsed time (more then 5 hours!!!), because according to Google [search](https://www.google.com/maps/dir/SBP,+Airport+Drive,+San+Luis+Obispo,+CA,+USA/San+Francisco+International+Airport+(SFO),+San+Francisco,+CA,+USA/@36.4210897,-122.8306609,8z/data=!3m1!4b1!4m14!4m13!1m5!1m1!1s0x80ecf6bf3876b9f1:0xf486acd07a0f3bd2!2m2!1d-120.6420121!2d35.2375699!1m5!1m1!1s0x808f778c55555555:0xa4f25c571acded3f!2m2!1d-122.3816274!2d37.6191145!3e4?entry=ttu&g_ep=EgoyMDI0MTAwMi4xIKXMDSoASAFQAw%3D%3D) shows that these airports are quite close to each other and estimated the direct flight time as 1h 5min, which is more close to the acctual elapsed time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Details for the flight ind = 26994453 which has the second most significant difference between scheduled and actual \n",
    "# elapsed times\n",
    "print(flights.iloc[21568647][data_details + route_details + DepArr_details + elapsed_time_fields])\n",
    "print('Flight number:', flights.iloc[21568647]['Flight_Number_Reporting_Airline'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second most differing flight has the same story: Google [search](https://www.google.com/maps/dir/LaGuardia+Airport+(LGA),+East+Elmhurst,+NY,+USA/Dallas+Fort+Worth+International+Airport+(DFW),+2400+Aviation+Dr,+Dallas,+TX+75261,+United+States/@36.3681193,-96.0279203,5z/data=!3m1!4b1!4m14!4m13!1m5!1m1!1s0x89c25f8983424db5:0x772fc4660e9666b3!2m2!1d-73.8742467!2d40.7766422!1m5!1m1!1s0x864c2a660d222aa7:0x73323f5e067d201c!2m2!1d-97.0335765!2d32.8990434!3e4?entry=ttu&g_ep=EgoyMDI0MTAwMi4xIKXMDSoASAFQAw%3D%3D) shows the estimated time of the direct flight 3h 40m which again closer to the actual elapsed time and far away from scheduled 431 min - more than 7h!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load source file for accessing some detailes that were deleted in the result dataset\n",
    "_fl = load_data_from(source_zip, source_path + '2017_10.csv')\n",
    "\n",
    "# tiltering the flight of interest \n",
    "ind = _fl[(_fl['Flight_Number_Reporting_Airline'] == 5028) \n",
    "    & (_fl['DayofMonth'] == 9) \n",
    "    & (_fl['Origin'] == 'SBP')\n",
    "    & (_fl['Dest'] == 'SFO')].index\n",
    "flight_top1 = _fl.iloc[*ind]\n",
    "\n",
    "# Printing results \n",
    "pd.set_option('display.max_rows', 115)\n",
    "print(_fl.iloc[*ind][:70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load source file for accessing some detailes that were deleted in the result dataset\n",
    "_fl = load_data_from(source_zip, source_path + '2018_7.csv')\n",
    "\n",
    "# tiltering the flight of interest \n",
    "ind = _fl[(_fl['Flight_Number_Reporting_Airline'] == 5935) \n",
    "    & (_fl['DayofMonth'] == 25) \n",
    "    & (_fl['Origin'] == 'DFW')\n",
    "    & (_fl['Dest'] == 'LGA')].index\n",
    "flight_top2 = _fl.iloc[*ind]\n",
    "\n",
    "# Printing results \n",
    "pd.set_option('display.max_rows', 115)\n",
    "print(_fl.iloc[*ind][:70])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two flight were quite ordinary flights: they were not canceled or diverted, they had just one flight (field 'Fligths'), and as we know from Google search above their actual elapsed time seems reasonable but their GRSElapsedTime doesn't. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Could the CRS Elapsed Time have been calculated incorrectly due to timezone differences?\n",
    "Let's check it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The fastest flight - TOP1\n",
    "def time_chech(list_of_flights):\n",
    "    for a in list_of_flights:\n",
    "        CRSDepTime = datetime(a.Year, a.Month, a.DayofMonth, a.CRSDepTime // 100, a.CRSDepTime % 100)\n",
    "        CRSArrTime = datetime(a.Year, a.Month, a.DayofMonth, a.CRSArrTime // 100, a.CRSArrTime % 100)\n",
    "\n",
    "        print('Flight #', a.Flight_Number_Reporting_Airline)\n",
    "        print('CRS: ')\n",
    "        print(a.Origin, '\\nTime zone: ', tz.gettz(IATAtz[a.Origin]))\n",
    "        print('Local departure time:      ', CRSDepTime)\n",
    "        print('Local departure time (tz): ', airport_time_tz(CRSDepTime, a.Origin))\n",
    "        print('UTC Departure time:        ', airport_time_UTC(CRSDepTime, a.Origin))\n",
    "        print('')\n",
    "        print(a.Dest, '\\nTime zone: ', tz.gettz(IATAtz[a.Dest]))\n",
    "        print('Local departure time:      ', CRSArrTime)\n",
    "        print('Local departure time (tz): ', airport_time_tz(CRSArrTime, a.Dest))\n",
    "        print('UTC Departure time:        ', airport_time_UTC(CRSArrTime, a.Dest))\n",
    "        print('')\n",
    "        print('Elapsed time (CRS):', round(a.CRSElapsedTime / 60, 2))\n",
    "        print('Elapsed time (UTC):', round((airport_time_UTC(CRSArrTime, a.Dest) - airport_time_UTC(CRSDepTime, a.Origin)).seconds / 3600, 2))\n",
    "        print('\\n')\n",
    "\n",
    "time_chech([flight_top1, flight_top2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can wee there is no error due to incorrect calculatinb elapsed time for different timezones of Origin and Destination. \n",
    "Let's check all outliers flights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, we see that the data for the flight wiht the earliest arrival is correct. \n",
    "Let's check correctness of Elapsed times for the sample of 1000 flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for correctness of CRS ET (elapsed times) for all records (rows)\n",
    "from datetime import datetime\n",
    "\n",
    "# filtering only flights that were not cancelled or diverted\n",
    "not_canceled_or_diverted = (flights['Cancelled'] != 1) & (flights['Diverted'] != 1)\n",
    "ordinary_flights = flights[not_canceled_or_diverted]\n",
    "print('Number of not cancelled or diverted flights', len(ordinary_flights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(flights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename 'DayofMonth' to 'Day' for pd.to_datetime\n",
    "ordinary_flights = ordinary_flights.rename(columns= {'DayofMonth': 'Day'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create temporary field 'Minute' from 'CRSDepTime' to use with pd.to_datetime\n",
    "ordinary_flights['Minute'] = ordinary_flights['CRSDepTime']\n",
    "ordinary_flights['CRSDepDT'] = pd.to_datetime(ordinary_flights[['Year', 'Month', 'Day', 'Minute']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinary_flights['CRSDepDT'] = [row.CRSDepDT.tz_localize(tz.gettz(IATAtz[row.Origin]), ambiguous=True).\n",
    "                                astimezone(tz.UTC) for row in ordinary_flights[['CRSDepDT', 'Origin']].itertuples()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temporary field 'Minute' from 'CRSArrTime' to use with pd.to_datetime\n",
    "ordinary_flights['Minute'] = ordinary_flights['CRSArrTime']\n",
    "ordinary_flights['CRSArrDT'] = pd.to_datetime(ordinary_flights[['Year', 'Month', 'Day', 'Minute']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinary_flights['CRSArrDT'] = [row.CRSArrDT.tz_localize(tz.gettz(IATAtz[row.Dest]), ambiguous=True, \n",
    "                                                         nonexistent = 'NaT') #.astimezone(tz.UTC) \n",
    "                                for row in ordinary_flights[['CRSArrDT', 'Dest']].itertuples()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_DST_filter = ordinary_flights['CRSArrDT'].isna()\n",
    "print('There are', wrong_DST_filter.sum(), 'flights with wrong spring DST')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, there are 41 flight with wrong spring DST time. I have saved them for future possible analysis. Let's try shift all incorrect flights forward, convert them to UTC and after that check the difference of scheduled and actual Elapsed time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At first, restore the 'CRSArrDT'\n",
    "ordinary_flights['Minute'] = ordinary_flights['CRSArrTime']\n",
    "ordinary_flights['CRSArrDT'] = pd.to_datetime(ordinary_flights[['Year', 'Month', 'Day', 'Minute']])\n",
    "\n",
    "# Taking only the flights with incorrect DST\n",
    "flights_with_wrong_DST = ordinary_flights[wrong_DST_filter].copy()\n",
    "\n",
    "# Shifting forward and converting to UTC\n",
    "flights_with_wrong_DST['CRSArrDT'] = [row.CRSArrDT.tz_localize(tz.gettz(IATAtz[row.Dest]), ambiguous=True, \n",
    "                                                         nonexistent = 'shift_forward').astimezone(tz.UTC) \n",
    "                                for row in flights_with_wrong_DST[['CRSArrDT', 'Dest']].itertuples()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights_with_wrong_DST[['Flight_Number_Reporting_Airline', 'CRSDepTime', 'CRSArrTime', 'CRSDepDT', 'CRSArrDT', 'CRSElapsedTime']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "source_zip = 'data/interim/csv_flight.zip'\n",
    "source_path = 'csv_flight/report_'\n",
    "\n",
    "test = load_data_from(source_zip, source_path + '2014_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Date_details = ['Year', 'Month', 'DayofMonth', 'DayOfWeek', 'FlightDate']\n",
    "DepTime_details = ['CRSDepTime', 'DepTime']\n",
    "ArrTime_details = ['CRSArrTime', 'ArrTime']\n",
    "ElapsedTime_details = ['CRSElapsedTime', 'ActualElapsedTime']\n",
    "CRS_details = ['CRSDepTime', 'CRSArrTime', 'CRSElapsedTime']\n",
    "Route_datails = ['Origin', 'Dest']\n",
    "test[(test['Flight_Number_Reporting_Airline'] == 121) & \n",
    "     (test['DayofMonth'] == 9)][Date_details + \n",
    "     CRS_details +\n",
    "     Route_datails]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create temporary field 'Minute' from 'DepTime' to use with pd.to_datetime\n",
    "ordinary_flights['Minute'] = ordinary_flights['DepTime']\n",
    "ordinary_flights['DepDT'] = pd.to_datetime(ordinary_flights[['Year', 'Month', 'Day', 'Minute']])\n",
    "\n",
    "# Create temporary field 'Minute' from 'ArrTime' to use with pd.to_datetime\n",
    "ordinary_flights['Minute'] = ordinary_flights['ArrTime']\n",
    "ordinary_flights['ArrDT'] = pd.to_datetime(ordinary_flights[['Year', 'Month', 'Day', 'Minute']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind in ordinary_flights.index:\n",
    "       ordinary_flights.loc[ind, 'CRSET_Diff'] = round(ordinary_flights.loc[ind, 'CRSElapsedTime'] / 60, 2) - \\\n",
    "                                        round((airport_time_UTC(ordinary_flights.loc[ind, 'CRSArrDT'], ordinary_flights.loc[ind, 'Dest']) - \\\n",
    "                                               airport_time_UTC(ordinary_flights.loc[ind, 'CRSDepDT'], ordinary_flights.loc[ind, 'Origin'])).seconds / 3600, 2)\n",
    "\n",
    "       ordinary_flights.loc[ind, 'ActET_Diff'] = round(ordinary_flights.loc[ind, 'ActualElapsedTime'] / 60, 2) - \\\n",
    "                                        round((airport_time_UTC(ordinary_flights.loc[ind, 'ArrDT'], ordinary_flights.loc[ind, 'Dest']) - \\\n",
    "                                               airport_time_UTC(ordinary_flights.loc[ind, 'DepDT'], ordinary_flights.loc[ind, 'Origin'])).seconds / 3600, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinary_flights[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
